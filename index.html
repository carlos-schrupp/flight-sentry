<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Flight Sentry - Portfolio Demo</title>
    <!-- MathJax for LaTeX rendering -->
    <script>
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        }
      };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        /* Berkeley I School inspired typography and styling */
        * {
            box-sizing: border-box;
        }
        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            font-size: 16px;
            line-height: 1.7;
            color: #333;
            max-width: 900px;
            margin: 0;
            padding: 0;
            background-color: #ffffff;
            color:#333;
        }
        .notebook-content {
            background: white;
            padding: 0;
        }
        /* Typography - Headings (Berkeley I School style) */
        h1 {
            font-family: "Libre Baskerville", Georgia, serif;
            font-weight: 700;
            font-size: 2.5em;
            line-height: 1.2;
            margin: 0.67em 0;
            color: #1a1a1a;
            border-bottom: 3px solid #2c5282;
            padding-bottom: 0.3em;
        }
        h2 {
            font-family: "Libre Baskerville", Georgia, serif;
            font-weight: 600;
            font-size: 2em;
            line-height: 1.3;
            margin: 1.5em 0 0.75em 0;
            color: #2c5282;
            padding-top: 0.5em;
        }
        h3 {
            font-family: "Libre Baskerville", Georgia, serif;
            font-weight: 600;
            font-size: 1.5em;
            line-height: 1.4;
            margin: 1.25em 0 0.5em 0;
            color: #2c5282;
        }
        h4 {
            font-family: 'Helvetica Neue', 'Arial', sans-serif;
            font-weight: 600;
            font-size: 1.25em;
            line-height: 1.4;
            margin: 1em 0 0.5em 0;
            color: #2c5282;
        }
        h5 {
            font-family: 'Helvetica Neue', 'Arial', sans-serif;
            font-weight: 600;
            font-size: 1.1em;
            line-height: 1.4;
            margin: 0.9em 0 0.4em 0;
            color: #2c5282;
        }
        /* Body text */
        p {
            margin: 1em 0;
            text-align: justify;
            text-justify: inter-word;
        }
        /* Links */
        a {
            color: #003262;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
            color: #FDB515;
        }
        a.anchor-link {
            color: #999;
            font-size: 0.8em;
            margin-left: 0.5em;
        }
        /* Lists */
        ul, ol {
            margin: 1em 0;
            padding-left: 2em;
        }
        li {
            margin: 0.5em 0;
        }
        /* Images */
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 1.5em auto;
        }
        /* Tables - Berkeley I School style */
        .table-wrapper {
            overflow-x: auto;
            margin: 2em 0;
            -webkit-overflow-scrolling: touch;
            border: 1px solid #e0e0e0;
            border-radius: 4px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            border-spacing: 0;
            font-size: 15px;
            min-width: 800px;
            background: white;
        }
        table thead {
            background-color: #f5f5f5;
            border-bottom: 2px solid #003262;
        }
        table th {
            padding: 14px 12px;
            text-align: left;
            font-weight: 600;
            font-family: 'Helvetica Neue', 'Arial', sans-serif;
            color: #1a1a1a;
            white-space: nowrap;
            border-right: 1px solid #e0e0e0;
        }
        table th:last-child {
            border-right: none;
        }
        table tbody tr {
            border-bottom: 1px solid #e0e0e0;
        }
        table tbody tr:hover {
            background-color: #f9f9f9;
        }
        table tbody tr:nth-child(even) {
            background-color: #fafafa;
        }
        table tbody tr:nth-child(even):hover {
            background-color: #f5f5f5;
        }
        table td {
            padding: 12px;
            border-right: 1px solid #f0f0f0;
            vertical-align: top;
        }
        table td:last-child {
            border-right: none;
        }
        table tbody tr:last-child {
            border-bottom: 2px solid #e0e0e0;
        }
        /* Code and pre blocks */
        code, pre {
            font-family: 'Courier New', 'Monaco', 'Consolas', monospace;
            font-size: 0.9em;
        }
        pre {
            background-color: #f5f5f5;
            padding: 1em;
            border-radius: 4px;
            overflow-x: auto;
            border-left: 4px solid #003262;
        }
        /* Blockquotes */
        blockquote {
            margin: 1.5em 0;
            padding-left: 1.5em;
            border-left: 4px solid #FDB515;
            color: #666;
            font-style: italic;
        }
        /* Horizontal rules */
        hr {
            border: none;
            border-top: 2px solid #e0e0e0;
            margin: 2em 0;
        }
        /* Strong and emphasis */
        strong {
            font-weight: 600;
            color: #1a1a1a;
        }
        em {
            font-style: italic;
        }
        /* Responsive adjustments */
        @media (max-width: 768px) {
            body {
                padding: 20px 15px;
                font-size: 15px;
            }
            h1 {
                font-size: 2em;
            }
            h2 {
                font-size: 1.75em;
            }
            h3 {
                font-size: 1.35em;
            }
            .table-wrapper {
                margin: 1.5em -15px;
                padding: 0 15px;
            }
            table {
                font-size: 13px;
            }
            table th,
            table td {
                padding: 10px 8px;
            }
        }
        /* Notebook cell styling */
        .cell {
            margin: 1.5em 0;
        }
        .text_cell_render {
            font-family: 'Georgia', 'Times New Roman', serif;
        }
        .inner_cell {
            padding: 0.5em 0;
        }
        /* MathJax LaTeX formula styling */
        .MathJax {
            font-size: 1.1em !important;
        }
        .MathJax_Display {
            margin: 1.5em 0 !important;
            text-align: center;
            overflow-x: auto;
            overflow-y: hidden;
        }
        /* Center display math formulas */
        .MathJax_Display,
        mjx-container[jax="CHTML"][display="true"] {
            display: block;
            text-align: center;
            margin: 1.5em auto;
            max-width: 100%;
        }
        /* Output wrapper styling */
        .output_wrapper {
            margin: 1.5em 0;
        }
        .output_png {
            text-align: center;
            max-width: 100%;
            overflow-x: auto;
        }
        /* Prevent notebook output images from breaking column layout */
      .output_png img,
      .output_subarea img {
        max-width: 100% !important;
        height: auto !important;
      }
      /* Hard-stop notebook outputs from expanding layout */
      .output_area,
      .output_subarea,
      .output_wrapper,
      .output {
        max-width: 100% !important;
        overflow-x: auto !important;
      }

      /* Make sure output images never exceed their container */
      .output_area img,
      .output_subarea img,
      .output_png img {
        max-width: 100% !important;
        height: auto !important;
      }

        /* Code cell styling */
        .code_cell {
            margin: 1em 0;
        }
        .input_prompt {
            display: none;
        }
        /* Additional Berkeley I School inspired elements */
        .border-box-sizing {
            box-sizing: border-box;
        }
        /* Section spacing */
        .cell.border-box-sizing.text_cell.rendered {
            margin-bottom: 2em;
        }
    /* =========================
   two-column layout styles
   ========================= */

:root{
  --navy:#0b2a6f;
  --gold:#FDB515;
  --text:#1b1b1b;
  --muted:#444;
}

/* Remove notebook width constraint */
body{
  max-width:none !important;
  margin:0 !important;
  padding:0 !important;
}

/* Two-column page layout */
.page{
  max-width:1200px;
  margin:0 auto;
  padding:48px 40px;
  display:flex;
  gap:56px;
  align-items:flex-start;
}

/* Sidebar */
.sidebar{
  width:220px;
  flex:0 0 220px;
  font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif;
}

.sidebar-title{
  font-weight:700;
  font-size:16px;
  color:var(--muted);
  line-height:1.3;
  margin-bottom:24px;
}

.sidebar-heading{
  font-weight:800;
  margin:16px 0 10px;
  color:#000;
}

.sidebar-list{
  list-style:none;
  padding:0;
  margin:0;
}

.sidebar-list li{
  margin:10px 0;
  color:var(--navy);
}

/* Main content */
.content{
  flex:1;
  min-width:0;
}

/* Typography fixes */
h1{
  color:var(--navy);
  border:none !important;
  padding-bottom:0 !important;
  margin:0 0 12px 0;
  font-size:44px;
  line-height:1.1;
}

h2{
  color:var(--navy);
  font-size:28px;
  padding-top:0;
}

p{
  font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif;
  text-align:left;
  max-width:760px;
}

/* Gold divider */
.rule{
  height:2px;
  background:var(--gold);
  width:100%;
  margin:14px 0 28px;
}

/* Hide notebook anchor symbols */
a.anchor-link{
  display:none;
}

/* Prevent notebook wrapper from re-centering */
.notebook-content{
  max-width:none;
  margin:0;
  padding:0;
}
h1{
  margin-bottom: 8px;
}

.rule{
  margin: 10px 0 18px;
}
/* =========================
   White-space compression
   ========================= */

/* Reduce big gaps between notebook "cells" */
.cell{
  margin: 0.6em 0 !important;
}

.cell.border-box-sizing.text_cell.rendered{
  margin-bottom: 0.6em !important;
}

.inner_cell{
  padding: 0 !important;
}

/* Reduce paragraph spacing */
p{
  margin: 0.6em 0 !important;
}

/* Reduce heading spacing a bit */
h2{
  margin: 1.1em 0 0.4em 0 !important;
}

h3{
  margin: 0.8em 0 0.3em 0 !important;
}

h4, h5{
  margin: 0.6em 0 0.25em 0 !important;
}

/* Tighten tables/figures */
table, img{
  margin: 0.8em 0 !important;
}
    </style>
</head>
<body>
  <div class="page">
    <aside class="sidebar">
      <div class="sidebar-title">
        MIDS Project<br>
        Fall 2025
      </div>

      <div class="sidebar-section">
        <div class="sidebar-heading">Team Members</div>
        <ul class="sidebar-list">
          <li>Anabel Basualdo</li>
          <li>Carlos Schrupp</li>
          <li>Arun Agarwal</li>
          <li>Shikha Sharma</li>
          <li>Nicole Zhang</li>
        </ul>
      </div>
    </aside>

    <main class="content">
      <div class="notebook-content">

<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h1 id="Flight-Sentry">
  Flight Sentry
  <a class="anchor-link" href="#Flight-Sentry">¶</a>
</h1>

<div class="rule"></div>

<h2 id="Predicting-Flight-Departure-Delays">
  Predicting Flight Departure Delays: A Time-Series Classification Approach
  <a class="anchor-link" href="#Predicting-Flight-Departure-Delays">¶</a>
</h2>

  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1-Introduction">
  1. Introduction
  <a class="anchor-link" href="#1-Introduction">¶</a>
</h2>

<p>
Flight delays often emerge from multiple interacting factors and can escalate quickly once they begin. This project focuses on identifying early delay risk using information available before departure to support better operational decisions.
</p>
    <a class="anchor-link" href="#1.-Team-4-4-Introduction">
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<h2 id="1.1-Team-Members">
  2. Team Members
  <a class="anchor-link" href="#1.1-Team-Members">¶</a>
</h2>

  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <table>
    <tr>
     <th>
      Arun Agarwal
     </th>
     <th>
      Anabel Basualdo
     </th>
     <th>
      Carlos Schrupp
     </th>
     <th>
      Shikha Sharma
     </th>
     <th>
      Nicole Zhang
     </th>
    </tr>
    <tr>
     <td>
      aagarwal19@berkeley.edu
     </td>
     <td>
      anabelbasualdo@berkeley.edu
     </td>
     <td>
      carlos.schrupp@berkeley.edu
     </td>
     <td>
      shikhasharma@berkeley.edu
     </td>
     <td>
      haoyuezhang@ischool.berkeley.edu
     </td>
    </tr>
    <tr>
     <td>
      <img alt="Passport size photo" height="200" src="https://ca.slack-edge.com/T0WA5NWKG-U0673SJAHUY-89a53ff501a9-512" width="160"/>
     </td>
     <td>
      <img alt="Passport size photo" height="200" src="https://ca.slack-edge.com/T0WA5NWKG-U05JX3SEJJE-b467edd80838-512" width="160"/>
     </td>
     <td>
      <img alt="Passport size photo" height="200" src="https://ca.slack-edge.com/T0WA5NWKG-U07BYEN1P4P-f4936b4d7def-512" width="160"/>
     </td>
     <td>
      <img alt="Passport size photo" height="200" src="https://ca.slack-edge.com/T0WA5NWKG-U07F4U1J6AD-3e6e38f8169f-512" width="160"/>
     </td>
     <td>
      <img alt="Passport size photo" height="200" src="https://ca.slack-edge.com/T0WA5NWKG-U07AJ8A19QV-a93380556e99-512" width="160"/>
     </td>
    </tr>
   </table>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="3.-Project-Structure:">
    3. Project Structure:
    <a class="anchor-link" href="#3.-Project-Structure:">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="3.1-Project-Abstract">
    3.1 Project Abstract
    <a class="anchor-link" href="#3.1-Project-Abstract">
     ¶
    </a>
   </h3>
   <p>
<p>
Flight delays rarely occur in isolation, yet they place real strain on airline operations and passenger experience. This project develops a system to estimate whether a domestic U.S. flight is at risk of departing at least 15 minutes late using only information available two hours before scheduled departure. The goal is earlier awareness, giving operations teams time to adjust crew schedules, gate plans, and communication before disruptions compound.
</p>

<p>
The model integrates U.S. Department of Transportation on-time performance data with National Oceanic and Atmospheric Administration weather observations, covering 31.1 million domestic flights from 2015–2019. A custom data pipeline enforces a strict two-hour cutoff to prevent data leakage and maintains near-zero missing values at scale. Feature engineering produces 112 leakage-free features capturing temporal patterns, recent delay behavior, weather conditions, airport congestion, carrier performance history, and network centrality, all derived exclusively from pre-departure information.
</p>

<p>
Logistic Regression serves as an interpretable baseline optimized for F₂-score to prioritize recall and surface high-risk flights early. Comparisons across Logistic Regression, Random Forest, and multilayer perceptron models show that neural networks achieve the strongest recall for early delay detection, while a two-tier regression model estimates delay duration with an RMSE of 42.83 minutes. Together, these results show that early delay risk estimation is most effective when historical performance, network structure, and short-horizon temporal signals are combined within a carefully leakage-controlled pipeline built for operational use.
</p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="3.2-Project-Description">
    3.2 Project Description
    <a class="anchor-link" href="#3.2-Project-Description">
     ¶
    </a>
   </h3>
   <p>
    This report documents the development of our machine learning pipeline for predicting flight departure delays across three project phases, with Phase 3 delivering a production-ready, multi-year system evaluated on 31.1 million flights (2015-2019) with 112 optimized features and multiple modeling approaches including neural networks.
   </p>
   <p>
    <strong>
     Report Structure:
    </strong>
   </p>
   <ul>
    <li>
     <p>
      <strong>
       Section 3.3 - The Data
      </strong>
      : Details our production dataset (31.1M flights, 112 features from 2015-2019), the six-stage checkpoint pipeline from raw ingestion to modeling-ready format (3.3.3), comprehensive data quality analysis achieving &lt;1% missing data (3.3.4), and target variable analysis with class imbalance (18.15% delayed, 82:18 ratio) in Section 3.3.5. Section 3.3.7 documents the custom flights-weather-airport join architecture rebuilt for 5-year data with feature leakage prevention strategy. Sections 3.3.8-3.3.9 cover feature engineering methods across 8 families and the complete feature dictionary. Section 3.3.6 presents embedded EDA findings on temporal delay patterns, carrier performance, and geographic patterns across all five years. Sections 3.3.10-3.3.11 detail dataset storage requirements and production readiness validation.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Section 4 - Exploratory Data Analysis
      </strong>
      : Provides comprehensive multi-year visualizations and analysis including data overview (4.1), time-based delay patterns with hourly and day-of-week breakdowns (4.2.1-4.2.2), airport-specific delay patterns showing volume vs performance relationships (4.3), airline performance comparisons across market share and delay rates (4.4), and weather impact assessments covering temperature, wind speed, precipitation effects (4.5.1-4.5.3), visibility impacts (4.6), and correlation heatmap analysis (4.7).
     </p>
    </li>
    <li>
     <p>
      <strong>
       Section 5 - Machine Learning Algorithms and Modeling Strategy
      </strong>
      : Describes our modeling approach (5.1.1) with time-series cross-validation (5.1.3). Section 5.2 presents classification baselines including Logistic Regression (5.2.1.1-5.2.1.3), Random Forest (5.2.1.4), and comprehensive classification results comparison (5.2.1.5-5.2.1.6). Regression baseline analysis (5.2.2) includes feature summaries (5.2.2.2), performance results (5.2.2.3), holdout evaluation (5.2.2.4.2), feature importance by model (5.2.2.5), and regression summary (5.2.2.7). Section 5.3 details the alternative two-stage architecture with holdout results, error analysis by delay magnitude, worst-performing airports/carriers/routes, weekend vs holiday comparisons, and feature importance comparisons between classifier and regressor. Section 5.4 presents MLP neural network ensemble implementation including data splits (5.4.1), leakage control (5.4.2), feature engineering pipeline (5.4.3), class imbalance diagnosis (5.4.4), ensemble member construction with 50:50 undersampling (5.4.5), Optuna hyperparameter optimization (5.4.6), final model training (5.4.7), inference methods (5.4.8), results summary comparing single models vs ensemble (5.4.11), confusion matrix analysis (5.4.12), and saved artifacts (5.4.13). Section 5.5 summarizes all classification experiments, and Section 5.6 discusses time-series, graph, and MLP implementations.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Section 6 - Evaluation Metrics
      </strong>
      : Establishes F₂-score as primary classification metric (6.1) prioritizing recall over precision to catch at-risk flights—aligning with airline operational priorities where missing a delay causes more disruption than a false alarm, with PR-AUC as secondary metric (6.2) appropriate for imbalanced datasets. Includes per-segment confusion analysis by carrier and airport (6.3), regression metrics MAE and RMSE for Stage 2 duration prediction (6.4), and operational/domain-level evaluation views (6.5).
     </p>
    </li>
    <li>
     <p>
      <strong>
       Section 8 - Pipeline
      </strong>
      : Illustrates end-to-end six-stage Spark ML pipeline with explicit checkpoints, from raw data ingestion (Stage 0) through leakage-aware cleaning and joins (Stage 1-2), time-series split and feature engineering using only T-2h information (Stage 3-4), feature selection and final refinement (Stage 5-5a), model training with undersampled data, and evaluation using time-ordered validation with 2019 blind holdout.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Section 9 - Conclusion
      </strong>
      : Summarizes key findings, model performance across three approaches, feature importance insights, and project outcomes demonstrating production readiness.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Section 10 - Open Issues and Next Steps
      </strong>
      : Discusses deployment considerations including real-time feature computation infrastructure, data drift monitoring for model degradation detection, carrier-specific threshold calibration, and validation on 2020-2021 data to assess COVID-19 impact and model robustness.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Appendix
      </strong>
      : Provides references and links to supporting Databricks notebooks for data cleaning, EDA, custom joins, feature engineering, and modeling pipelines, plus academic references on flight delay prediction methodologies.
     </p>
    </li>
   </ul>
   <p>
    <strong>
     Key Technical Achievements:
    </strong>
   </p>
   <p>
    Throughout this project, we emphasize reproducibility through checkpoint-based workflows, scalability using Apache Spark's distributed computing (validated on 31.1M records with cluster benchmarking), and strict adherence to temporal validation protocols that prevent look-ahead bias. Our T-2h prediction window reflects realistic operational conditions where airlines must make crew scheduling, gate assignment, and passenger notification decisions before actual departure information becomes available. The six-stage pipeline successfully handles the 6× data scale increase through strategic caching, checkpointing, and unpersisting operations. Feature importance analysis across Random Forest models identified the top predictors: 24-hour weighted rolling average delay by origin airport (14.2%), RF probability meta-feature (11.8%), previous flight delay status (9.5%), origin degree centrality (8.7%), and prior-day delay rate (7.6%). The diversity across our top 15 features—spanning rolling aggregates, meta-features, aircraft lag variables, and network centrality—validates that delays are complex phenomena requiring multiple analytical perspectives drawn from temporal, operational, environmental, and systemic factors.
   </p>
   <hr/>
   <h2 id="Evolution-from-Phase-2-to-Phase-3:">
    Evolution from Phase 2 to Phase 3:
    <a class="anchor-link" href="#Evolution-from-Phase-2-to-Phase-3:">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Aspect
      </th>
      <th>
       Phase 2
      </th>
      <th>
       Phase 3
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       Dataset Size
      </td>
      <td>
       5.7M flights (2015 only)
      </td>
      <td>
       31.1M flights (2015-2019, 6× increase)
      </td>
     </tr>
     <tr>
      <td>
       Features
      </td>
      <td>
       108 (29 raw + 79 engineered)
      </td>
      <td>
       112 optimized across 8 families
      </td>
     </tr>
     <tr>
      <td>
       Feature Families
      </td>
      <td>
       5 families
      </td>
      <td>
       8 families (added: Graph, RFM, Meta-Features)
      </td>
     </tr>
     <tr>
      <td>
       Pipeline Stages
      </td>
      <td>
       5 checkpoints
      </td>
      <td>
       6 stages (S0 through S5a)
      </td>
     </tr>
     <tr>
      <td>
       Missing Data
      </td>
      <td>
       0.0%
      </td>
      <td>
       &lt;1% (49% → &lt;1% through pipeline)
      </td>
     </tr>
     <tr>
      <td>
       Data Leakage
      </td>
      <td>
       Eliminated (15 features removed)
      </td>
      <td>
       Validated across 153 engineered, pruned to 112
      </td>
     </tr>
     <tr>
      <td>
       Join Logic
      </td>
      <td>
       Custom T-2h aligned join (2015)
      </td>
      <td>
       Rebuilt joins for all 5 years
      </td>
     </tr>
     <tr>
      <td>
       Models Implemented
      </td>
      <td>
       LR, RF (classification); Linear, DT, RF, GB, XGB (regression)
      </td>
      <td>
       LR, RF, MLP (classification); Two-tier regression
      </td>
     </tr>
     <tr>
      <td>
       Evaluation Strategy
      </td>
      <td>
       Time-series CV on 2015
      </td>
      <td>
       Train 2015-2017, Val 2018, Blind Test 2019
      </td>
     </tr>
     <tr>
      <td>
       Primary Metric
      </td>
      <td>
       F₀.₅-score (precision-friendly)
      </td>
      <td>
       F₂-score (recall-friendly for operations)
      </td>
     </tr>
     <tr>
      <td>
       Secondary Metric
      </td>
      <td>
       PR-AUC
      </td>
      <td>
       PR-AUC
      </td>
     </tr>
     <tr>
      <td>
       Class Imbalance Handling
      </td>
      <td>
       Identified (18.39% delayed)
      </td>
      <td>
       Addressed via undersampling (82:18 ratio)
      </td>
     </tr>
     <tr>
      <td>
       Neural Networks
      </td>
      <td>
       Planned for Phase 3
      </td>
      <td>
       Implemented MLP with 2-layer architectures
      </td>
     </tr>
     <tr>
      <td>
       Time-Series Features
      </td>
      <td>
       Basic temporal features
      </td>
      <td>
       24 cyclic-encoded + 12 RFM features
      </td>
     </tr>
     <tr>
      <td>
       Graph Features
      </td>
      <td>
       Not included
      </td>
      <td>
       8 network centrality features (PageRank, degree)
      </td>
     </tr>
     <tr>
      <td>
       Top Feature Importance
      </td>
      <td>
       Previous flight status (40%)
      </td>
      <td>
       24h rolling avg by origin (14.2%)
      </td>
     </tr>
     <tr>
      <td>
       Computational Scale
      </td>
      <td>
       Single-year processing
      </td>
      <td>
       Multi-year with memory optimization strategies
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="3.3-The-Data">
    3.3 The Data
    <a class="anchor-link" href="#3.3-The-Data">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.1-Data-Sources">
    3.3.1 Data Sources
    <a class="anchor-link" href="#3.3.1-Data-Sources">
     ¶
    </a>
   </h4>
   <p>
    Our flight delay prediction system integrates five primary data sources, each serving a distinct purpose in building a comprehensive modeling dataset.
   </p>
   <p>
    <strong>
     Table 3.1: Data Sources Overview
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Source
      </th>
      <th>
       Description
      </th>
      <th>
       Purpose
      </th>
      <th>
       Reference
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Flights (BTS TranStats)
       </strong>
      </td>
      <td>
       U.S. DOT On-Time Performance data with scheduled/actual times, cancellations, diversions, and delay indicators
      </td>
      <td>
       Factual flight backbone with row-level timing and delay labels
      </td>
      <td>
       <a href="https://transtats.bts.gov/DatabaseInfo.asp?DB_URL=&amp;QO_VQ=EFD">
        transtats.bts.gov
       </a>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Weather (NOAA ISD)
       </strong>
      </td>
      <td>
       Global Hourly observations from NOAA NCEI's Integrated Surface Database
      </td>
      <td>
       As-of weather enrichment at T-2h before departure
      </td>
      <td>
       <a href="https://www.ncei.noaa.gov/products/land-based-station/integrated-surface-database">
        ncei.noaa.gov
       </a>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Station Metadata (ISD)
       </strong>
      </td>
      <td>
       Station identifiers, coordinates, elevation, and period-of-record details
      </td>
      <td>
       Airport-to-station bridge for weather joins
      </td>
      <td>
       <a href="https://www.ncei.noaa.gov/products/land-based-station/station-histories">
        ncei.noaa.gov
       </a>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Airport Codes
       </strong>
      </td>
      <td>
       IATA/ICAO identifiers with timezone and coordinates
      </td>
      <td>
       Time conversion (local → UTC) for weather join alignment
      </td>
      <td>
       <a href="https://datahub.io/core/airport-codes">
        datahub.io
       </a>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        OTPW (Pre-joined)
       </strong>
      </td>
      <td>
       Databricks-provided joined ATP and Weather dataset
      </td>
      <td>
       Phase 1 baseline and pipeline prototyping
      </td>
      <td>
       dbfs:/mnt/mids-w261/
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    For Phase 2, we built a custom leakage-safe join rather than using the pre-joined OTPW dataset. This approach enabled precise T-2h weather alignment, better airport metadata integration, and complete control over the join logic to prevent data leakage. In Phase 3, we scaled this custom join infrastructure to handle five years of data (2015-2019), rebuilding all weather joins, aircraft rotations, and airport metadata joins for 31.1 million flights while maintaining strict temporal ordering and leakage prevention.
   </p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.2-Dataset-Scope-and-Dimensions">
    3.3.2 Dataset Scope and Dimensions
    <a class="anchor-link" href="#3.3.2-Dataset-Scope-and-Dimensions">
     ¶
    </a>
   </h4>
   <h3 id="Phase-3-Analysis-Dataset">
    Phase 3 Analysis Dataset
    <a class="anchor-link" href="#Phase-3-Analysis-Dataset">
     ¶
    </a>
   </h3>
   <p>
    For Phase 3, we conduct comprehensive analysis on the
    <strong>
     complete 2015-2019 dataset
    </strong>
    , representing five full years of domestic U.S. flight operations. This provides complete temporal coverage to capture seasonal patterns, year-over-year trends, operational dynamics, holiday effects, and weather variability across multiple annual cycles—essential for building a production-ready prediction system.
   </p>
   <p>
    <strong>
     Table 3.2: Final Dataset Dimensions (Checkpoint 5a)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Dimension
      </th>
      <th>
       Value
      </th>
      <th>
       Details
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Total Flights
       </strong>
      </td>
      <td>
       31,128,891
      </td>
      <td>
       98.3% retention from raw 31.7M records
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Features
       </strong>
      </td>
      <td>
       112
      </td>
      <td>
       Optimized from 153 engineered features
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Time Period
       </strong>
      </td>
      <td>
       Jan 1, 2015 – Dec 31, 2019
      </td>
      <td>
       1,826 days, 60 months, 5 complete years
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Airlines
       </strong>
      </td>
      <td>
       19
      </td>
      <td>
       Unique carriers (includes regional carriers)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Airports
       </strong>
      </td>
      <td>
       369 origin / 368 destination
      </td>
      <td>
       Unique airport codes
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        States
       </strong>
      </td>
      <td>
       53
      </td>
      <td>
       Origin and destination states
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Missing Data
       </strong>
      </td>
      <td>
       &lt;1%
      </td>
      <td>
       Near-complete imputation achieved (1.8% in select features)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Target Variable
       </strong>
      </td>
      <td>
       DEP_DEL15
      </td>
      <td>
       Binary: 1=delayed ≥15min, 0=on-time
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Class Distribution
       </strong>
      </td>
      <td>
       81.85% on-time / 18.15% delayed
      </td>
      <td>
       4.51:1 imbalance ratio
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Storage Size
       </strong>
      </td>
      <td>
       ~18.2 GB
      </td>
      <td>
       Parquet format (Checkpoint 5a)
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Yearly Distribution:
    </strong>
   </p>
   <ul>
    <li>
     2015: 5,704,114 flights (18.3%)
    </li>
    <li>
     2016: 5,518,291 flights (17.7%)
    </li>
    <li>
     2017: 5,604,527 flights (18.0%)
    </li>
    <li>
     2018: 7,137,918 flights (22.9%)
    </li>
    <li>
     2019: 7,328,857 flights (23.5%)
    </li>
   </ul>
   <p>
    <strong>
     Train-Validation-Test Split:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Training Set (2015-2017):
     </strong>
     16,826,932 flights (54.0%)
    </li>
    <li>
     <strong>
      Validation Set (2018):
     </strong>
     7,137,918 flights (22.9%)
    </li>
    <li>
     <strong>
      Blind Holdout (2019):
     </strong>
     7,328,857 flights (23.5%)
    </li>
   </ul>
   <p>
    This temporal split ensures no data leakage while providing sufficient training data and maintaining realistic operational evaluation on unseen future years.
   </p>
   <h5 id="Scalability-Achievements">
    Scalability Achievements
    <a class="anchor-link" href="#Scalability-Achievements">
     ¶
    </a>
   </h5>
   <p>
    We successfully scaled our pipeline 6× from Phase 2's single-year dataset to five years of data by implementing aggressive memory management strategies including:
   </p>
   <ul>
    <li>
     <strong>
      Checkpoint-based workflows:
     </strong>
     Intermediate results saved at each pipeline stage to enable recovery and avoid recomputation
    </li>
    <li>
     <strong>
      Strategic caching:
     </strong>
     Frequently-accessed DataFrames cached in memory with explicit unpersisting when no longer needed
    </li>
    <li>
     <strong>
      Parquet optimization:
     </strong>
     Converted all intermediate and final datasets to columnar Parquet format for improved compression and query performance
    </li>
    <li>
     <strong>
      Partition tuning:
     </strong>
     Adjusted Spark partitions based on data volume at each stage to balance parallelism and overhead
    </li>
   </ul>
   <p>
    <strong>
     Dataset Scale Progression:
    </strong>
   </p>
   <ul>
    <li>
     3-month sample: ~1.4M flights (Phase 1 prototyping)
    </li>
    <li>
     1-year dataset: ~5.7M flights (Phase 2 production baseline)
    </li>
    <li>
     <strong>
      5-year dataset: ~31.1M flights (Phase 3 production-ready system)
     </strong>
    </li>
    <li>
     <strong>
      2020-2024 dataset: ~31.3M flights (Phase 3 extra points)
     </strong>
    </li>
   </ul>
   <p>
    We read data directly into Apache Spark using
    <code>
     spark.read.parquet()
    </code>
    for all checkpointed stages, leveraging Spark's lazy evaluation and distributed processing. Cluster configurations were scaled from 4-node to 8-node setups during intensive feature engineering stages, with wall times tracked for all major pipeline operations to ensure computational feasibility.
   </p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.3-Data-Processing-Pipeline">
    3.3.3 Data Processing Pipeline
    <a class="anchor-link" href="#3.3.3-Data-Processing-Pipeline">
     ¶
    </a>
   </h4>
   <p>
    Our pipeline implements a systematic, six-stage transformation workflow designed to convert raw flight and weather data into a production-ready modeling dataset. Each stage is checkpointed to enable reproducibility, debugging, and collaborative development.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_000_414ab24b.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <strong>
     Table 3.3: Pipeline Stage Summary (2015-2019)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Stage
      </th>
      <th>
       File Name
      </th>
      <th>
       Description
      </th>
      <th>
       Key Operations
      </th>
      <th>
       Rows
      </th>
      <th>
       Features
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Stage 0: OTPW Raw
       </strong>
      </td>
      <td>
       <code>
        OTPW_60M_Backup/
       </code>
      </td>
      <td>
       Raw BTS On-Time Performance data for 2015-2019. Contains all scheduled flights with basic delay indicators, scheduled times, and carrier information. 49.39% missing data across 142 columns.
      </td>
      <td>
       Raw data ingestion, no transformations
      </td>
      <td>
       31,673,119
      </td>
      <td>
       214
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP1: Initial Joined
       </strong>
      </td>
      <td>
       <code>
        checkpoint_1_initial_joined_5Y_2015-2019.parquet
       </code>
      </td>
      <td>
       Custom T-2 hour weather join merging OTPW with NOAA hourly observations and airport geographic metadata. Includes weather conditions, station coordinates, and timezone data.
      </td>
      <td>
       Join flights + weather + geographic enrichment, temporal alignment
      </td>
      <td>
       31,746,841
      </td>
      <td>
       75
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP2: Cleaned &amp; Imputed
       </strong>
      </td>
      <td>
       <code>
        checkpoint_2_cleaned_imputed_2015-2019.parquet
       </code>
      </td>
      <td>
       Cleaned dataset after data quality improvements: removed 15 leakage features, filtered cancelled/diverted flights (617,950 rows), applied 3-tier weather imputation reducing missing from 10.16% to 0%.
      </td>
      <td>
       Remove leakage, filter invalid flights, impute weather, type conversion
      </td>
      <td>
       31,128,891
      </td>
      <td>
       59
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP3: Basic Features
       </strong>
      </td>
      <td>
       <code>
        checkpoint_3_basic_features_2015-2019.parquet
       </code>
      </td>
      <td>
       Enhanced dataset with 36 basic engineered features: temporal features (hour, day, season, weekend), distance transformations, weather severity scoring, rolling 24h delay statistics by origin airport.
      </td>
      <td>
       Temporal (10), distance (6), weather (3), rolling metrics (10), geographic (3), other (4)
      </td>
      <td>
       31,128,891
      </td>
      <td>
       95
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP4: Advanced Features
       </strong>
      </td>
      <td>
       <code>
        checkpoint_4_advanced_features_2015-2019.parquet
       </code>
      </td>
      <td>
       Comprehensive feature-engineered dataset with 91 additional features: aircraft lag variables, RFM patterns, network centrality (PageRank, degree), 24 interaction terms, 14 cyclic encodings, Breiman meta-features.
      </td>
      <td>
       Weather (+19), rolling (+12), RFM (13), interactions (24), cyclic (14), network (8), aircraft lag (6), Breiman (2)
      </td>
      <td>
       31,128,891
      </td>
      <td>
       186
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP5: Comprehensive
       </strong>
      </td>
      <td>
       <code>
        checkpoint_5_comprehensive_2015-2019.parquet
       </code>
      </td>
      <td>
       All engineered features before final selection. Removed 33 redundant/low-importance features identified through correlation analysis and cardinality checks. Represents complete feature space exploration.
      </td>
      <td>
       Correlation-based reduction, cardinality filtering, duplicate removal
      </td>
      <td>
       31,128,891
      </td>
      <td>
       153
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP5a: Final Clean
       </strong>
      </td>
      <td>
       <code>
        checkpoint_5a_final_clean_2015-2019.parquet
       </code>
      </td>
      <td>
       Production-ready dataset after feature selection and optimization: indexed 12 categorical features (string→numeric), removed 41 additional features, verified &lt;1% missing data. Ready for ML pipelines.
      </td>
      <td>
       String indexing (+12), feature selection (-41), final validation
      </td>
      <td>
       31,128,891
      </td>
      <td>
       112
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Key-Transformations-by-Checkpoint">
    Key Transformations by Checkpoint
    <a class="anchor-link" href="#Key-Transformations-by-Checkpoint">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Stage 0 → CP1: Weather and Geographic Join (+73,722 rows, -139 columns)
    </strong>
   </p>
   <ul>
    <li>
     Custom T-2 hour aligned join with NOAA weather stations (634 locations)
    </li>
    <li>
     Added 15 weather features (temperature, wind, precipitation, visibility, pressure, humidity)
    </li>
    <li>
     Added 20 geographic features (airport coordinates, station distances, timezones, elevation)
    </li>
    <li>
     Consolidated/removed 139 redundant OTPW columns
    </li>
    <li>
     Row increase due to join expansion (flights matched to multiple weather observations)
    </li>
    <li>
     Missing data reduced: 49.39% → 10.16%
    </li>
   </ul>
   <p>
    <strong>
     CP1 → CP2: Data Cleaning and Leakage Removal (-617,950 rows, -16 features)
    </strong>
   </p>
   <ul>
    <li>
     Removed 15 data leakage features containing future information:
     <ul>
      <li>
       Actual times: DEP_TIME, ARR_TIME, WHEELS_OFF, WHEELS_ON, TAXI_OUT, TAXI_IN, ACTUAL_ELAPSED_TIME, AIR_TIME
      </li>
      <li>
       Delay breakdowns: CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY
      </li>
      <li>
       Target leakage: ARR_DEL15, ARR_DELAY
      </li>
     </ul>
    </li>
    <li>
     Filtered cancelled flights (28,812 records) and diverted flights (589,138 records) as operationally distinct scenarios
    </li>
    <li>
     Applied 3-tier weather imputation strategy:
     <ul>
      <li>
       Tier 1: Actual observed value
      </li>
      <li>
       Tier 2: 24h rolling average by airport
      </li>
      <li>
       Tier 3: Global median
      </li>
     </ul>
    </li>
    <li>
     Result: 10.16% missing → 0.00% missing
    </li>
    <li>
     All 477,296 target variable nulls removed
    </li>
   </ul>
   <p>
    <strong>
     CP2 → CP3: Basic Feature Engineering (+36 features)
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Temporal Features (10):
     </strong>
     departure_hour, departure_month, departure_dayofweek, is_weekend, season, is_peak_hour, time-of-day categories, day/hour interaction
    </li>
    <li>
     <strong>
      Distance Features (6):
     </strong>
     log_distance, distance bins (very_long, etc.), DISTANCE_high_corr, DISTANCE_GROUP_high_corr
    </li>
    <li>
     <strong>
      Weather Features (3):
     </strong>
     weather_condition_category, temp_anomaly, sky_condition_parsed
    </li>
    <li>
     <strong>
      Rolling Metrics (10):
     </strong>
     rolling_origin_num_delays_24h, rolling_origin_delay_ratio_24h, dep_delay15_24h_rolling_avg variants by origin/carrier/dayofweek
    </li>
    <li>
     <strong>
      Geographic (3):
     </strong>
     airport_traffic_density, carrier_flight_count
    </li>
    <li>
     <strong>
      Other (4):
     </strong>
     is_superbowl_week, is_major_event, is_airport_maintenance, is_natural_disaster
    </li>
   </ul>
   <p>
    <strong>
     CP3 → CP4: Advanced Feature Engineering (+91 features)
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Weather Expansion (+19):
     </strong>
     Hourly wind direction, gust speed, relative humidity, station pressure, altimeter setting, additional weather composites
    </li>
    <li>
     <strong>
      Rolling Features (+12):
     </strong>
     30-day route delay rates, carrier delays at origin, same-day statistics, time-based congestion ratios
    </li>
    <li>
     <strong>
      RFM Features (13):
     </strong>
     days_since_last_delay_route, days_since_carrier_last_delay_at_origin, route_delays_30d, route_delay_rate_30d, carrier_delays_at_origin_30d, 1-year delay rates
    </li>
    <li>
     <strong>
      Interaction Terms (24):
     </strong>
     peak_hour × traffic, weekend × route_volume, weather × airport_delays, temp × holiday, carrier × hour, origin × weather/visibility/precipitation/wind, origin × dest, carrier × origin/dest
    </li>
    <li>
     <strong>
      Cyclic Encoding (14):
     </strong>
     dep_time_sin/cos, arr_time_sin/cos, day_of_week_sin/cos, month_sin/cos (7 pairs = 14 features)
    </li>
    <li>
     <strong>
      Network Features (8):
     </strong>
     origin_degree_centrality, dest_betweenness, delay_propagation_score, network_delay_cascade, origin_1yr_delay_rate, dest_1yr_delay_rate, dest_delay_rate_today
    </li>
    <li>
     <strong>
      Aircraft Lag (6):
     </strong>
     prev_flight_dep_del15, prev_flight_crs_elapsed_time, hours_since_prev_flight, turnaround_category, num_airport_wide_delays, oncoming_flights
    </li>
    <li>
     <strong>
      Breiman Meta-Features (2):
     </strong>
     rf_prob_delay, rf_prob_delay_binned
    </li>
   </ul>
   <p>
    <strong>
     CP4 → CP5: Feature Optimization and Reduction (-33 features)
    </strong>
   </p>
   <ul>
    <li>
     Removed high-correlation features (Pearson &gt;0.85): YEAR, QUARTER, DISTANCE_high_corr, DISTANCE_GROUP_high_corr, and 29 others
    </li>
    <li>
     Removed high-cardinality features: TAIL_NUM, FL_DATE, prediction_utc, origin_obs_utc, asof_minutes
    </li>
    <li>
     Removed duplicate features identified through analysis
    </li>
    <li>
     Removed low-importance features with zero contribution in preliminary models
    </li>
    <li>
     Result: 186 features → 153 features (18% reduction)
    </li>
   </ul>
   <p>
    <strong>
     CP5 → CP5a: String Indexing and Final Selection (-41 features, +12 indexed)
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      String Indexing (12 categorical features converted):
     </strong>
     <ul>
      <li>
       DEST_indexed, ORIGIN_indexed, OP_UNIQUE_CARRIER_indexed
      </li>
      <li>
       ORIGIN_STATE_ABR_indexed, DEST_STATE_ABR_indexed
      </li>
      <li>
       origin_type_indexed, season_indexed, weather_condition_category_indexed
      </li>
      <li>
       airline_reputation_category_indexed, turnaround_category_indexed
      </li>
      <li>
       day_hour_interaction_indexed, sky_condition_parsed_indexed
      </li>
     </ul>
    </li>
    <li>
     <strong>
      Removed 41 features:
     </strong>
     Original string columns retained for validation but removed from modeling set, plus additional low-importance features identified through feature importance analysis
    </li>
    <li>
     <strong>
      Final validation:
     </strong>
     Verified &lt;1% missing data (0.01%), confirmed zero leakage, validated all data types
    </li>
    <li>
     <strong>
      Result:
     </strong>
     153 features → 112 production-ready features (27% reduction from CP4)
    </li>
   </ul>
   <h5 id="Checkpoint-Strategy">
    Checkpoint Strategy
    <a class="anchor-link" href="#Checkpoint-Strategy">
     ¶
    </a>
   </h5>
   <p>
    All checkpoints are stored at
    <code>
     dbfs:/student-groups/Group_4_4/
    </code>
    with the following benefits:
   </p>
   <ul>
    <li>
     <strong>
      Resumability
     </strong>
     : Team members can start from any intermediate stage without re-running 6+ hour join operations on 31M records
    </li>
    <li>
     <strong>
      Debugging
     </strong>
     : Errors can be traced to specific pipeline stages with detailed logging at each checkpoint
    </li>
    <li>
     <strong>
      Collaboration
     </strong>
     : Multiple team members can work on different feature families simultaneously
    </li>
    <li>
     <strong>
      Version Control
     </strong>
     : Each checkpoint represents a stable, validated state of data transformation
    </li>
    <li>
     <strong>
      Computational Efficiency
     </strong>
     : Expensive operations (weather joins, rolling aggregations, network metrics) are computed once and cached
    </li>
    <li>
     <strong>
      Memory Management
     </strong>
     : Strategic caching, checkpointing, and unpersisting at each stage prevents out-of-memory errors on 31M+ row dataset
    </li>
    <li>
     <strong>
      Quality Assurance
     </strong>
     : Each checkpoint includes validation checks for missing data, duplicates, leakage, and data type consistency
    </li>
   </ul>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.4-Data-Quality-and-Missing-Data-Analysis">
    3.3.4 Data Quality and Missing Data Analysis
    <a class="anchor-link" href="#3.3.4-Data-Quality-and-Missing-Data-Analysis">
     ¶
    </a>
   </h4>
   <h5 id="Quality-Metrics-Across-Pipeline">
    Quality Metrics Across Pipeline
    <a class="anchor-link" href="#Quality-Metrics-Across-Pipeline">
     ¶
    </a>
   </h5>
   <p>
    Our systematic data processing pipeline achieved comprehensive quality improvement, reducing missing data from 49.39% to &lt;1% while preserving 98.3% of flight records from the raw OTPW source and ensuring zero data leakage.
   </p>
   <p>
    <strong>
     Table 3.4: Data Quality Metrics Across Pipeline Stages (2015-2019)
    </strong>
   </p>
   <div class="table-wrapper">
   <table>
    <thead>
     <tr>
      <th>
       Metric
      </th>
      <th>
       Stage 0: Raw
      </th>
      <th>
       CP1: Initial
      </th>
      <th>
       CP2: Cleaned
      </th>
      <th>
       CP3: Basic
      </th>
      <th>
       CP4: Advanced
      </th>
      <th>
       CP5: Comprehensive
      </th>
      <th>
       CP5a: Final
      </th>
      <th>
       Improvement
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        File Name
       </strong>
      </td>
      <td>
       OTPW_60M_Backup/
      </td>
      <td>
       checkpoint_1_initial_joined_5Y_2015-2019.parquet
      </td>
      <td>
       checkpoint_2_cleaned_imputed_2015-2019.parquet
      </td>
      <td>
       checkpoint_3_basic_features_2015-2019.parquet
      </td>
      <td>
       checkpoint_4_advanced_features_2015-2019.parquet
      </td>
      <td>
       checkpoint_5_comprehensive_2015-2019.parquet
      </td>
      <td>
       checkpoint_5a_final_clean_2015-2019.parquet
      </td>
      <td>
       —
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Total Rows
       </strong>
      </td>
      <td>
       31,673,119
      </td>
      <td>
       31,746,841
      </td>
      <td>
       31,128,891
      </td>
      <td>
       31,128,891
      </td>
      <td>
       31,128,891
      </td>
      <td>
       31,128,891
      </td>
      <td>
       <strong>
        31,128,891
       </strong>
      </td>
      <td>
       98.3% retained from Stage 0
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Rows Removed
       </strong>
      </td>
      <td>
       —
      </td>
      <td>
       +73,722
      </td>
      <td>
       -617,950
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       Cancelled/diverted/null-target only
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Data Retention
       </strong>
      </td>
      <td>
       100%
      </td>
      <td>
       100.2%
      </td>
      <td>
       98.1%
      </td>
      <td>
       100%
      </td>
      <td>
       100%
      </td>
      <td>
       100%
      </td>
      <td>
       <strong>
        100%
       </strong>
      </td>
      <td>
       98.3% from Stage 0
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Total Features
       </strong>
      </td>
      <td>
       214
      </td>
      <td>
       75
      </td>
      <td>
       59
      </td>
      <td>
       95
      </td>
      <td>
       186
      </td>
      <td>
       153
      </td>
      <td>
       <strong>
        112
       </strong>
      </td>
      <td>
       -102 net from Stage 0
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Missing Data %
       </strong>
      </td>
      <td>
       49.39%
      </td>
      <td>
       10.16%
      </td>
      <td>
       0.00%
      </td>
      <td>
       0.00%
      </td>
      <td>
       0.02%
      </td>
      <td>
       0.01%
      </td>
      <td>
       <strong>
        &lt;1%
       </strong>
      </td>
      <td>
       99.98% reduction
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Cols with Missing
       </strong>
      </td>
      <td>
       142
      </td>
      <td>
       51
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       6
      </td>
      <td>
       4
      </td>
      <td>
       <strong>
        4
       </strong>
      </td>
      <td>
       97.2% reduction
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Target Nulls
       </strong>
      </td>
      <td>
       475,789
      </td>
      <td>
       477,296
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       <strong>
        0
       </strong>
      </td>
      <td>
       Complete elimination
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Data Leakage Features
       </strong>
      </td>
      <td>
       N/A
      </td>
      <td>
       15
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       <strong>
        0
       </strong>
      </td>
      <td>
       All removed in CP2
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Categorical (unindexed)
       </strong>
      </td>
      <td>
       83
      </td>
      <td>
       21
      </td>
      <td>
       14
      </td>
      <td>
       14
      </td>
      <td>
       14
      </td>
      <td>
       12
      </td>
      <td>
       <strong>
        0
       </strong>
      </td>
      <td>
       All indexed in CP5a
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Duplicate Features
       </strong>
      </td>
      <td>
       N/A
      </td>
      <td>
       N/A
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       1
      </td>
      <td>
       <strong>
        0
       </strong>
      </td>
      <td>
       Identified and removed
      </td>
     </tr>
    </tbody>
   </table>
   </div>
   <h5 id="Row-Count-Evolution">
    Row Count Evolution
    <a class="anchor-link" href="#Row-Count-Evolution">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Stage 0 → CP1: Join Expansion (+73,722 rows, +0.2%)
    </strong>
   </p>
   <ul>
    <li>
     Raw OTPW contained 31,673,119 flight records
    </li>
    <li>
     Weather join added 73,722 rows due to multiple weather station matches per airport
    </li>
    <li>
     Some flights matched to backup weather stations when primary station data was unavailable
    </li>
    <li>
     This temporary expansion is expected behavior for left join with geographic proximity matching
    </li>
   </ul>
   <p>
    <strong>
     CP1 → CP2: Data Cleaning (-617,950 rows, -1.9%)
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Total rows removed:
     </strong>
     617,950 (1.95% of CP1)
    </li>
    <li>
     <strong>
      Breakdown:
     </strong>
     <ul>
      <li>
       Cancelled flights: ~141,000 records (estimated 0.44% of CP1)
      </li>
      <li>
       Diverted flights: ~98,000 records (estimated 0.31% of CP1)
      </li>
      <li>
       Target nulls (no delay status): 477,296 records (1.50% of CP1, includes overlap with cancelled/diverted)
      </li>
      <li>
       Invalid records (missing critical fields): remaining balance
      </li>
     </ul>
    </li>
    <li>
     <strong>
      Final retention:
     </strong>
     31,128,891 rows (98.05% of CP1, 98.28% of Stage 0)
    </li>
   </ul>
   <p>
    <strong>
     CP2 → CP5a: Feature Engineering (0 rows removed)
    </strong>
   </p>
   <ul>
    <li>
     All feature engineering stages preserved 100% of cleaned records
    </li>
    <li>
     Focus shifted from row filtering to column expansion and optimization
    </li>
    <li>
     Strict preservation ensures reproducibility and auditability
    </li>
   </ul>
   <h5 id="Cancelled-and-Diverted-Flights">
    Cancelled and Diverted Flights
    <a class="anchor-link" href="#Cancelled-and-Diverted-Flights">
     ¶
    </a>
   </h5>
   <p>
    Cancelled and diverted flights were filtered from the dataset during CP2 cleaning:
   </p>
   <ul>
    <li>
     <strong>
      Cancelled flights
     </strong>
     : ~141,000 records (0.44% of CP1, 2015-2019)
    </li>
    <li>
     <strong>
      Diverted flights
     </strong>
     : ~98,000 records (0.31% of CP1, 2015-2019)
    </li>
    <li>
     <strong>
      Total removed with nulls
     </strong>
     : 617,950 records (1.95% of CP1)
    </li>
   </ul>
   <p>
    <strong>
     Why Remove These Flights?
    </strong>
   </p>
   <p>
    Cancelled and diverted flights represent fundamentally different operational scenarios than delayed departures:
   </p>
   <ol>
    <li>
     <p>
      <strong>
       Cancelled flights
      </strong>
      never depart, making departure delay prediction undefined. Including them would require predicting whether a flight will be cancelled (a different binary task) rather than whether a departing flight will be delayed.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Diverted flights
      </strong>
      involve mid-flight operational decisions (weather, medical emergencies, mechanical issues) that cannot be predicted at the T-2 hour departure window. Their "departure delay" may be minimal, but they don't arrive at the intended destination.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Target variable integrity
      </strong>
      : DEP_DEL15 is undefined or irrelevant for cancelled flights (no departure occurred) and misleading for diverted flights (successful departure but operational failure).
     </p>
    </li>
   </ol>
   <p>
    By filtering these records, we ensure our model focuses exclusively on
    <strong>
     flights that departed as scheduled to their intended destination
    </strong>
    , making predictions directly actionable for operational decision-making around crew scheduling, gate assignments, and passenger notifications.
   </p>
   <h5 id="Missing-Data-Reduction-Strategy">
    Missing Data Reduction Strategy
    <a class="anchor-link" href="#Missing-Data-Reduction-Strategy">
     ¶
    </a>
   </h5>
   <p>
    Our three-tier imputation approach systematically eliminated missing data across 5 years:
   </p>
   <p>
    <strong>
     Stage 0: Raw OTPW
    </strong>
   </p>
   <ul>
    <li>
     142 of 214 columns contained missing values
    </li>
    <li>
     Primary sources: weather features not yet joined, optional OTPW fields
    </li>
    <li>
     475,789 flights missing DEP_DEL15 target variable
    </li>
   </ul>
   <p>
    <strong>
     CP1: After Weather Join
    </strong>
   </p>
   <ul>
    <li>
     Weather join reduced missing data significantly
    </li>
    <li>
     51 of 75 columns still contained missing values
    </li>
    <li>
     Remaining gaps: weather observations outside T-2 hour window, station outages
    </li>
    <li>
     477,296 flights still missing DEP_DEL15
    </li>
   </ul>
   <p>
    <strong>
     CP2: Three-Tier Imputation
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Tier 1 (Preferred):
     </strong>
     Use actual observed weather value from matched station
    </li>
    <li>
     <strong>
      Tier 2 (Historical):
     </strong>
     Use 24-hour rolling average by airport if no observation within T-2 window
    </li>
    <li>
     <strong>
      Tier 3 (Global):
     </strong>
     Use global median for weather variable if no historical data available
    </li>
    <li>
     <strong>
      Categorical nulls:
     </strong>
     Replace with 'UNK' indicator to preserve missingness signal
    </li>
    <li>
     <strong>
      Target variable:
     </strong>
     Remove all 477,296 records with null DEP_DEL15 (overlap with cancelled/diverted)
    </li>
    <li>
     <strong>
      Result:
     </strong>
     Complete elimination of missing values across all 59 columns
    </li>
   </ul>
   <p>
    <strong>
     CP3-CP4: Minimal Missing from New Features
    </strong>
   </p>
   <ul>
    <li>
     Basic features (CP3): No missing values (all derived from complete CP2 data)
    </li>
    <li>
     Advanced features (CP4): Minimal missing in 6 RFM features
     <ul>
      <li>
       Missing occurs for first flights on routes (no historical delay data)
      </li>
      <li>
       Represents edge case: route's inaugural flight or first flight after long gap
      </li>
      <li>
       Strategy: Impute with carrier-average or route-average from similar distances
      </li>
     </ul>
    </li>
   </ul>
   <p>
    <strong>
     CP5-CP5a: Production Quality
    </strong>
   </p>
   <ul>
    <li>
     CP5: Minimal missing in 4 features (same_day_prior_delay_percentage, dest_delay_rate_today, route_delays_30d, carrier_delays_at_origin_30d)
    </li>
    <li>
     CP5a: Less than 1% missing maintained (563,214 nulls in same_day_prior_delay_percentage = 1.81% of rows)
    </li>
    <li>
     <strong>
      Strategic decision:
     </strong>
     Retain minimal missing in temporal features as signal (first flight of day, new route)
    </li>
    <li>
     <strong>
      Modeling approach:
     </strong>
     Tree-based models handle these naturally; for linear models, impute with 0 or create is_missing indicator
    </li>
   </ul>
   <h5 id="Data-Quality-Validation-Checks">
    Data Quality Validation Checks
    <a class="anchor-link" href="#Data-Quality-Validation-Checks">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Checkpoint 2 Validation (Post-Cleaning):
    </strong>
   </p>
   <ul>
    <li>
     Zero missing values in core features (ORIGIN, DEST, OP_UNIQUE_CARRIER, FL_DATE)
    </li>
    <li>
     Zero missing values in target variable (DEP_DEL15)
    </li>
    <li>
     All weather features imputed (15 features complete)
    </li>
    <li>
     All geographic features complete (20 features)
    </li>
    <li>
     No duplicate records (verified via FL_DATE + OP_CARRIER_FL_NUM + ORIGIN + DEST)
    </li>
    <li>
     Date range validated: 2015-01-01 to 2019-12-31 (no out-of-range dates)
    </li>
    <li>
     All numeric features within expected ranges (temperature: -50°F to 130°F, etc.)
    </li>
   </ul>
   <p>
    <strong>
     Checkpoint 5a Validation (Production-Ready):
    </strong>
   </p>
   <ul>
    <li>
     99.99% data completeness (0.01% missing in 4 temporal features by design)
    </li>
    <li>
     All categorical features indexed (12 indexed columns)
    </li>
    <li>
     Zero data leakage (all features validated against T-2 hour cutoff)
    </li>
    <li>
     All date/time features in UTC (timezone consistency)
    </li>
    <li>
     Target variable complete with valid class balance (81.85% / 18.15%)
    </li>
    <li>
     No high-correlation features remaining (Pearson &gt;0.85 removed)
    </li>
   </ul>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Missing-Data-Breakdown-by-Feature-Category-(CP1)">
    Missing Data Breakdown by Feature Category (CP1)
    <a class="anchor-link" href="#Missing-Data-Breakdown-by-Feature-Category-(CP1)">
     ¶
    </a>
   </h5>
   <p>
    After the initial weather join (CP1), missing data was reduced from 49.39% (Stage 0) to 10.16%, concentrated in specific feature categories:
   </p>
   <p>
    <strong>
     Table 3.5: Missing Data by Category (CP1 - Post-Weather Join)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Category
      </th>
      <th>
       Features Affected
      </th>
      <th>
       Missing Rate
      </th>
      <th>
       Reason for Missingness
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Weather (High)
       </strong>
      </td>
      <td>
       HourlyWindGustSpeed
      </td>
      <td>
       78%
      </td>
      <td>
       Gusts only recorded during high-wind events; calm conditions have no gust measurement
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Weather (High)
       </strong>
      </td>
      <td>
       HourlyPresentWeatherType
      </td>
      <td>
       62%
      </td>
      <td>
       Weather type codes only populated when specific conditions (rain, fog, snow) are present; clear weather often left blank
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Weather (Moderate)
       </strong>
      </td>
      <td>
       HourlyPrecipitation
      </td>
      <td>
       15%
      </td>
      <td>
       Precipitation only recorded when measurable; dry periods have null entries
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Weather (Low)
       </strong>
      </td>
      <td>
       HourlyDryBulbTemperature, HourlyDewPointTemperature, HourlyVisibility
      </td>
      <td>
       2-5%
      </td>
      <td>
       Occasional sensor failures or station maintenance periods
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Delay Breakdowns
       </strong>
      </td>
      <td>
       CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY
      </td>
      <td>
       80%
      </td>
      <td>
       By design—only populated when delays occur and causes are attributed; removed in CP2 as leakage features
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Target Variable
       </strong>
      </td>
      <td>
       DEP_DEL15
      </td>
      <td>
       1.5% (477,296 nulls)
      </td>
      <td>
       Cancelled/diverted flights have no departure delay to measure; removed in CP2
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Core Identifiers
       </strong>
      </td>
      <td>
       FL_DATE, CRS_DEP_TIME, ORIGIN, DEST, OP_UNIQUE_CARRIER
      </td>
      <td>
       &lt;0.01%
      </td>
      <td>
       Essential flight identifiers rarely missing
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Understanding-Weather-Data-Missingness">
    Understanding Weather Data Missingness
    <a class="anchor-link" href="#Understanding-Weather-Data-Missingness">
     ¶
    </a>
   </h5>
   <p>
    Weather observations are
    <strong>
     event-driven rather than continuous
    </strong>
    . NOAA stations report certain conditions only when they occur, making missingness informative:
   </p>
   <ul>
    <li>
     <p>
      <strong>
       Wind gusts
      </strong>
      are only measured when gusts exceed sustained wind speed thresholds. Null values typically indicate calm conditions rather than missing observations.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Present weather types
      </strong>
      (rain, fog, thunderstorm codes) are only logged during active weather events. Clear, calm weather often results in null entries rather than explicit "clear" codes.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Precipitation amounts
      </strong>
      are null during dry periods rather than recorded as zero. This follows meteorological convention where absence of measurement indicates absence of precipitation.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Remote airports
      </strong>
      have limited weather station coverage, leading to temporal gaps where the nearest station is beyond the reliable proximity threshold.
     </p>
    </li>
   </ul>
   <p>
    This pattern means that missing weather data often indicates benign conditions rather than data quality issues. Our three-tier imputation strategy accounts for this by using historical patterns at the same airport before falling back to global medians.
   </p>
   <h5 id="Imputation-Results">
    Imputation Results
    <a class="anchor-link" href="#Imputation-Results">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Features Requiring Imputation (15 weather features):
    </strong>
   </p>
   <ul>
    <li>
     Temperature: HourlyDryBulbTemperature, HourlyDewPointTemperature, HourlyWetBulbTemperature
    </li>
    <li>
     Precipitation: HourlyPrecipitation
    </li>
    <li>
     Wind: HourlyWindSpeed, HourlyWindDirection, HourlyWindGustSpeed
    </li>
    <li>
     Visibility: HourlyVisibility
    </li>
    <li>
     Atmospheric: HourlyRelativeHumidity, HourlyStationPressure, HourlySeaLevelPressure, HourlyAltimeterSetting
    </li>
    <li>
     Conditions: HourlyPresentWeatherType, HourlySkyConditions, HourlyDryBulbTemperature
    </li>
   </ul>
   <p>
    <strong>
     Imputation Coverage (CP2):
    </strong>
   </p>
   <ul>
    <li>
     Tier 1 (Actual observed): Approximately 90% of values used as-is
    </li>
    <li>
     Tier 2 (24h rolling average): Approximately 8% imputed from historical airport data
    </li>
    <li>
     Tier 3 (Global median): Approximately 2% imputed from overall distribution
    </li>
    <li>
     Result: 10.16% missing (CP1) → 0.00% missing (CP2)
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.5-Target-Variable-and-Class-Balance">
    3.3.5 Target Variable and Class Balance
    <a class="anchor-link" href="#3.3.5-Target-Variable-and-Class-Balance">
     ¶
    </a>
   </h4>
   <h5 id="Target-Definition">
    Target Definition
    <a class="anchor-link" href="#Target-Definition">
     ¶
    </a>
   </h5>
   <p>
    Our binary classification task predicts
    <strong>
     DEP_DEL15
    </strong>
    , where:
   </p>
   <ul>
    <li>
     <strong>
      DEP_DEL15 = 1
     </strong>
     : Flight delayed ≥15 minutes from scheduled departure
    </li>
    <li>
     <strong>
      DEP_DEL15 = 0
     </strong>
     : Flight on-time (delayed &lt;15 minutes)
    </li>
   </ul>
   <p>
    This 15-minute threshold aligns with the U.S. Department of Transportation's official definition of flight delay used in carrier performance reporting.
   </p>
   <p>
    <strong>
     Table 3.5: Target Variable Distribution
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Class
      </th>
      <th>
       Count
      </th>
      <th>
       Percentage
      </th>
      <th>
       Description
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        On-Time (0)
       </strong>
      </td>
      <td>
       4,655,123
      </td>
      <td>
       81.61%
      </td>
      <td>
       Flights departing &lt;15min late
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Delayed (1)
       </strong>
      </td>
      <td>
       1,048,991
      </td>
      <td>
       18.39%
      </td>
      <td>
       Flights departing ≥15min late
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Total
       </strong>
      </td>
      <td>
       5,704,114
      </td>
      <td>
       100.00%
      </td>
      <td>
       Complete 2015 dataset
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Imbalance Ratio:
    </strong>
    4.44:1 (on-time : delayed)
   </p>
   <h5 id="Class-Imbalance-Mitigation-Strategies">
    Class Imbalance Mitigation Strategies
    <a class="anchor-link" href="#Class-Imbalance-Mitigation-Strategies">
     ¶
    </a>
   </h5>
   <p>
    The 4.44:1 imbalance is substantial but manageable through multiple complementary approaches:
   </p>
   <ol>
    <li>
     <p>
      <strong>
       SMOTE Undersampling (Current Approach):
      </strong>
      We apply undersampling of the majority class (on-time flights) to training data only, creating a more balanced training set while preserving the original test distribution for realistic evaluation.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Class Weighting (Previously Tested):
      </strong>
      We initially experimented with inverse frequency weights during model training (weight_0 = 1.0, weight_1 = 4.44), but found SMOTE undersampling provided better results for our use case.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Threshold Tuning:
      </strong>
      Adjust decision threshold from default 0.5 to optimize F₀.₅-score based on precision-recall trade-offs.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Ensemble Methods:
      </strong>
      Tree-based models (Random Forest, Gradient Boosting) naturally handle imbalance via sample weighting and bagging.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Evaluation Metrics:
      </strong>
      Prioritize F₀.₅-score, precision, and precision-recall AUC over accuracy to avoid majority-class bias.
     </p>
    </li>
   </ol>
   <p>
    <strong>
     Business Justification:
    </strong>
    From a business perspective, false negatives (predicting on-time when actually delayed) are more costly than false positives. Airlines can proactively notify passengers, adjust crew scheduling, and optimize aircraft rotation when delays are predicted, even if some predictions are false alarms. Therefore, we optimize for high recall on the delayed class.
   </p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.6--Data-Results---Exploratory-Data-Analysis">
    3.3.6  Data Results - Exploratory Data Analysis
    <a class="anchor-link" href="#3.3.6--Data-Results---Exploratory-Data-Analysis">
     ¶
    </a>
   </h4>
   <p>
    Our EDA reveals critical patterns in temporal dynamics, carrier performance, geographic distributions, and distance effects that inform feature engineering and modeling strategies.
   </p>
   <h5 id="Temporal-Patterns">
    Temporal Patterns
    <a class="anchor-link" href="#Temporal-Patterns">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_001_3aba5043.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <strong>
     Table 3.6: Key Temporal Insights (2015-2019 Analysis)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Pattern
      </th>
      <th>
       Finding
      </th>
      <th>
       Implication for Modeling
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Quarterly Seasonality
       </strong>
      </td>
      <td>
       Delay rates vary from 16.30% (Q4) to 19.39% (Q2)
      </td>
      <td>
       Summer travel period (Q2) shows highest delay rates; winter holiday season (Q4) has lowest rates; quarterly features essential for capturing seasonal patterns
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Day-of-Week Effects
       </strong>
      </td>
      <td>
       Friday (19.74%) highest; Saturday lowest (16.21%); 3.53pp spread
      </td>
      <td>
       End-of-week travel concentration creates congestion; day-of-week features critical for distinguishing business vs. leisure travel patterns
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Within-Day Accumulation
       </strong>
      </td>
      <td>
       Delay rates increase from ~6-7% (6AM-noon) to 26.21% by 11PM (19pp increase)
      </td>
      <td>
       Delays cascade through the day due to aircraft rotation and airport congestion; time-of-day features and rolling delay metrics are critical for capturing this accumulation effect
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Flight Volume Pattern
       </strong>
      </td>
      <td>
       Peak departures 10AM-8PM (~1,900k flights/hour); lower overnight and early morning
      </td>
      <td>
       Volume correlates with delay accumulation; congestion features should capture hourly traffic density relative to airport capacity
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Weekend vs. Weekday
       </strong>
      </td>
      <td>
       Weekday delays (18.49%) exceed weekend (17.21%) by 1.28pp
      </td>
      <td>
       Higher operational tempo during business days creates more opportunities for cascading delays; weekend indicator helps model adjust expectations
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Year-over-Year Variation
       </strong>
      </td>
      <td>
       Delay rates range from 17.12% (2016) to 19.08% (2017); 1.96pp spread
      </td>
      <td>
       Year-to-year variation suggests temporal trends and operational changes; year features or temporal validation splits necessary
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Peak Delay Hour
       </strong>
      </td>
      <td>
       Hour 23 (11PM) shows highest delay rate at 26.21%
      </td>
      <td>
       Late evening flights accumulate delays from entire day's operations; hour-of-day cyclic encoding captures non-linear temporal patterns
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Cumulative Distribution
       </strong>
      </td>
      <td>
       50% of total delays occur by hour 16 (4PM)
      </td>
      <td>
       Morning and afternoon operations are critical for overall delay management; models should weight early-day predictions appropriately
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Overall Dataset Characteristics:
    </strong>
   </p>
   <ul>
    <li>
     Total flights analyzed: 31,128,891 (2015-2019)
    </li>
    <li>
     Overall delay rate: 18.15%
    </li>
    <li>
     Best performing day: Saturday (16.21% delay rate)
    </li>
    <li>
     Worst performing day: Friday (19.74% delay rate)
    </li>
    <li>
     Lowest delay quarter: Q4 (16.30%)
    </li>
    <li>
     Highest delay quarter: Q2 (19.39%)
    </li>
   </ul>
   <h5 id="Carrier-Performance">
    Carrier Performance
    <a class="anchor-link" href="#Carrier-Performance">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_002_f3b0aec3.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <strong>
     Table 3.7: Key Carrier Insights
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Pattern
      </th>
      <th>
       Finding
      </th>
      <th>
       Implication for Modeling
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Carrier Delay Rate Spread
       </strong>
      </td>
      <td>
       Delay rates range from 7.61% (HA) to 25.01% (B6); 17.4pp spread
      </td>
      <td>
       Massive carrier-specific performance differences; carrier features and carrier-specific interactions essential for accurate predictions
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Volume-Performance Relationship
       </strong>
      </td>
      <td>
       Large carriers show varying performance: DL (4.6M flights, 14.24%) vs. WN (6.5M flights, 21.06%)
      </td>
      <td>
       High volume does not predict high delays; carrier operational efficiency varies; volume × carrier interaction terms needed
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Best Performers (Low Delay)
       </strong>
      </td>
      <td>
       HA: 7.61% (0.9M flights), AS: 12.81% (1.0M flights), DL: 14.24% (4.6M flights)
      </td>
      <td>
       Regional/hub-focused carriers (HA, AS) and efficient network carriers (DL) outperform; carrier reputation features capture operational quality
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Worst Performers (High Delay)
       </strong>
      </td>
      <td>
       B6: 25.01% (1.4M flights), F9: 24.39% (0.9M flights), VX: 24.39% (1.4M flights)
      </td>
      <td>
       Low-cost and point-to-point carriers show higher delay rates; budget carrier indicator or carrier category features may improve predictions
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Market Concentration
       </strong>
      </td>
      <td>
       Top 3 carriers (WN, DL, AA) represent 49.6% of flights; "Others" represent 30.2%
      </td>
      <td>
       Model must handle both major carriers (dense data) and regional carriers (sparse data); carrier encoding strategy critical for generalization
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Delay Duration Variance
       </strong>
      </td>
      <td>
       Average delay ranges from ~8 minutes (HA) to ~14 minutes (F9, B6, VX)
      </td>
      <td>
       Carrier-specific delay severity patterns; two-stage models (delay occurrence + duration) should incorporate carrier-specific duration features
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Performance Consistency
       </strong>
      </td>
      <td>
       DL, HA, AS show consistent low delays; B6, F9, VX consistently high
      </td>
      <td>
       Carrier reliability score features capture persistent operational differences; historical carrier performance predicts future delays
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Hub vs. Point-to-Point
       </strong>
      </td>
      <td>
       Network carriers (DL, AA, UA) show varied performance; point-to-point (WN) shows moderate delays
      </td>
      <td>
       Network structure affects delay propagation; carrier type and hub airport features capture operational model differences
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Overall Carrier Characteristics:
    </strong>
   </p>
   <ul>
    <li>
     Total carriers analyzed: 19 distinct operators (2015-2019)
    </li>
    <li>
     Overall delay rate: 18.03%
    </li>
    <li>
     Best performing carrier: Hawaiian Airlines (HA) - 7.61% delay rate
    </li>
    <li>
     Worst performing carrier: JetBlue (B6) - 25.01% delay rate
    </li>
    <li>
     Largest carrier by volume: Southwest (WN) - 6.5M flights (20.8% market share)
    </li>
    <li>
     Most efficient large carrier: Delta (DL) - 4.6M flights with 14.24% delay rate
    </li>
    <li>
     Carrier performance spread: 17.4 percentage points (HA to B6)
    </li>
   </ul>
   <h5 id="Geographic-Patterns">
    Geographic Patterns
    <a class="anchor-link" href="#Geographic-Patterns">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_003_3032a6d8.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <strong>
     Table 3.8: Key Geographic Performance Insights (2015-2019 Analysis)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Pattern
      </th>
      <th>
       Finding
      </th>
      <th>
       Implication for Modeling
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        State Volume Concentration
       </strong>
      </td>
      <td>
       Top 5 states (CA, TX, FL, GA, IL) account for ~40% of all flights
      </td>
      <td>
       Geographic features must handle concentrated and sparse regions; state-level aggregates provide valuable signal for high-volume areas
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Airport Delay Rate Spread
       </strong>
      </td>
      <td>
       Airport delay rates range from ~13% to ~24%; 11pp spread across top 30 airports
      </td>
      <td>
       Airport-specific operational efficiency varies dramatically; origin and destination airport features critical for predictions
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Worst Performing Airports
       </strong>
      </td>
      <td>
       MDW (~24%), DAL (~24%), EWR (~23%), FLL (~23%), LGA (~23%)
      </td>
      <td>
       Congested urban airports and secondary hubs show highest delays; airport congestion metrics and infrastructure quality features needed
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Best Performing Major Airports
       </strong>
      </td>
      <td>
       HNL (~13%), SLC, SEA show lowest delay rates among high-traffic airports
      </td>
      <td>
       Demonstrates that high volume doesn't require high delays; airport efficiency captured by congestion ratio and operational quality features
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Volume-Delay Relationship
       </strong>
      </td>
      <td>
       No simple correlation—some high-volume airports (ATL) maintain moderate delays while smaller airports (MDW) show high delays
      </td>
      <td>
       Airport delay rates depend on infrastructure, weather exposure, and operational practices, not just volume; network centrality and congestion features capture these dynamics
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Hub Airport Patterns
       </strong>
      </td>
      <td>
       Major hubs (ATL, ORD, DFW, LAX) show 18-22% delay rates despite highest volumes
      </td>
      <td>
       Hub complexity creates delay opportunities but also operational expertise; hub indicator features and network centrality metrics capture systemic effects
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        State-Level Distribution
       </strong>
      </td>
      <td>
       Mean delay rate ~18%; median ~18%; majority of states cluster 15-20%
      </td>
      <td>
       Regional weather patterns and operational environments create state-level effects; most states perform near national average with notable outliers
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Geographic Clustering
       </strong>
      </td>
      <td>
       Northeast corridor (EWR, LGA, JFK, BOS, PHL) consistently shows elevated delays (20-24%)
      </td>
      <td>
       Regional congestion affects multiple airports; geographic region features and inter-airport network effects important for modeling
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        High Volume States
       </strong>
      </td>
      <td>
       CA (~3.5M flights), TX, FL lead in volume; CA shows internal variance across airports
      </td>
      <td>
       State alone insufficient predictor; airport-level granularity required; state × airport interactions capture regional + local effects
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Overall Geographic Characteristics:
    </strong>
   </p>
   <ul>
    <li>
     Total states analyzed: 53 (all US states + territories, 2015-2019)
    </li>
    <li>
     Total unique airports: 369 origins, 368 destinations
    </li>
    <li>
     State delay rate mean: ~18%
    </li>
    <li>
     State delay rate median: ~18%
    </li>
    <li>
     Highest volume state: California (CA) - ~3.5M flights
    </li>
    <li>
     Worst performing airports: MDW, DAL, EWR, FLL, LGA (~23-24% delay rates)
    </li>
    <li>
     Best performing major airport: Honolulu (HNL) - ~13% delay rate
    </li>
    <li>
     Northeast corridor delay premium: 2-5pp above national average
    </li>
    <li>
     Airport delay spread: ~11 percentage points across top performers
    </li>
   </ul>
   <hr/>
   <h5 id="Distance-and-Flight-Duration">
    Distance and Flight Duration
    <a class="anchor-link" href="#Distance-and-Flight-Duration">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Table 3.9: Distance and Duration Analysis (2015-2019)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Metric
      </th>
      <th>
       Value
      </th>
      <th>
       Implication for Modeling
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Distance Range
       </strong>
      </td>
      <td>
       31 miles (shortest) to 4,983 miles (longest)
      </td>
      <td>
       Wide range requires non-linear distance features (log transformation, categorical bins); log_distance feature created
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Average Scheduled Duration
       </strong>
      </td>
      <td>
       ~130 minutes
      </td>
      <td>
       Short-haul vs. long-haul distinction affects operational dynamics and turnaround constraints
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Short-Haul Delay Pattern
       </strong>
      </td>
      <td>
       Shorter flights show higher proportional delay impact
      </td>
      <td>
       15-minute delays represent larger percentage of total flight time for short routes; tighter turnarounds create more delay propagation risk
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Distance Categories
       </strong>
      </td>
      <td>
       Created bins: very_short, short, medium, long, very_long
      </td>
      <td>
       distance_very_long and categorical features capture non-linear relationship between distance and delay patterns
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Distance-Weather Interaction
       </strong>
      </td>
      <td>
       Long-distance flights cross multiple weather systems
      </td>
      <td>
       Distance × weather interaction terms capture compounding effects of weather across route length
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Weather-Impact-Patterns">
    Weather Impact Patterns
    <a class="anchor-link" href="#Weather-Impact-Patterns">
     ¶
    </a>
   </h5>
   <p>
    Correlation analysis between weather features and delays from 5-year dataset:
   </p>
   <p>
    <strong>
     Table 3.10: Weather Feature Correlations with DEP_DEL15
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Correlation
      </th>
      <th>
       Interpretation
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        HourlyVisibility
       </strong>
      </td>
      <td>
       -0.035
      </td>
      <td>
       Lower visibility associated with higher delays; fog and low clouds directly impact airport operations and departure clearances
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        HourlyDryBulbTemperature
       </strong>
      </td>
      <td>
       -0.022
      </td>
      <td>
       Slight negative correlation overall but U-shaped pattern; extreme temperatures (below 25°F or above 90°F) show elevated delays
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        HourlyDewPointTemperature
       </strong>
      </td>
      <td>
       +0.022
      </td>
      <td>
       Higher dew point (humidity) associated with marginally higher delays; affects aircraft performance and ground operations
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        HourlyWindGustSpeed
       </strong>
      </td>
      <td>
       Moderate positive
      </td>
      <td>
       High wind gusts increase delays through crosswind limitations, ground operation slowdowns, and turbulence-related holds
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        HourlyPrecipitation
       </strong>
      </td>
      <td>
       Weak positive
      </td>
      <td>
       Precipitation increases delay likelihood through ground operations slowdowns, de-icing requirements, and runway capacity reduction
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Weather Severity Index
       </strong>
      </td>
      <td>
       Composite measure
      </td>
      <td>
       Multi-factor weather severity combining temperature, wind, precipitation, visibility shows stronger predictive power than individual features
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Key Weather Insights:
    </strong>
   </p>
   <ul>
    <li>
     Individual weather features show
     <strong>
      weak to moderate correlations
     </strong>
     (-0.04 to +0.05), suggesting weather is a contributing but not dominant factor
    </li>
    <li>
     <strong>
      Extreme values
     </strong>
     matter more than means: temperatures below 25°F and wind gusts above 30 units show disproportionate delay impact
    </li>
    <li>
     <strong>
      Composite weather features
     </strong>
     (weather_condition_category, temp_anomaly) capture non-linear relationships better than raw measurements
    </li>
    <li>
     <strong>
      Weather × airport interactions
     </strong>
     are critical: same weather conditions affect airports differently based on infrastructure and operational capacity
    </li>
    <li>
     Emphasizes need for comprehensive feature engineering capturing
     <strong>
      operational factors
     </strong>
     (aircraft history, airport congestion, time-of-day, carrier performance) alongside weather conditions
    </li>
   </ul>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.7-Custom-Flights-to-Weather-Join">
    3.3.7 Custom Flights to Weather Join
    <a class="anchor-link" href="#3.3.7-Custom-Flights-to-Weather-Join">
     ¶
    </a>
   </h4>
   <h5 id="Entity-Relationship-Model">
    Entity-Relationship Model
    <a class="anchor-link" href="#Entity-Relationship-Model">
     ¶
    </a>
   </h5>
   <p>
    The following diagram illustrates the relationships between our core data entities used for enriching flight records with meteorological data:
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_004_f2c152f1.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Data-Integration-Challenges">
    Data Integration Challenges
    <a class="anchor-link" href="#Data-Integration-Challenges">
     ¶
    </a>
   </h5>
   <p>
    Our exploratory review identified key blockers in the lookup tables rather than the flights themselves. These challenges were addressed once in Phase 2 and scaled to 31M records in Phase 3:
   </p>
   <p>
    <strong>
     Table 3.11: Data Integration Challenges and Solutions
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Challenge
      </th>
      <th>
       Problem
      </th>
      <th>
       Solution
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Missing Timezones
       </strong>
      </td>
      <td>
       Original airport codes file lacks timezones; flight local times cannot align to UTC weather
      </td>
      <td>
       Build master airport dimension by joining GitHub timezone data with existing codes; coalesce coordinates so every IATA has timezone, lat/lon, and name
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Coordinate Parsing
       </strong>
      </td>
      <td>
       Airport geolocation packed as single text field ("lon, lat")
      </td>
      <td>
       Parse and standardize lat/lon for all 369 origin and 368 destination airports
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Station-Based Weather
       </strong>
      </td>
      <td>
       NOAA data is station-based, not airport-based; no native key for airport-to-weather connection
      </td>
      <td>
       Compute airport → nearest 3 stations using haversine distance; store in airport_weather_station bridge table covering 634 NOAA stations
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Station ID Normalization
       </strong>
      </td>
      <td>
       Stations come from two slightly different sources (weather.csv vs stations.csv)
      </td>
      <td>
       Normalize station identifiers across sources; validate station codes across 5-year period
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Time Alignment
       </strong>
      </td>
      <td>
       Weather is UTC while flights are local time; some flights depart at odd minutes (e.g., 01:59) where no weather row exists
      </td>
      <td>
       Convert flight times to UTC using airport timezone; floor to hour with 1-hour fallback to nearest observation
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Odd Minute Departures
       </strong>
      </td>
      <td>
       Flights at 01:55 or 01:59 have no matching hourly weather observation
      </td>
      <td>
       Date-trunc to hour and/or fallback 1 hour to avoid nulls; preserve asof_minutes for transparency
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Destination Weather Leakage
       </strong>
      </td>
      <td>
       Destination weather observations could leak future information at arrival time
      </td>
      <td>
       Only keep origin weather observations where obs_time_utc ≤ prediction_utc (T-2h cutoff enforced)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Multi-Year Scaling
       </strong>
      </td>
      <td>
       Join logic must scale from 5.7M (2015) to 31.7M (2015-2019) records
      </td>
      <td>
       Partition by year, checkpoint intermediate results, cache frequent lookups (airport dimension, station bridge)
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="As-Of-Join-Logic">
    As-Of Join Logic
    <a class="anchor-link" href="#As-Of-Join-Logic">
     ¶
    </a>
   </h5>
   <p>
    Our custom, leakage-safe join combines DOT on-time performance with NOAA Global Hourly weather at the origin airport as-of T-2h before scheduled departure. This join was executed on 31.7M raw OTPW records, producing 31.7M joined records in CP1.
   </p>
   <p>
    <strong>
     Join Algorithm (T-2 Hour Weather Alignment):
    </strong>
   </p>
   <ol>
    <li>
     <strong>
      Normalize flight times
     </strong>
     using master airports dimension (IATA, timezone, lat/lon for 369 airports)
    </li>
    <li>
     <strong>
      Convert scheduled departure to UTC
     </strong>
     for weather alignment:
     <code>
      prediction_utc = scheduled_dep_local - 2h → UTC
     </code>
    </li>
    <li>
     <strong>
      Link airports to nearest 3 NOAA stations
     </strong>
     via haversine distance (634 total stations, average 2.1 stations/airport)
    </li>
    <li>
     <strong>
      Filter to valid hourly report types
     </strong>
     (FM-15, FM-16, FM-12) from NOAA ISD format
    </li>
    <li>
     <strong>
      Apply strict as-of rule
     </strong>
     :
     <code>
      obs_utc ≤ prediction_utc
     </code>
     with 6-hour lookback window
    </li>
    <li>
     <strong>
      Select latest qualifying observation
     </strong>
     , preferring station rank 1 → 2 → 3 based on proximity
    </li>
    <li>
     <strong>
      Preserve provenance fields
     </strong>
     : station_id, origin_obs_utc, origin_station_dis, asof_minutes
    </li>
    <li>
     <strong>
      Select only T-2h valid features
     </strong>
     : visibility, wind speed/direction/gusts, precipitation, temperature, humidity, pressure, sky conditions
    </li>
    <li>
     <strong>
      Exclude all leakage features
     </strong>
     : actual departure/arrival times, taxi times, delay cause breakdowns, cancelled/diverted status
    </li>
   </ol>
   <p>
    <strong>
     Join Statistics (2015-2019):
    </strong>
   </p>
   <ul>
    <li>
     Input rows (Stage 0 OTPW): 31,673,119
    </li>
    <li>
     Output rows (CP1): 31,746,841 (+73,722 rows, +0.2%)
    </li>
    <li>
     Row expansion: Some flights matched to multiple backup weather stations when primary station had missing observations
    </li>
    <li>
     Weather match rate: ~99.8% of flights successfully matched to at least one weather observation within 6-hour window
    </li>
    <li>
     Average asof_minutes: ~45 minutes (weather observation typically 30-60 minutes before T-2h cutoff)
    </li>
    <li>
     Missing weather features after join: 10.16% (down from 49.39% in Stage 0)
    </li>
    <li>
     Stations utilized: 634 NOAA stations across US
    </li>
    <li>
     Airports covered: 369 origin, 368 destination
    </li>
   </ul>
   <p>
    <strong>
     Performance Optimizations for 31M Records:
    </strong>
   </p>
   <ul>
    <li>
     Airport dimension broadcast join (small lookup table ~500 rows)
    </li>
    <li>
     Weather data partitioned by year and month for efficient temporal filtering
    </li>
    <li>
     Station bridge table cached (airport-to-station mappings computed once)
    </li>
    <li>
     Haversine distance calculations vectorized using PySpark UDFs
    </li>
    <li>
     Checkpoint after join to prevent recomputation (CP1 saved)
    </li>
    <li>
     Processing time: ~6 hours on 8-node cluster
    </li>
   </ul>
   <p>
    <strong>
     Phase 2 Deliverables:
    </strong>
   </p>
   <ul>
    <li>
     Custom join notebook implementing T-2h weather alignment
    </li>
    <li>
     Airport dimension table with timezone/coordinate enrichment
    </li>
    <li>
     Airport-to-station bridge table with haversine distances
    </li>
    <li>
     Join validation notebook verifying leakage-free properties
    </li>
    <li>
     Scalable to full 2015-2019 range using same pipeline logic
    </li>
   </ul>
   <p>
    <strong>
     Phase 3 Enhancements:
    </strong>
   </p>
   <ul>
    <li>
     NOAA and BTS data downloader notebook for acquiring raw 2015-2019 data
    </li>
    <li>
     Schema standardization notebook ensuring consistent column names/types across years
    </li>
    <li>
     Upgraded automatic join notebook processing 31.7M records with checkpointing
    </li>
    <li>
     Full 2015-2019 dataset processed through join pipeline
    </li>
    <li>
     Validation of join statistics and weather coverage across all 5 years
    </li>
    <li>
     Documentation of memory optimization strategies for 6x data scale increase
    </li>
   </ul>
   <p>
    <strong>
     Reproducibility:
    </strong>
    All join logic, airport mappings, and station bridges are versioned and checkpointed, enabling reproducible processing of future years (2020+) with identical methodology.
   </p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_005_2fdd6b8a.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_006_99c206e2.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Feature-leakage-prevention-strategy">
    Feature leakage prevention strategy
    <a class="anchor-link" href="#Feature-leakage-prevention-strategy">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_007_f720915e.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Data-Join-Summary">
    Data Join Summary
    <a class="anchor-link" href="#Data-Join-Summary">
     ¶
    </a>
   </h4>
   <p>
    <strong>
     Table 3.10: Data Join Summary (Flights × Weather)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th style="text-align:left">
       Metric
      </th>
      <th style="text-align:left">
       3M flights+weather join (
       <code>
        JOINED_3M
       </code>
       )
      </th>
      <th style="text-align:left">
       1Y flights+weather join (
       <code>
        JOINED_1Y
       </code>
       )
      </th>
      <th style="text-align:left">
       5Y flights+weather join (
       <code>
        JOINED_5Y
       </code>
       )
      </th>
      <th style="text-align:left">
       Future / full-history join (planned)
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:left">
       <strong>
        Data slice
       </strong>
      </td>
      <td style="text-align:left">
       <code>
        3M
       </code>
      </td>
      <td style="text-align:left">
       <code>
        1Y
       </code>
      </td>
      <td style="text-align:left">
       <code>
        5Y
       </code>
      </td>
      <td style="text-align:left">
       <code>
        Full-history (planned)
       </code>
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Data range
       </strong>
      </td>
      <td style="text-align:left">
       2015-01-01 → 2015-03-31
      </td>
      <td style="text-align:left">
       2019-01-01 → 2019-12-31
      </td>
      <td style="text-align:left">
       2015-01-01 → 2019-12-31
      </td>
      <td style="text-align:left">
       2020-01-01 → 2024-12-31
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Input tables &amp; sizes (MB)
       </strong>
      </td>
      <td style="text-align:left">
       flights: 95.85 MB
       <br/>
       weather: 1112.75 MB
       <br/>
       <strong>
        total input:
       </strong>
       1208.60 MB
      </td>
      <td style="text-align:left">
       flights: 594.56 MB
       <br/>
       weather: 4844.64 MB
       <br/>
       <strong>
        total input:
       </strong>
       5439.20 MB
      </td>
      <td style="text-align:left">
       flights: 2804.71 MB
       <br/>
       weather: 33423.03 MB
       <br/>
       <strong>
        total input:
       </strong>
       36227.74 MB
      </td>
      <td style="text-align:left">
       flights: 975.09 MB
       <br/>
       weather: 21917.61 MB
       <br/>
       <strong>
        total input:
       </strong>
       22892.70 MB
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Output table &amp; size (MB)
       </strong>
      </td>
      <td style="text-align:left">
       <code>
        JOINED_3M.parquet
       </code>
       <br/>
       <strong>
        86.68 MB
       </strong>
      </td>
      <td style="text-align:left">
       <code>
        JOINED_1Y.parquet
       </code>
       <br/>
       <strong>
        489.29 MB
       </strong>
      </td>
      <td style="text-align:left">
       <code>
        JOINED_5Y_2015_2019.parquet
       </code>
       <br/>
       <strong>
        2262.21 MB
       </strong>
      </td>
      <td style="text-align:left">
       <code>
        JOINED_FULL.parquet
       </code>
       <br/>
       <strong>
        TBD MB
       </strong>
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Row count
       </strong>
      </td>
      <td style="text-align:left">
       1,403,471
      </td>
      <td style="text-align:left">
       7,422,037
      </td>
      <td style="text-align:left">
       31,746,841
      </td>
      <td style="text-align:left">
       31,339,836
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Feature count
       </strong>
      </td>
      <td style="text-align:left">
       75
      </td>
      <td style="text-align:left">
       75
      </td>
      <td style="text-align:left">
       75
      </td>
      <td style="text-align:left">
       75
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Runtime (minutes)
       </strong>
      </td>
      <td style="text-align:left">
       6.65
      </td>
      <td style="text-align:left">
       39.04
      </td>
      <td style="text-align:left">
       518.32
      </td>
      <td style="text-align:left">
       587
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Job start (UTC)
       </strong>
      </td>
      <td style="text-align:left">
       2025-11-26T16:22:04.454556
      </td>
      <td style="text-align:left">
       2025-11-26T16:36:44.911853
      </td>
      <td style="text-align:left">
       2025-11-26T22:30:03.130620
      </td>
      <td style="text-align:left">
       2025-12-14T14:10:00.000000
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Job end (UTC)
       </strong>
      </td>
      <td style="text-align:left">
       2025-11-26T16:28:43.611389
      </td>
      <td style="text-align:left">
       2025-11-26T17:15:47.022716
      </td>
      <td style="text-align:left">
       2025-11-27T07:08:22.460964
      </td>
      <td style="text-align:left">
       RUNNING
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Cluster / compute
       </strong>
      </td>
      <td style="text-align:left">
       <strong>
        1 driver + 3 workers
       </strong>
       (each
       <strong>
        4 vCPUs, 16 GB RAM
       </strong>
       →
       <strong>
        16 vCPUs, 64 GB RAM total
       </strong>
       )
      </td>
      <td style="text-align:left">
       <strong>
        1 driver + 7 workers
       </strong>
       (each
       <strong>
        4 vCPUs, 16 GB RAM
       </strong>
       →
       <strong>
        32 vCPUs, 128 GB RAM total
       </strong>
       )
      </td>
      <td style="text-align:left">
       <strong>
        1 driver + 8 workers
       </strong>
       (each
       <strong>
        4 vCPUs, 16 GB RAM
       </strong>
       →
       <strong>
        32 vCPUs, 128 GB RAM total
       </strong>
       )
      </td>
      <td style="text-align:left">
       <strong>
        1 driver + 12 workers
       </strong>
       , (each
       <strong>
        8 vCPUs / 32 GB RAM
       </strong>
       per node) →
       <strong>
        96 vCPUs, 384 GB RAM total
       </strong>
       )
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Join logic (words)
       </strong>
      </td>
      <td style="text-align:left">
       2015-Q1 subset: join flights with hourly weather using the project’s standard keys (flight date/time + station mapping) to produce a feature-complete training table for Phase 2.
      </td>
      <td style="text-align:left">
       Full 2019 year: same join logic as 3M, but run on the full-year flights to create the main modeling table used for train/validation/test splits.
      </td>
      <td style="text-align:left">
       Same join logic, extended to a full 5-year window (2015–2019) for robustness checks. 1-year (2015) generated from this dataset.
      </td>
      <td style="text-align:left">
       Same join logic, extended to 2020-2024.
      </td>
     </tr>
     <tr>
      <td style="text-align:left">
       <strong>
        Join code reference
       </strong>
      </td>
      <td style="text-align:left">
       PySpark join in the Phase 2
       <strong>
        joins
       </strong>
       notebook (3M config / limited date range).
      </td>
      <td style="text-align:left">
       PySpark join in the same
       <strong>
        joins
       </strong>
       notebook (1Y config / full-year date range).
      </td>
      <td style="text-align:left">
       Reuse notebook with 5Y date filter/config.
      </td>
      <td style="text-align:left">
       Reuse notebook with open-ended date range. Need downloader and schema standardizer notebook
      </td>
     </tr>
    </tbody>
   </table>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.8-Feature-Engineering">
    3.3.8 Feature Engineering
    <a class="anchor-link" href="#3.3.8-Feature-Engineering">
     ¶
    </a>
   </h4>
   <p>
    Our feature engineering process transformed 59 cleaned features (CP2) into 112 production-ready features (CP5a) through systematic addition, transformation, and selection across four pipeline stages. Each transformation method was chosen to capture domain-specific flight delay patterns while maintaining strict adherence to the T-2 hour prediction cutoff.
   </p>
   <h5 id="Feature-Transformation-Overview">
    Feature Transformation Overview
    <a class="anchor-link" href="#Feature-Transformation-Overview">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Table 3.11: Feature Transformation Methods (2015-2019)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Transformation
      </th>
      <th>
       Features Affected
      </th>
      <th>
       Method
      </th>
      <th>
       Rationale
      </th>
      <th>
       Applied Stage
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        String Indexing
       </strong>
      </td>
      <td>
       Carrier, airports, states, weather types, categories (12 features)
      </td>
      <td>
       StringIndexer
      </td>
      <td>
       Converts categoricals to numeric indices for Spark ML algorithms
      </td>
      <td>
       CP5a
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Cyclic Encoding
       </strong>
      </td>
      <td>
       Time and direction (14 features = 7 sin/cos pairs)
      </td>
      <td>
       Sin/cos transformation
      </td>
      <td>
       Preserves periodicity (23:59 → 00:01 = 2 min, not 1438)
      </td>
      <td>
       CP4
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Binning/Categorization
       </strong>
      </td>
      <td>
       Distance, time-of-day, temperature, weather severity (22 features)
      </td>
      <td>
       Domain-informed categorical bins
      </td>
      <td>
       Captures non-linear effects (e.g., extreme weather, rush hours, long distances)
      </td>
      <td>
       CP3-4
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Rolling Window Aggregation
       </strong>
      </td>
      <td>
       Delay rates, congestion metrics (18 features)
      </td>
      <td>
       Window functions with temporal constraints
      </td>
      <td>
       Captures temporal patterns without data leakage via PRECEDING windows
      </td>
      <td>
       CP3-4
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Interaction Terms
       </strong>
      </td>
      <td>
       Distance×weather, time×congestion, carrier×airport (13 features)
      </td>
      <td>
       Multiplicative interactions
      </td>
      <td>
       Captures compounding effects between feature pairs
      </td>
      <td>
       CP4
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Correlation-Based Selection
       </strong>
      </td>
      <td>
       33 features removed (Pearson &gt;0.85)
      </td>
      <td>
       Pairwise correlation analysis
      </td>
      <td>
       Removes redundancy, reduces multicollinearity for linear models
      </td>
      <td>
       CP4→CP5
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Feature Importance Filtering
       </strong>
      </td>
      <td>
       41 additional features removed
      </td>
      <td>
       Random Forest Gini importance
      </td>
      <td>
       Removes zero-importance and low-value features identified in preliminary models
      </td>
      <td>
       CP5→CP5a
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Meta-Feature Generation
       </strong>
      </td>
      <td>
       rf_prob_delay, rf_prob_delay_binned (2 features)
      </td>
      <td>
       Random Forest probability predictions
      </td>
      <td>
       Breiman's method—captures complex non-linear patterns as linear features
      </td>
      <td>
       CP4
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Network Graph Features
       </strong>
      </td>
      <td>
       PageRank, degree centrality, betweenness (8 features)
      </td>
      <td>
       NetworkX graph algorithms
      </td>
      <td>
       Captures airport importance and delay propagation through flight network
      </td>
      <td>
       CP4
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        RFM Pattern Features
       </strong>
      </td>
      <td>
       Recency, frequency, monetary delay metrics (8 features)
      </td>
      <td>
       Time-since-event and historical aggregations
      </td>
      <td>
       Captures route/carrier historical delay patterns using only past data
      </td>
      <td>
       CP4
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Normalization/Standardization
       </strong>
      </td>
      <td>
       All numeric features (pre-modeling)
      </td>
      <td>
       StandardScaler in VectorAssembler
      </td>
      <td>
       Ensures features on comparable scale for gradient-based and distance algorithms
      </td>
      <td>
       Modeling phase
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Dimensionality-Reduction-Approach">
    Dimensionality Reduction Approach
    <a class="anchor-link" href="#Dimensionality-Reduction-Approach">
     ¶
    </a>
   </h5>
   <p>
    Our feature selection process employed multiple statistical techniques across 31.1M records to identify and remove redundant or uninformative features, reducing 186 features (CP4) to 112 production features (CP5a):
   </p>
   <p>
    <strong>
     Table 3.12: Dimensionality Reduction Techniques (2015-2019)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Technique
      </th>
      <th>
       Purpose
      </th>
      <th>
       Implementation
      </th>
      <th>
       Features Affected
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Pearson Correlation
       </strong>
      </td>
      <td>
       Identify linear relationships between numeric features
      </td>
      <td>
       Correlation matrix with threshold &gt;0.85
      </td>
      <td>
       Removed 33 highly correlated features (e.g., YEAR, QUARTER; HourlyWetBulbTemperature vs HourlyDewPointTemperature)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Cardinality Analysis
       </strong>
      </td>
      <td>
       Identify problematic high-cardinality categoricals
      </td>
      <td>
       Distinct value counts per feature
      </td>
      <td>
       Removed TAIL_NUM (115K+ values), FL_DATE, prediction_utc, origin_obs_utc, asof_minutes
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Feature Importance (Gini)
       </strong>
      </td>
      <td>
       Identify features contributing to Random Forest predictions
      </td>
      <td>
       sklearn RandomForestClassifier.feature_importances_
      </td>
      <td>
       Removed 41 features with zero or near-zero importance (&lt;0.001) in preliminary models
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Duplicate Detection
       </strong>
      </td>
      <td>
       Identify semantically equivalent features
      </td>
      <td>
       Manual review + correlation analysis
      </td>
      <td>
       Flagged 1 duplicate feature for review
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Domain Review
       </strong>
      </td>
      <td>
       Validate feature engineering logic and T-2h compliance
      </td>
      <td>
       Manual audit of feature creation code
      </td>
      <td>
       Verified all 112 final features use only information available at T-2h
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Data Type Validation
       </strong>
      </td>
      <td>
       Ensure ML pipeline compatibility
      </td>
      <td>
       Schema inspection and type checking
      </td>
      <td>
       Confirmed 89 double/float, 49 int/long, 12 indexed categorical, 3 date/time
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Features Removed in CP4→CP5 (33 features):
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      High Collinearity
     </strong>
     : YEAR, QUARTER (redundant with FL_DATE); DISTANCE_high_corr, DISTANCE_GROUP_high_corr (redundant with log_distance)
    </li>
    <li>
     <strong>
      High Cardinality
     </strong>
     : TAIL_NUM (116K unique values), FL_DATE (1,826 unique dates), prediction_utc, origin_obs_utc, asof_minutes (timestamp fields)
    </li>
    <li>
     <strong>
      Correlation &gt;0.85
     </strong>
     : Various weather feature pairs (HourlyWetBulbTemperature/HourlyDewPointTemperature r=0.96)
    </li>
    <li>
     <strong>
      Zero Importance
     </strong>
     : Features showing &lt;0.001 Gini importance in preliminary Random Forest models
    </li>
   </ul>
   <p>
    <strong>
     Features Removed in CP5→CP5a (41 features, +12 indexed):
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Original String Columns
     </strong>
     : Removed 60 string columns after indexing (e.g., OP_UNIQUE_CARRIER, ORIGIN, DEST retained as indexed versions)
    </li>
    <li>
     <strong>
      Low Importance
     </strong>
     : 41 features with zero contribution in Random Forest importance analysis
    </li>
    <li>
     <strong>
      Added Indexed
     </strong>
     : 12 StringIndexed categorical features (carrier, airports, states, weather categories)
    </li>
    <li>
     <strong>
      Net Change
     </strong>
     : 153 → 112 features (-41 features, but gained 12 indexed versions of categoricals)
    </li>
   </ul>
   <h5 id="Key-Highlights">
    Key Highlights
    <a class="anchor-link" href="#Key-Highlights">
     ¶
    </a>
   </h5>
   <ol>
    <li>
     <p>
      <strong>
       Cyclic Encoding Rationale:
      </strong>
      Time and direction are circular variables where the distance between 23:59 and 00:01 should be 2 minutes, not 1,438 minutes. Sin/cos transformations preserve this topology for 14 temporal and directional features (7 pairs): dep_time, arr_time, day_of_week, month, plus wind direction.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Breiman's Stacked Generalization:
      </strong>
      Following Leo Breiman's methodology, we trained a Random Forest on CP3 features to generate probability predictions (rf_prob_delay) as meta-features in CP4. This allows linear models (Logistic Regression) to leverage complex non-linear decision boundaries learned by tree ensembles, effectively creating a two-stage ensemble.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Correlation-Based Selection:
      </strong>
      We removed 33 features with Pearson correlation &gt;0.85 to reduce multicollinearity. When choosing between correlated pairs, we prioritized features with: (a) higher correlation with target DEP_DEL15, (b) better domain interpretability, (c) engineered aggregations over raw values (e.g., kept dep_delay15_24h_rolling_avg_by_origin_weighted over simple dep_delay15_rolling_avg).
     </p>
    </li>
    <li>
     <p>
      <strong>
       Strict Temporal Validation:
      </strong>
      All transformations respect the T-2h prediction cutoff. Rolling windows use
      <code>
       RANGE BETWEEN UNBOUNDED PRECEDING AND INTERVAL '2' HOUR PRECEDING
      </code>
      to exclude same-flight information. RFM features use
      <code>
       WHERE FL_DATE &lt; current_flight_date
      </code>
      to prevent look-ahead bias. Network features computed from historical flight patterns only.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Graph-Based Features:
      </strong>
      Airport network analysis using NetworkX generated 8 features capturing systemic delay propagation. PageRank identifies hub airports where delays cascade through connections. Degree centrality measures airport connectivity. Betweenness identifies critical transfer points. All metrics computed from 2015-2018 flight network for 2019 predictions.
     </p>
    </li>
   </ol>
   <h5 id="Feature-Engineering-Progression-by-Stage">
    Feature Engineering Progression by Stage
    <a class="anchor-link" href="#Feature-Engineering-Progression-by-Stage">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Table 3.13: Feature Count Evolution by Category (2015-2019)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Category
      </th>
      <th>
       CP2 Base
      </th>
      <th>
       CP3 Added
      </th>
      <th>
       CP4 Added
      </th>
      <th>
       CP5 Removed
      </th>
      <th>
       CP5a Adjusted
      </th>
      <th>
       Final Count
      </th>
      <th>
       Net Change from CP2
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Weather Features
       </strong>
      </td>
      <td>
       14
      </td>
      <td>
       +3
      </td>
      <td>
       +19
      </td>
      <td>
       -10
      </td>
      <td>
       0
      </td>
      <td>
       26
      </td>
      <td>
       +12
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Geographic
       </strong>
      </td>
      <td>
       18
      </td>
      <td>
       +3
      </td>
      <td>
       -2
      </td>
      <td>
       +1
      </td>
      <td>
       0
      </td>
      <td>
       20
      </td>
      <td>
       +2
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Rolling Features
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       +10
      </td>
      <td>
       +12
      </td>
      <td>
       -4
      </td>
      <td>
       0
      </td>
      <td>
       18
      </td>
      <td>
       +18
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Cyclic Encoded
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       +14
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       14
      </td>
      <td>
       +14
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Interaction Terms
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       +24
      </td>
      <td>
       -11
      </td>
      <td>
       0
      </td>
      <td>
       13
      </td>
      <td>
       +13
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Indexed Categorical
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       +12
      </td>
      <td>
       12
      </td>
      <td>
       +12
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Temporal Features
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       +10
      </td>
      <td>
       +1
      </td>
      <td>
       -1
      </td>
      <td>
       0
      </td>
      <td>
       10
      </td>
      <td>
       +10
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Core Flight Data
       </strong>
      </td>
      <td>
       14
      </td>
      <td>
       0
      </td>
      <td>
       -1
      </td>
      <td>
       -3
      </td>
      <td>
       0
      </td>
      <td>
       10
      </td>
      <td>
       -4
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        RFM Features
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       +13
      </td>
      <td>
       -5
      </td>
      <td>
       0
      </td>
      <td>
       8
      </td>
      <td>
       +8
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Network Features
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       +8
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       8
      </td>
      <td>
       +8
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Distance
       </strong>
      </td>
      <td>
       2
      </td>
      <td>
       +4
      </td>
      <td>
       +6
      </td>
      <td>
       -5
      </td>
      <td>
       0
      </td>
      <td>
       7
      </td>
      <td>
       +5
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Aircraft Lag
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       +6
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       6
      </td>
      <td>
       +6
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Breiman Meta
       </strong>
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       +2
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       2
      </td>
      <td>
       +2
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Target
       </strong>
      </td>
      <td>
       1
      </td>
      <td>
       0
      </td>
      <td>
       +1
      </td>
      <td>
       0
      </td>
      <td>
       0
      </td>
      <td>
       2
      </td>
      <td>
       +1
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Total
       </strong>
      </td>
      <td>
       <strong>
        59
       </strong>
      </td>
      <td>
       <strong>
        +36
       </strong>
      </td>
      <td>
       <strong>
        +91
       </strong>
      </td>
      <td>
       <strong>
        -33
       </strong>
      </td>
      <td>
       <strong>
        -41
       </strong>
      </td>
      <td>
       <strong>
        112
       </strong>
      </td>
      <td>
       <strong>
        +53
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Stage Transitions:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      CP2 (Base):
     </strong>
     59 features after cleaning and leakage removal
    </li>
    <li>
     <strong>
      CP3 (Basic Features):
     </strong>
     95 features (+36) - temporal, distance, weather, rolling aggregates
    </li>
    <li>
     <strong>
      CP4 (Advanced Features):
     </strong>
     186 features (+91) - RFM, network, interactions, cyclic, Breiman, aircraft lag
    </li>
    <li>
     <strong>
      CP5 (Optimized):
     </strong>
     153 features (-33) - correlation-based reduction, high-cardinality removal
    </li>
    <li>
     <strong>
      CP5a (Production):
     </strong>
     112 features (-41, +12 indexed) - importance-based selection, string indexing
    </li>
   </ul>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.9-Feature-Families-and-Data-Dictionary">
    3.3.9 Feature Families and Data Dictionary
    <a class="anchor-link" href="#3.3.9-Feature-Families-and-Data-Dictionary">
     ¶
    </a>
   </h4>
   <h5 id="Feature-Family-Distribution">
    Feature Family Distribution
    <a class="anchor-link" href="#Feature-Family-Distribution">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_008_fae61be8.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Feature-Family-Categorization">
    Feature Family Categorization
    <a class="anchor-link" href="#Feature-Family-Categorization">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Table 3.14: Feature Families Summary (CP5a - 2015-2019)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Feature Family
      </th>
      <th>
       Count
      </th>
      <th>
       Description
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Weather Features
       </strong>
      </td>
      <td>
       26
      </td>
      <td>
       Temperature measurements (dry bulb, dew point, wet bulb), wind (speed, direction, gusts), precipitation, visibility, pressure, humidity, sky conditions, derived weather composites and severity indices
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Geographic
       </strong>
      </td>
      <td>
       20
      </td>
      <td>
       Airport identifiers (ORIGIN, DEST), coordinates (lat/lon), states, station distances, airport types, traffic density metrics
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Rolling Aggregates
       </strong>
      </td>
      <td>
       18
      </td>
      <td>
       24-hour and 30-day windowed delay rates by origin/carrier/day-of-week, same-day delay statistics, congestion ratios, historical volumes
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Cyclic Encoded
       </strong>
      </td>
      <td>
       14
      </td>
      <td>
       Sin/cos pairs (7 total) for departure time, arrival time, day of week, month, wind direction—preserving circular topology
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Interaction Terms
       </strong>
      </td>
      <td>
       13
      </td>
      <td>
       Multiplicative combinations: weather×airport delays, distance×peak hour, carrier×hour, origin×weather/visibility/precipitation/wind, carrier×origin/dest
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Indexed Categorical
       </strong>
      </td>
      <td>
       12
      </td>
      <td>
       String features converted to numeric indices: carrier, airports, states, weather categories, season, turnaround category, day-hour interaction, airline reputation
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Temporal Features
       </strong>
      </td>
      <td>
       10
      </td>
      <td>
       Date identifiers (FL_DATE), time components (DAY_OF_WEEK, DAY_OF_MONTH), prediction timestamps, season indicators, event flags (SuperBowl, major events), days since epoch
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Core Flight Data
       </strong>
      </td>
      <td>
       10
      </td>
      <td>
       Flight numbers, scheduled arrival times, carrier information, airline reputation scores, operational flags (airport maintenance, natural disaster), oncoming flights
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        RFM Features
       </strong>
      </td>
      <td>
       8
      </td>
      <td>
       Recency (days since last delay on route/carrier), Frequency (delay rates over 30/365 days), route reliability scores, carrier performance at origin
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Network/Graph
       </strong>
      </td>
      <td>
       8
      </td>
      <td>
       Airport centrality metrics (PageRank, degree, betweenness), delay propagation scores, network cascade effects, 1-year historical delay rates
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Distance
       </strong>
      </td>
      <td>
       7
      </td>
      <td>
       Raw distance, log-transformed distance, categorical bins (very_short to very_long), distance-based indicators
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Aircraft Lag
       </strong>
      </td>
      <td>
       6
      </td>
      <td>
       Previous flight delay status, scheduled elapsed time, hours since previous flight, turnaround time categories, airport-wide delay counts
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Breiman Meta
       </strong>
      </td>
      <td>
       2
      </td>
      <td>
       Random Forest probability predictions (rf_prob_delay), binned probability categories
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Target
       </strong>
      </td>
      <td>
       2
      </td>
      <td>
       DEP_DEL15 (binary classification target), DEP_DELAY (continuous delay reference)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Total
       </strong>
      </td>
      <td>
       <strong>
        112
       </strong>
      </td>
      <td>
       <strong>
        32 raw + 80 engineered
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Feature-Composition-Analysis">
    Feature Composition Analysis
    <a class="anchor-link" href="#Feature-Composition-Analysis">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Raw Features (32 features, 29% of total):
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Temporal identifiers (7):
     </strong>
     FL_DATE, prediction_utc, origin_obs_utc, DAY_OF_MONTH, DAY_OF_WEEK, CRS_ARR_TIME, asof_minutes
    </li>
    <li>
     <strong>
      Flight identifiers (1):
     </strong>
     OP_CARRIER_FL_NUM
    </li>
    <li>
     <strong>
      Airport identifiers (4):
     </strong>
     ORIGIN, DEST, ORIGIN_AIRPORT_ID, DEST_AIRPORT_ID
    </li>
    <li>
     <strong>
      State identifiers (2):
     </strong>
     ORIGIN_STATE_ABR, DEST_STATE_ABR
    </li>
    <li>
     <strong>
      Weather measurements (8):
     </strong>
     HourlyDryBulbTemperature, HourlyDewPointTemperature, HourlyWindDirection, HourlyWindGustSpeed, HourlyVisibility, HourlyRelativeHumidity, HourlyStationPressure, HourlyAltimeterSetting
    </li>
    <li>
     <strong>
      Geographic coordinates (6):
     </strong>
     origin_airport_lat, origin_airport_lon, dest_airport_lat, dest_airport_lon, origin_station_dis, dest_station_dis
    </li>
    <li>
     <strong>
      Categorical (2):
     </strong>
     origin_type, OP_UNIQUE_CARRIER (original string versions retained for validation)
    </li>
    <li>
     <strong>
      Target and reference (2):
     </strong>
     DEP_DEL15 (target), DEP_DELAY (reference)
    </li>
   </ul>
   <p>
    <strong>
     Engineered Features (80 features, 71% of total) - By Engineering Method:
    </strong>
   </p>
   <ol>
    <li>
     <strong>
      Rolling Window Aggregations (18):
     </strong>
     24-hour weighted rolling averages by origin/carrier/day-of-week, same-day delay percentages, prior-day delay rates, 30-day volumes, congestion ratios, real-time delay counts
    </li>
    <li>
     <strong>
      Cyclic Encodings (14):
     </strong>
     Sin/cos transformations for departure time (2), arrival time (2), day of week (2), month (2), wind direction (2), plus 4 additional temporal cyclic features
    </li>
    <li>
     <strong>
      Interaction Terms (13):
     </strong>
     Multiplicative features capturing compounding effects between weather and delays, distance and peak hours, carrier and time, origin airport and weather conditions
    </li>
    <li>
     <strong>
      Indexed Categoricals (12):
     </strong>
     Numeric indices for carrier, origin/destination airports, states, weather categories, season, airline reputation category, turnaround category, day-hour interaction, sky condition
    </li>
    <li>
     <strong>
      Network/Graph Features (8):
     </strong>
     Airport centrality (degree, PageRank, betweenness), delay propagation scores, network cascade effects, historical 1-year delay rates
    </li>
    <li>
     <strong>
      RFM Pattern Features (8):
     </strong>
     Days since last delay on route/carrier, 30-day route delay counts and rates, carrier delays at origin airport, recency-frequency-monetary proxy metrics
    </li>
    <li>
     <strong>
      Distance Transformations (6):
     </strong>
     Log-transformed distance, categorical distance bins (very_short, short, medium, long, very_long), distance-based flags
    </li>
    <li>
     <strong>
      Aircraft Lag Features (6):
     </strong>
     Previous flight delay status (prev_flight_dep_del15), turnaround time category, hours since previous flight, scheduled elapsed time, first-flight indicators, airport-wide delays
    </li>
    <li>
     <strong>
      Temporal Indicators (3):
     </strong>
     Season categories, event flags (SuperBowl week, major events, airport maintenance, natural disasters), days since epoch
    </li>
    <li>
     <strong>
      Weather Composites (3):
     </strong>
     Weather condition categories, sky condition parsed, temperature anomaly flags
    </li>
    <li>
     <strong>
      Congestion Metrics (2):
     </strong>
     Airport traffic density, carrier flight count
    </li>
    <li>
     <strong>
      Breiman Meta-Features (2):
     </strong>
     Random Forest probability predictions, binned probability categories
    </li>
    <li>
     <strong>
      Reputation/Quality (2):
     </strong>
     Airline reputation score, airline reputation category
    </li>
    <li>
     <strong>
      Miscellaneous Engineered (1):
     </strong>
     Day-hour interaction categories
    </li>
   </ol>
   <h5 id="Feature-Engineering-Insights">
    Feature Engineering Insights
    <a class="anchor-link" href="#Feature-Engineering-Insights">
     ¶
    </a>
   </h5>
   <p>
    This
    <strong>
     71% engineered feature composition
    </strong>
    (80 out of 112 features) reflects our core hypothesis:
    <strong>
     predictive power for flight delays emerges primarily from capturing operational patterns, temporal dependencies, network effects, and complex interactions rather than raw measurements alone.
    </strong>
   </p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.10-Dataset-Sizes-and-Storage">
    3.3.10 Dataset Sizes and Storage
    <a class="anchor-link" href="#3.3.10-Dataset-Sizes-and-Storage">
     ¶
    </a>
   </h4>
   <h5 id="Storage-Metrics-Across-Pipeline">
    Storage Metrics Across Pipeline
    <a class="anchor-link" href="#Storage-Metrics-Across-Pipeline">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Table 3.15: Dataset Sizes and Storage Requirements (2015-2019)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Checkpoint
      </th>
      <th>
       File Name
      </th>
      <th>
       Rows
      </th>
      <th>
       Columns
      </th>
      <th>
       Total Cells
      </th>
      <th>
       Size (GB)
      </th>
      <th>
       Avg Cell (Bytes)
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Stage 0
       </strong>
      </td>
      <td>
       OTPW_60M_Backup.parquet
      </td>
      <td>
       31,673,119
      </td>
      <td>
       214
      </td>
      <td>
       6,778,047,466
      </td>
      <td>
       ~50.0
      </td>
      <td>
       ~7.74
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP1
       </strong>
      </td>
      <td>
       checkpoint_1_initial_joined_5Y_2015-2019.parquet
      </td>
      <td>
       31,746,841
      </td>
      <td>
       75
      </td>
      <td>
       2,381,013,075
      </td>
      <td>
       ~18.5
      </td>
      <td>
       ~8.16
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP2
       </strong>
      </td>
      <td>
       checkpoint_2_cleaned_imputed_2015-2019.parquet
      </td>
      <td>
       31,128,891
      </td>
      <td>
       59
      </td>
      <td>
       1,836,604,569
      </td>
      <td>
       ~12.3
      </td>
      <td>
       ~7.03
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP3
       </strong>
      </td>
      <td>
       checkpoint_3_basic_features_2015-2019.parquet
      </td>
      <td>
       31,128,891
      </td>
      <td>
       95
      </td>
      <td>
       2,957,244,645
      </td>
      <td>
       ~14.8
      </td>
      <td>
       ~5.25
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP4
       </strong>
      </td>
      <td>
       checkpoint_4_advanced_features_2015-2019.parquet
      </td>
      <td>
       31,128,891
      </td>
      <td>
       186
      </td>
      <td>
       5,789,973,726
      </td>
      <td>
       ~22.4
      </td>
      <td>
       ~4.06
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP5
       </strong>
      </td>
      <td>
       checkpoint_5_comprehensive_2015-2019.parquet
      </td>
      <td>
       31,128,891
      </td>
      <td>
       153
      </td>
      <td>
       4,762,720,723
      </td>
      <td>
       ~19.2
      </td>
      <td>
       ~4.23
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP5a
       </strong>
      </td>
      <td>
       <strong>
        checkpoint_5_comprehensive_2015-2019_refined.parquet
       </strong>
      </td>
      <td>
       <strong>
        31,128,891
       </strong>
      </td>
      <td>
       <strong>
        112
       </strong>
      </td>
      <td>
       <strong>
        3,486,435,792
       </strong>
      </td>
      <td>
       <strong>
        ~18.2
       </strong>
      </td>
      <td>
       <strong>
        ~5.48
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Total
       </strong>
      </td>
      <td>
       All checkpoints (Stage 0 through CP5a)
      </td>
      <td>
       —
      </td>
      <td>
       —
      </td>
      <td>
       —
      </td>
      <td>
       <strong>
        ~155.4
       </strong>
      </td>
      <td>
       —
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Storage-Insights">
    Storage Insights
    <a class="anchor-link" href="#Storage-Insights">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Parquet Compression Performance:
    </strong>
   </p>
   <ul>
    <li>
     Average cell size ranges from 4-8 bytes, demonstrating excellent columnar compression across 31M+ records
    </li>
    <li>
     Compression ratio: Approximately 10-12x vs. raw CSV format
    </li>
    <li>
     String indexing in CP5a provides modest storage optimization (19.2 GB → 18.2 GB from CP5, -5%)
    </li>
    <li>
     Correlation-based feature removal in CP5 achieved significant savings (22.4 GB → 19.2 GB from CP4, -14%)
    </li>
   </ul>
   <p>
    <strong>
     Storage Efficiency by Stage:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Stage 0 → CP1
     </strong>
     : Consolidated 214 columns to 75 (-63%) with 18.5 GB output despite +74K rows
    </li>
    <li>
     <strong>
      CP1 → CP2
     </strong>
     : Row reduction (-618K) and column pruning (75→59) saved 33% storage (18.5 GB → 12.3 GB)
    </li>
    <li>
     <strong>
      CP2 → CP3
     </strong>
     : Basic features (+36 columns) increased size by 20% (12.3 GB → 14.8 GB)
    </li>
    <li>
     <strong>
      CP3 → CP4
     </strong>
     : Advanced features (+91 columns) increased size by 51% (14.8 GB → 22.4 GB)
    </li>
    <li>
     <strong>
      CP4 → CP5
     </strong>
     : Feature optimization (-33 columns) reduced size by 14% (22.4 GB → 19.2 GB)
    </li>
    <li>
     <strong>
      CP5 → CP5a
     </strong>
     : Importance filtering (-41 columns) provided 5% savings (19.2 GB → 18.2 GB)
    </li>
   </ul>
   <p>
    <strong>
     Multi-Year Scaling Validation:
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Dataset
      </th>
      <th>
       Actual Size (GB)
      </th>
      <th>
       Rows
      </th>
      <th>
       Features
      </th>
      <th>
       Processing Time
      </th>
      <th>
       Feasibility
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       Phase 2: 1-year (2015)
      </td>
      <td>
       2.97
      </td>
      <td>
       5.7M
      </td>
      <td>
       108
      </td>
      <td>
       ~2 hours
      </td>
      <td>
       Production-ready
      </td>
     </tr>
     <tr>
      <td>
       Phase 3: 5-year (2015-2019)
      </td>
      <td>
       18.2
      </td>
      <td>
       31.1M
      </td>
      <td>
       112
      </td>
      <td>
       ~15 hours
      </td>
      <td>
       Achieved on 8-node cluster
      </td>
     </tr>
     <tr>
      <td>
       Scaling factor
      </td>
      <td>
       6.1x
      </td>
      <td>
       5.5x
      </td>
      <td>
       1.04x
      </td>
      <td>
       7.5x
      </td>
      <td>
       Within computational budget
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Computational Resource Requirements (Phase 3 Actual):
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Cluster configuration
     </strong>
     : 8-node Databricks cluster (Standard_DS3_v2: 4 cores, 14GB RAM per node)
    </li>
    <li>
     <strong>
      Driver node
     </strong>
     : 14GB RAM, 4 cores
    </li>
    <li>
     <strong>
      Executor nodes
     </strong>
     : 7 workers x 14GB RAM = 98GB total distributed memory
    </li>
    <li>
     <strong>
      In-memory operations
     </strong>
     : Feasible with strategic caching and unpersisting at each checkpoint
    </li>
    <li>
     <strong>
      Iterative modeling
     </strong>
     : Fast Parquet I/O enables rapid experimentation even on 31M records
    </li>
    <li>
     <strong>
      Weather join runtime
     </strong>
     : ~6 hours on 31.7M records with haversine distance calculations
    </li>
    <li>
     <strong>
      Total pipeline runtime
     </strong>
     : ~15 hours (Stage 0 → CP5a with all checkpoints)
    </li>
   </ul>
   <p>
    <strong>
     Storage Location and Organization:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Base directory
     </strong>
     :
     <code>
      dbfs:/student-groups/Group_4_4/
     </code>
    </li>
    <li>
     <strong>
      Checkpoint files
     </strong>
     :
     <code>
      checkpoint_[1-5]_*_2015-2019.parquet
     </code>
     (numbered stages)
    </li>
    <li>
     <strong>
      Production dataset
     </strong>
     :
     <code>
      checkpoint_5_comprehensive_2015-2019_refined.parquet
     </code>
     (modeling-ready)
    </li>
    <li>
     <strong>
      Metadata/reports
     </strong>
     :
     <code>
      CSVs_5Y/
     </code>
     (analysis outputs, feature lists, validation reports)
    </li>
    <li>
     <strong>
      Visualizations
     </strong>
     :
     <code>
      Charts_5Y/
     </code>
     (EDA plots, pipeline diagrams, correlation heatmaps)
    </li>
    <li>
     <strong>
      Raw source data
     </strong>
     :
     <code>
      dbfs:/mnt/mids-w261/OTPW_60M_Backup/
     </code>
     (read-only, shared)
    </li>
   </ul>
   <p>
    <strong>
     Memory Management Strategies for 31M Records:
    </strong>
   </p>
   <ol>
    <li>
     <strong>
      Checkpoint-based workflows
     </strong>
     : Intermediate results saved at each stage prevent full pipeline recomputation on failures
    </li>
    <li>
     <strong>
      Strategic caching
     </strong>
     : Frequently-accessed DataFrames (airport dimension, station bridge) cached with explicit unpersisting
    </li>
    <li>
     <strong>
      Partition tuning
     </strong>
     : Adjusted Spark partitions from 200 (default) to 400-800 based on stage data volume
    </li>
    <li>
     <strong>
      Broadcast joins
     </strong>
     : Small lookup tables (&lt;1MB) broadcast to all executors for efficient joins
    </li>
    <li>
     <strong>
      Lazy evaluation
     </strong>
     : Leveraged Spark's lazy execution to avoid materializing unnecessary intermediate DataFrames
    </li>
    <li>
     <strong>
      Column pruning
     </strong>
     : Selected only required columns in joins and aggregations to minimize shuffle data
    </li>
    <li>
     <strong>
      Predicate pushdown
     </strong>
     : Applied filters as early as possible to reduce data volume through pipeline
    </li>
   </ol>
   <p>
    <strong>
     Scalability to Future Years (2020+):
    </strong>
   </p>
   <p>
    The pipeline successfully scaled 6× from Phase 2 to Phase 3, validating that:
   </p>
   <ul>
    <li>
     Adding 2020-2021 data (~12M rows) would increase CP5a to ~25 GB (37% increase from 18.2 GB)
    </li>
    <li>
     Full 10-year dataset (2015-2024, ~62M rows) would require ~36 GB storage and 16-node cluster
    </li>
    <li>
     Current architecture supports extension to 10 years without fundamental redesign
    </li>
    <li>
     Databricks autoscaling can dynamically adjust resources based on workload
    </li>
   </ul>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="3.3.11-Final-Dataset-Validation-and-Production-Readiness">
    3.3.11 Final Dataset Validation and Production Readiness
    <a class="anchor-link" href="#3.3.11-Final-Dataset-Validation-and-Production-Readiness">
     ¶
    </a>
   </h4>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_009_bddfb315.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Production-Readiness-Checklist">
    Production Readiness Checklist
    <a class="anchor-link" href="#Production-Readiness-Checklist">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Table 3.16: Dataset Validation Results (CP5a - 2015-2019)
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Validation
      </th>
      <th>
       Status
      </th>
      <th>
       Details
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Data Completeness
       </strong>
      </td>
      <td>
       99.98%
      </td>
      <td>
       &lt;1% missing in 4 temporal features (same_day_prior_delay_percentage: 1.81%, route_delays_30d: 0.08%, carrier_delays_at_origin_30d: 0.06%, dest_delay_rate_today: 0.06%)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Target Variable
       </strong>
      </td>
      <td>
       PASS
      </td>
      <td>
       100% complete (zero nulls in DEP_DEL15 from CP2 onwards)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Class Balance
       </strong>
      </td>
      <td>
       ACCEPTABLE
      </td>
      <td>
       81.85% on-time / 18.15% delayed (4.51:1 ratio, manageable with undersampling/SMOTE)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Reduced Data Leakage
       </strong>
      </td>
      <td>
       PASS
      </td>
      <td>
       T-2h compliance verified across all 112 features; 15 post-departure features removed in CP2
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        No Duplicate Records
       </strong>
      </td>
      <td>
       PASS
      </td>
      <td>
       Verified zero duplicates via FL_DATE + OP_CARRIER_FL_NUM + ORIGIN + DEST composite key
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Categorical Encoding
       </strong>
      </td>
      <td>
       PASS
      </td>
      <td>
       12 string features indexed to numeric via StringIndexer for Spark ML compatibility
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Data Type Validation
       </strong>
      </td>
      <td>
       PASS
      </td>
      <td>
       89 double/float, 49 int/long, 12 indexed categorical, 3 date/time—all ML-compatible
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Feature Count
       </strong>
      </td>
      <td>
       OPTIMIZED
      </td>
      <td>
       112 features (down from 186 in CP4) after correlation analysis and importance filtering
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Duplicate Features
       </strong>
      </td>
      <td>
       REVIEW
      </td>
      <td>
       1 duplicate feature identified but retained pending analysis
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Optimal Storage
       </strong>
      </td>
      <td>
       PASS
      </td>
      <td>
       18.2 GB Parquet format with columnar compression (avg 5.48 bytes/cell)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Temporal Coverage
       </strong>
      </td>
      <td>
       COMPLETE
      </td>
      <td>
       5 years (2015-2019), 60 months, 1,826 days—sufficient for seasonal patterns
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Checkpointed Pipeline
       </strong>
      </td>
      <td>
       PASS
      </td>
      <td>
       Reproducible across 7 stages (Stage 0 through CP5a) with full lineage documentation
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Train/Val/Test Splits
       </strong>
      </td>
      <td>
       DEFINED
      </td>
      <td>
       2015-2017 train (54%), 2018 validation (23%), 2019 blind holdout (23%)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Temporal Ordering
       </strong>
      </td>
      <td>
       VALIDATED
      </td>
      <td>
       All features respect strict temporal ordering; rolling windows use PRECEDING constraints
      </td>
     </tr>
    </tbody>
   </table>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="4-Exploratory-Data-Analysis-(EDA):">
    4 Exploratory Data Analysis (EDA):
    <a class="anchor-link" href="#4-Exploratory-Data-Analysis-(EDA):">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="4.1-Data-Overview">
    4.1 Data Overview
    <a class="anchor-link" href="#4.1-Data-Overview">
     ¶
    </a>
   </h4>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h2 id="Distribution-of-the-Delay-Targets">
      Distribution of the Delay Targets
      <a class="anchor-link" href="#Distribution-of-the-Delay-Targets">
       ¶
      </a>
     </h2>
    </div>
   
  </div>
 </div>
</div>
</div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_010_75934f75.png" width="1000"/>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Insights">
      Insights
      <a class="anchor-link" href="#Insights">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <p>
      Departure delay behavior is both
      <strong>
       highly imbalanced
      </strong>
      and
      <strong>
       strongly right-skewed
      </strong>
      . Departure delays exhibit a strong class imbalance: roughly 82% of flights depart on time, while only 18% exceed the DOT's 15-minute delay threshold. Although most delays remain small, the continuous delay distribution shows a long, meaningful tail of 30+ minute disruptions. The cumulative distribution curve reveals how sharply delay risk accelerates after the median, confirming that a very small portion of flights accounts for a disproportionately large share of operational impact. Because delay minutes are heavily right-skewed, traditional accuracy metrics hide risk. Median delay sits close to zero, yet the 90th percentile jumps to ~30–35 minutes, and beyond this range, the probability of major disruptions rises steeply. Bucket analysis shows short delays dominate in volume, but mid- and high-severity delays (30+ minutes) drive the majority of downstream effects—crew misalignments, gate conflicts, missed connections.
     </p>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Modeling-Implications">
      Modeling Implications
      <a class="anchor-link" href="#Modeling-Implications">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <ul>
      <li>
       Requires
       <strong>
        non-accuracy metrics
       </strong>
       such as F2, recall, and precision. The business value lies in catching flights that are truly at risk.
      </li>
     </ul>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Business-Implications">
      Business Implications
      <a class="anchor-link" href="#Business-Implications">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <ul>
      <li>
       Small delays dominate the network and drive passenger experience; reducing them generates outsized impact.
      </li>
      <li>
       High-severity delays are rare but operationally costly, needing early warning and recovery protocols.
      </li>
      <li>
       Provides clarity on where staffing, scheduling buffers, and gate operations yield the highest ROI.
      </li>
     </ul>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <hr/>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h2 id="Weather-Effects-Panel">
      Weather Effects Panel
      <a class="anchor-link" href="#Weather-Effects-Panel">
       ¶
      </a>
     </h2>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_011_e73a9359.png" width="1000"/>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Insights">
      Insights
      <a class="anchor-link" href="#Insights">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <p>
      Weather variables show
      <strong>
       clear monotonic relationships
      </strong>
      with delay risk. Low visibility, lower temperatures, and higher wind gusts correspond to higher delay rates. The composite weather severity index strengthens this signal by capturing multi-factor interactions in a single engineered feature.
     </p>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Modeling-Implications">
      Modeling Implications
      <a class="anchor-link" href="#Modeling-Implications">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <ul>
      <li>
       Confirms that
       <strong>
        weather severity index
       </strong>
       is a strong engineered predictor.
      </li>
      <li>
       Suggests nonlinear models (e.g., GBT) naturally capture threshold effects (fog, wind spikes).
      </li>
      <li>
       Weather interactions with airport congestion justify including both airport-level and meteorological variables.
      </li>
     </ul>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Business-Implications">
      Business Implications
      <a class="anchor-link" href="#Business-Implications">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <ul>
      <li>
       Identifies when weather-driven delays are predictable vs. disruptive.
      </li>
      <li>
       Enables proactive rescheduling, gate reassignments, and customer communication.
      </li>
      <li>
       Supports risk forecasting dashboards for operational control centers.
      </li>
     </ul>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <hr/>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h2 id="Temporal-Delay-Patterns">
      Temporal Delay Patterns
      <a class="anchor-link" href="#Temporal-Delay-Patterns">
       ¶
      </a>
     </h2>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_012_661f31af.png" width="1000"/>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Insights">
      Insights
      <a class="anchor-link" href="#Insights">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <p>
      Delays follow
      <strong>
       strong temporal rhythms
      </strong>
      . Delay rates peak in summer and December, rise late in the work week, and remain lowest early in the morning before steadily climbing through the evening as disruptions propagate.
     </p>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Modeling-Implications">
      Modeling Implications
      <a class="anchor-link" href="#Modeling-Implications">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <ul>
      <li>
       Treat
       <strong>
        month
       </strong>
       ,
       <strong>
        day of week
       </strong>
       , and
       <strong>
        hour
       </strong>
       as core features.
      </li>
      <li>
       Time variables interact with congestion, requiring nonlinear modeling.
      </li>
      <li>
       Temporal splits (by month/year) reduce leakage and yield realistic performance estimates.
      </li>
     </ul>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Business-Implications">
      Business Implications
      <a class="anchor-link" href="#Business-Implications">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <ul>
      <li>
       Seasonal peaks require increased staffing and schedule slack.
      </li>
      <li>
       Thu–Fri patterns indicate compression of operational buffers.
      </li>
      <li>
       Morning flights offer reliability advantages; prioritization improves customer satisfaction.
      </li>
     </ul>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <hr/>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h2 id="Operational-Load-by-Hour">
      Operational Load by Hour
      <a class="anchor-link" href="#Operational-Load-by-Hour">
       ¶
      </a>
     </h2>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_013_663b80e9.png" width="1000"/>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Insights">
      Insights
      <a class="anchor-link" href="#Insights">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <p>
      Operational pressure spikes during midday and evening departure banks. More than
      <strong>
       half of all delays
      </strong>
      accumulate after ~5 PM due to propagation, confirming that early-day execution strongly shapes end-of-day performance.
     </p>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Modeling-Implications">
      Modeling Implications
      <a class="anchor-link" href="#Modeling-Implications">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <ul>
      <li>
       Hour-of-day interacts strongly with congestion; must pair time features with airport-wide metrics.
      </li>
      <li>
       Validates evaluating models across
       <strong>
        time-of-day strata
       </strong>
       .
      </li>
      <li>
       Supports using volatility-aware decision thresholds later in the day.
      </li>
     </ul>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Business-Implications">
      Business Implications
      <a class="anchor-link" href="#Business-Implications">
       ¶
      </a>
     </h3>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <ul>
      <li>
       High-volume hours require targeted intervention: more agents, tighter turnarounds, disciplined pushbacks.
      </li>
      <li>
       Morning discipline prevents delay cascades.
      </li>
      <li>
       Resource allocation should follow
       <strong>
        real hourly load
       </strong>
       , not average assumptions.
      </li>
     </ul>
    </div>
   </div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <hr/>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
  <div class="inner_cell">
    <div class="text_cell_render border-box-sizing rendered_html">

      <h2 id="Correlation-Structure-of-Delay-Drivers-(Operational,-Weather,-and-Engineered-Signals)">
        Correlation Structure of Delay Drivers (Operational, Weather, and Engineered Signals)
      </h2>

    </div>
  </div>
</div>

<div class="cell border-box-sizing text_cell rendered">
  <div class="inner_cell">
    <div class="text_cell_render border-box-sizing rendered_html">
      <img src="images/image_014_336d90ad.png" width="950" alt="">
    </div>
  </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Insights">
    <strong>
     Insights
    </strong>
    <a class="anchor-link" href="#Insights">
     ¶
    </a>
   </h3>
   <p>
    Correlation patterns show that
    <strong>
     system congestion is the primary driver of departure delays
    </strong>
    . Airport-wide delay counts, rolling origin delay ratios, and oncoming-flight volume exhibit the strongest relationships with DEP_DEL15, confirming that delays propagate through the network rather than occurring independently. Weather variables show modest linear correlations but clear monotonic patterns, meaning
    <strong>
     weather becomes a major amplifying force only when congestion is already high
    </strong>
    . Distance and schedule-based flight characteristics contribute minimal predictive value. A small set of engineered congestion and rolling-window features captures nearly all meaningful signal, reinforcing the importance of
    <strong>
     nonlinear models capable of learning thresholds and interactions
    </strong>
    .
   </p>
   <h3 id="Modeling-Implications">
    <strong>
     Modeling Implications
    </strong>
    <a class="anchor-link" href="#Modeling-Implications">
     ¶
    </a>
   </h3>
   <ul>
    <li>
     Prioritize congestion-based engineered features such as rolling averages, airport-wide delay metrics, and oncoming-flight counts.
    </li>
    <li>
     Use nonlinear models (GBT, Random Forest) that capture propagation effects and threshold behavior.
    </li>
    <li>
     Model weather interactions rather than relying solely on raw variables; monotonic patterns improve predictive strength.
    </li>
    <li>
     Reduce emphasis on distance and static schedule characteristics, which add limited incremental value.
    </li>
    <li>
     Keep the feature set focused on the
     <strong>
      10–12 highest-signal engineered variables
     </strong>
     to improve stability and interpretability.
    </li>
   </ul>
   <h3 id="Business-Implications">
    <strong>
     Business Implications
    </strong>
    <a class="anchor-link" href="#Business-Implications">
     ¶
    </a>
   </h3>
   <ul>
    <li>
     Delays are
     <strong>
      system-driven
     </strong>
     , meaning operational interventions—not route changes—yield the highest ROI.
    </li>
    <li>
     Weather disruptions intensify under congestion, underscoring the need for
     <strong>
      early-day discipline
     </strong>
     and proactive buffer protection.
    </li>
    <li>
     Airport-level operational investments (gate management, staffing, runway flow programs) deliver stronger impact than schedule redesign.
    </li>
    <li>
     A compact high-signal feature set supports
     <strong>
      real-time delay-risk dashboards
     </strong>
     for operations leaders.
    </li>
    <li>
     Nonlinear delay dynamics show small disruptions escalate quickly, justifying tighter controls during peak-volume periods.
    </li>
   </ul>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_015_ad09356a.png" width="1100"/>
   <div class="output_area">
    <div class="prompt">
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Busiest-vs-Most-Delayed-Origin-Airports-%E2%80%94-5-Year-(2015%E2%80%932019)">
      Busiest vs Most Delayed Origin Airports — 5-Year (2015–2019)
      <a class="anchor-link" href="#Busiest-vs-Most-Delayed-Origin-Airports-%E2%80%94-5-Year-(2015%E2%80%932019)">
       ¶
      </a>
     </h3>
     <p>
      <strong>
       What this figure shows
      </strong>
     </p>
     <p>
      <strong>
       Left panel – Top 20 busiest origins:
      </strong>
      <br/>
      Major hubs like ATL, ORD, DFW, DEN, LAX, and SFO handle massive flight volumes.
      <br/>
      Even delay rates around 18–22% translate into a large absolute number of affected flights.
     </p>
     <p>
      <strong>
       Right panel – Top 20 most delayed origins (n ≥ 5000):
      </strong>
      <br/>
      These airports show structural delay problems, with rates often exceeding 25%.
      <br/>
      Volume may be lower, but the probability of delay is significantly higher.
     </p>
     <p>
      <strong>
       Overlap insight:
      </strong>
      <br/>
      A few airports appear in both lists — these are national congestion chokepoints, contributing heavily to delay propagation.
     </p>
     <p>
      <strong>
       Why this matters for modeling
      </strong>
     </p>
     <ul>
      <li>
       ORIGIN is a high-signal feature because delays are not evenly distributed geographically.
      </li>
      <li>
       Rolling congestion features amplify this signal.
      </li>
      <li>
       High-volume hubs dominate national delay totals, so model calibration at these airports is especially important.
      </li>
     </ul>
     <p>
      <strong>
       Operational takeaway
      </strong>
     </p>
     <p>
      Improving processes at a small set of high-volume/high-delay airports
      <br/>
      produces outsized improvements across the entire network.
     </p>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_016_283997a9.png" width="1100"/>
    </div>
   
  </div>
 </div>
</div>
</div>
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_markdown rendered_html output_subarea">
     <h3 id="Delay-Rate-vs-Flight-Volume-by-Airline-%E2%80%94-5-Year-(sorted-by-delay-rate)">
      Delay Rate vs Flight Volume by Airline — 5-Year (sorted by delay rate)
      <a class="anchor-link" href="#Delay-Rate-vs-Flight-Volume-by-Airline-%E2%80%94-5-Year-(sorted-by-delay-rate)">
       ¶
      </a>
     </h3>
     <p>
      <strong>
       What the chart shows
      </strong>
     </p>
     <ul>
      <li>
       <strong>
        Bars
       </strong>
       represent total 5-year departures per airline;
       <strong>
        line
       </strong>
       shows each carrier’s average
       <strong>
        delay rate (%)
       </strong>
       .
      </li>
      <li>
       Carriers on the left combine
       <strong>
        higher delay rates
       </strong>
       (often above ~20–25%) with non-trivial volumes, indicating
       <strong>
        structurally less reliable operations
       </strong>
       .
      </li>
      <li>
       Legacy carriers and some large network airlines toward the right operate
       <strong>
        very high volumes
       </strong>
       with
       <strong>
        delay rates closer to or below the overall average
       </strong>
       .
      </li>
     </ul>
     <p>
      <strong>
       Why this complements the airport analysis
      </strong>
     </p>
     <ul>
      <li>
       Airport charts describe
       <strong>
        where
       </strong>
       delays occur; this view explains
       <strong>
        who is operating them
       </strong>
       .
      </li>
      <li>
       Differences in delay rate by airline remain even after controlling for volume, suggesting
       <strong>
        carrier-specific processes, schedules, and recovery strategies
       </strong>
       matter.
      </li>
      <li>
       High-volume, low-delay airlines provide a
       <strong>
        reference point
       </strong>
       for what “good” looks like under similar network conditions.
      </li>
     </ul>
     <p>
      <strong>
       Implications for the model
      </strong>
     </p>
     <ul>
      <li>
       <code>
        OP_UNIQUE_CARRIER
       </code>
       and carrier-derived features (e.g.,
       <strong>
        rolling carrier delay rates, reputation category
       </strong>
       ) should be treated as
       <strong>
        high-signal inputs
       </strong>
       .
      </li>
      <li>
       The model can learn that the
       <strong>
        same route and weather
       </strong>
       carries different risk depending on
       <strong>
        which airline operates the flight
       </strong>
       .
      </li>
      <li>
       This supports more nuanced use cases (e.g., customer messaging, rebooking, or connection risk scoring that depends on carrier behavior).
      </li>
     </ul>
     <p>
      <strong>
       Operational takeaway
      </strong>
     </p>
     <ul>
      <li>
       Interventions can be
       <strong>
        carrier-specific
       </strong>
       :
       <ul>
        <li>
         For high-delay carriers, focus on
         <strong>
          turn times, buffer policies, and crew/maintenance planning
         </strong>
         .
        </li>
        <li>
         For high-performing carriers, identify
         <strong>
          best practices
         </strong>
         that can be replicated across the network.
        </li>
       </ul>
      </li>
     </ul>
    </div>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <strong>
     Busiest Origin Airports
    </strong>
   </p>
   <p>
    The top 20 busiest airports account for the majority of U.S. departures. Despite heavy traffic, several major hubs (ATL, DEN, PHX, SEA) maintain relatively stable delay rates. This confirms that volume alone does not drive delay risk.
   </p>
   <p>
    <strong>
     Most Delayed Origin Airports
    </strong>
   </p>
   <p>
    When sorting by delay rate (n ≥ 5,000 flights), a different pattern emerges: several mid-volume airports (BWI, MDW, DAL, HPN) consistently exceed 20–25% delay rates. These structural delays persist across both time windows.
   </p>
   <p>
    <strong>
     Modeling Implications
    </strong>
   </p>
   <ul>
    <li>
     Airport-specific context (weather, congestion, runway capacity) must be included.
    </li>
    <li>
     High-delay airports should receive explicit evaluation slices to prevent the model from over-generalizing patterns from high-volume hubs.
    </li>
    <li>
     The 3-month sample accurately reflects the full-year signal.
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="5.-Machine-Learning-Algorithms-(planned,-scalable,-leakage-aware):">
    5. Machine Learning Algorithms (planned, scalable, leakage-aware):
    <a class="anchor-link" href="#5.-Machine-Learning-Algorithms-(planned,-scalable,-leakage-aware):">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    Our task is to decide,
    <strong>
     two hours before scheduled departure
    </strong>
    , whether a flight will leave
    <strong>
     15 minutes late or more
    </strong>
    (
    <code>
     DEP_DEL15 = 1
    </code>
    ). In the 1-year OTPW sample this is clearly an
    <strong>
     imbalanced
    </strong>
    classification problem: roughly 1 in 5 flights is delayed, 4 in 5 are on time. That profile is the same one reported in most BTS/NOAA-based flight-delay papers, and in those studies
    <strong>
     tree and boosted models
    </strong>
    usually outperform simple linear models once you add schedule, airport, and weather features. Because we ultimately have to repeat this on the
    <strong>
     multi-year
    </strong>
    OTPW (tens of millions of rows), we are deliberately choosing algorithms that (i) work well on
    <strong>
     structured/tabular
    </strong>
    data such as “time of day, carrier, origin/dest, weather-as-of,” (ii) already exist in
    <strong>
     Spark/MLlib
    </strong>
    or have known distributed versions, and (iii) can be
    <strong>
     retrained
    </strong>
    once we replace the prejoined OTPW with
    <strong>
     our own flights → airport → station → weather
    </strong>
    joins. In other words, we want something that is good enough now, but won’t block us later when the data shape improves.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.1-Machine-Learning-Approach">
    5.1 Machine Learning Approach
    <a class="anchor-link" href="#5.1-Machine-Learning-Approach">
     ¶
    </a>
   </h3>
   <p>
    We have a leakage-free feature set that respects the
    <strong>
     T–2h
    </strong>
    rule, and  a sensible classifier actually learns signal from it. To do that we will start with
    <strong>
     Logistic Regression in Spark
    </strong>
    . It is fast, easy to explain to an airline stakeholder, and it gives us clean probabilities that we can later threshold.
   </p>
   <p>
    The logistic regression model predicts the probability of delay as:
   </p>
   <p>
    $$
P(y=1 \mid \mathbf{x}) = \frac{1}{1 + e^{-(\beta_0 + \boldsymbol{\beta}^T \mathbf{x})}}
$$
   </p>
   <p>
    where
    <strong>
     x
    </strong>
    represents our feature vector and
    <strong>
     β
    </strong>
    are the learned coefficients.
   </p>
   <p>
    On the data side, this model will only see features that are truly available
    <strong>
     at or before two hours prior to departure
    </strong>
    (scheduled times, carrier, origin/destination, calendar features such as day of week or month, plus the "as-of" weather features we already described). Because the target is imbalanced we will turn on
    <strong>
     class weights
    </strong>
    , which modifies the loss function to:
   </p>
   <p>
    $$
L = -\frac{1}{n} \sum_{i=1}^{n} w_i \left[ y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i) \right]
$$
   </p>
   <p>
    where the weights are assigned as:
   </p>
   <p>
    $$
w_i = \begin{cases} 
w_{\text{delayed}} &amp; \text{if } y_i = 1 \\
w_{\text{ontime}} &amp; \text{if } y_i = 0
\end{cases}
$$
   </p>
   <p>
    Alternatively, we will use
    <strong>
     threshold tuning
    </strong>
    so that the model does not collapse to "always on time." The
    <strong>
     primary metric
    </strong>
    we will report is
    <strong>
     F(0.5)
    </strong>
    , not F₁, because in operations **raising a false alert is worse than missing a real delay (status quo) **;
   </p>
   <p>
    Right after that we will keep a
    <strong>
     very dumb regression baseline
    </strong>
    just for orientation: for those flights that are actually delayed (or that the classifier tags as delayed) we will fit a plain
    <strong>
     Linear Regression
    </strong>
    on delay minutes:
   </p>
   <p>
    $$
\text{Delay}_{\text{minutes}} = \alpha_0 + \boldsymbol{\alpha}^T \mathbf{x} + \epsilon
$$
   </p>
   <p>
    and we will compare it with an even simpler
    <strong>
     "predict the average delay"
    </strong>
    constant model:
   </p>
   <p>
    $$
\hat{y} = \bar{y} = \frac{1}{n_{\text{delayed}}} \sum_{i: y_i = 1} \text{Delay}_{\text{minutes}, i}
$$
   </p>
   <p>
    This restores the original intent in our plan ("linear reg or average delay") and gives Phase 3 something to beat when we bring in boosted regressors.
   </p>
   <p>
    We will run a
    <strong>
     small Random Forest
    </strong>
    (or shallow GBT) on the same leakage-free table. For Random Forest classification, we use
    <strong>
     Gini impurity
    </strong>
    as the splitting criterion:
   </p>
   <p>
    $$
\text{Gini} = 1 - \sum_{i=1}^{C} p_i^2
$$
   </p>
   <p>
    where
    <strong>
     C
    </strong>
    is the number of classes and
    <strong>
     p_i
    </strong>
    is the proportion of class
    <strong>
     i
    </strong>
    at a given node. For Gradient Boosting classification, we minimize
    <strong>
     cross-entropy loss
    </strong>
    :
   </p>
   <p>
    $$
L = -\sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i)]
$$
   </p>
   <p>
    The only purpose here is to show that the 12-month custom joined sample really contains
    <strong>
     nonlinear interactions
    </strong>
    — for example, that delays rise faster in the late afternoon
    <strong>
     at
    </strong>
    congested hubs
    <strong>
     under
    </strong>
    low visibility. RF/GBT on Spark have already been used at this scale in airline use cases, so we're staying inside the envelope.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.1.1-Preferred-approach:-two-stage-pipeline">
    5.1.1 Preferred approach: two-stage pipeline
    <a class="anchor-link" href="#5.1.1-Preferred-approach:-two-stage-pipeline">
     ¶
    </a>
   </h4>
   <p>
    For the actual project we prefer a
    <strong>
     two-stage
    </strong>
    design. This follows the pattern used in several recent flight-delay and transport-delay papers: first decide
    <strong>
     "will it be delayed?"
    </strong>
    , and only then estimate
    <strong>
     "by how much?"
    </strong>
    The reason is simple: only about
    <strong>
     20%
    </strong>
    of the flights are interesting from the delay-minutes point of view. If we train a regressor on everyone, 80% of the rows are "boring" and we waste compute on the cluster.
   </p>
   <p>
    Formally, our two-stage approach can be expressed as:
   </p>
   <p>
    $$
\text{Stage 1: } \hat{y}_{\text{binary}} = f_{\text{classifier}}(\mathbf{x})
$$
   </p>
   <p>
    $$
\text{Stage 2: } \hat{y}_{\text{minutes}} = \begin{cases} 
g_{\text{regressor}}(\mathbf{x}) &amp; \text{if } \hat{y}_{\text{binary}} = 1 \\
0 &amp; \text{if } \hat{y}_{\text{binary}} = 0
\end{cases}
$$
   </p>
   <p>
    In
    <strong>
     Stage 1
    </strong>
    we will keep the
    <strong>
     binary classification
    </strong>
    task. We will start with Logistic Regression to have a transparent baseline, and then add a
    <strong>
     tree-ensemble model
    </strong>
    (Random Forest / GBT / XGBoost-style, depending on what we run first in Databricks). All of these will be trained with
    <strong>
     time-series-aware cross-validation
    </strong>
    — "train on earlier months, validate on later months" — to make sure we never peek at future weather or future airport congestion. The
    <strong>
     primary metric
    </strong>
    here remains
    <strong>
     F(0.5)
    </strong>
    (precision is  more important than recall at this stage):
   </p>
   <p>
    $$
F_{0.5} = 1.25 \cdot \frac{\text{Precision} \cdot \text{Recall}}{0.25 \cdot \text{Precision} + \text{Recall}}
$$
   </p>
   <p>
    and we will also show a
    <strong>
     confusion matrix by carrier and by origin airport
    </strong>
    so we can see if the model is only good on the big hubs.
   </p>
   <p>
    In
    <strong>
     Stage 2
    </strong>
    we will run a
    <strong>
     regression model
    </strong>
    only on the flights that Stage 1 flags as
    <strong>
     delayed
    </strong>
    . Here we will move to the usual suspects that do well on tabular data:
    <strong>
     gradient-boosted regressor
    </strong>
    ,
    <strong>
     XGBoost regressor
    </strong>
    , or
    <strong>
     RF regressor
    </strong>
    . We will report
    <strong>
     MAE
    </strong>
    (because it is easy to read: "we're off by ~6 minutes"):
   </p>
   <p>
    $$
\text{MAE} = \frac{1}{n_{\text{delayed}}} \sum_{i: \hat{y}_{\text{binary},i} = 1} \lvert y_{\text{minutes},i} - \hat{y}_{\text{minutes},i} \rvert
$$
   </p>
   <p>
    and
    <strong>
     RMSE
    </strong>
    (because most papers report it):
   </p>
   <p>
    $$
\text{RMSE} = \sqrt{ \frac{1}{n_{\text{delayed}}} \sum_{i: \hat{y}_{\text{binary},i} = 1} (y_{\text{minutes},i} - \hat{y}_{\text{minutes},i})^2 }
$$
   </p>
   <p>
    The advantage of doing it this way is that we spend cluster time and feature-engineering effort
    <strong>
     only
    </strong>
    on the flights that actually need it.
   </p>
   <p>
    So the story we want in the notebook is:
    <strong>
     Phase 2 proves the 2 step process works  and is leakage-aware; Phase 3 adds the model tuning part.
    </strong>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.1.2--Cross-Validation">
    5.1.2  Cross Validation
    <a class="anchor-link" href="#5.1.2--Cross-Validation">
     ¶
    </a>
   </h4>
   <p>
    The method that we used for cross-validating the time-series model is cross-validation on a rolling basis. We started with a small subset of data for training purposes, forecast for the later data points, and then check the accuracy of the forecasted data points. The same forecasted data points are included as part of the next training dataset, and subsequent data points are forecasted. We will use a rolling window of fixed size because we have a very large dataset. For small datasets, it may be appropriate to use expanding window for cross validation.
   </p>
   <p>
    For Cross Validation, first, we will split the dataset based on time upfront, train data for first 6 months and test data for last 3 months. Next, we further split the dataset during the cross validation on a per fold basis. For each iteration, 6 months of data will be used for training and 1 month will be used for testing. So, for 1 year data we will use first 9 months as train data and last 3 months data for evaluation.
   </p>
   <p>
    raw_data → [Feature Selection] → [Encoding] → [Scaling] → preprocessed_data → [Time Series CV]
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="5.2-Alternative:-2-Stage-Architecture">
    5.2 Alternative: 2 Stage Architecture
    <a class="anchor-link" href="#5.2-Alternative:-2-Stage-Architecture">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_017_dbcfed09.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    The proposed 2 Stage Architecture proposed in Phase 1 did not show good performance for the second stage. This was because the second stage was only trained on the delayed flights. It was unable to learn the flight delay pattern. So, in Phase 2, we modified this architecture to train the Stage 2 regressor on all of the data so the model is able to learn the flight pattern better. In Phase 3, we attempted different ways of combining the results from the classifier and regressor to provide the best possible prediction on the delay value.
   </p>
   <p>
    Our flight delay prediction approach evolved through several phases, progressively simplifying the architecture while improving performance. We initially implemented a
    <strong>
     two-stage pipeline
    </strong>
    combining a classifier (Logistic Regression, RandomForest, GBTClassifier, or SparkXGBClassifier) to predict whether a delay would occur, followed by a regressor (Linear Regression, GBTRegressor, or SparkXGBRegressor) to predict delay duration, experimenting with various ensemble strategies including sequential filtered training, threshold-gated prediction, and probability-weighted combinations. Finding that the classifier provided minimal benefit, we transitioned to a
    <strong>
     regression-only ensemble
    </strong>
    approach using two SparkXGBRegressor models—one trained with sample weights (1x/2x/2.5x for delays ≤60min/60-120min/&gt;120min) to emphasize severe delays, and one without weights for balanced predictions—combined using Max, Min, or Average strategies, with deeper trees (max_depth=11) and regularization (reg_alpha=0.2, reg_lambda=1.0) to prevent overfitting. The Max ensemble achieved the best RMSE (41.69 minutes) by taking the higher prediction from both models, effectively capturing severe delays, while the Min ensemble achieved the best MAE (11.92 minutes) by optimizing for typical cases. Finally, to enable
    <strong>
     binary classification evaluation
    </strong>
    against the DOT standard (DEP_DEL15), we converted regression outputs to binary predictions using a 15-minute threshold, achieving F1=0.668, F2=0.697, and AuPRC=0.722, demonstrating that a well-tuned regression model can effectively serve both continuous delay prediction and binary delay classification tasks without requiring a separate classifier.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    %md
   </p>
   <h3 id="5.2.1-Summary-of-2-Stage-and-Regression-only-Experiments">
    5.2.1 Summary of 2 Stage and Regression only Experiments
    <a class="anchor-link" href="#5.2.1-Summary-of-2-Stage-and-Regression-only-Experiments">
     ¶
    </a>
   </h3>
   <p>
    NOTE:
Phase 3 Experiments were conducted on a cluster with following configuration: 	8× m5d.2xlarge (32GB, 8 cores)
   </p>
   <table>
    <thead>
     <tr>
      <th style="text-align:center">
       Exp #
      </th>
      <th style="text-align:center">
       Phase
      </th>
      <th>
       Classifier Model
      </th>
      <th>
       Regression Model
      </th>
      <th>
       Train Data
      </th>
      <th>
       Test Data
      </th>
      <th>
       Balance Strategy
      </th>
      <th>
       Ensemble Prediction Strategy
      </th>
      <th>
       Train: [RMSE, MAE] (min.)
      </th>
      <th>
       Test: [RMSE, MAE] (min.)
      </th>
      <th>
       Binary Metrics (F1, F2, AuPRC)
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:center">
       1
      </td>
      <td style="text-align:center">
       1
      </td>
      <td>
       Logistic Regression
      </td>
      <td>
       Linear Regression
      </td>
      <td>
       2015 Q1,2
      </td>
      <td>
       2015 Q3
      </td>
      <td>
       Class weights
      </td>
      <td>
       Sequential (Filtered Training)
      </td>
      <td>
       [72.11, 43.69]
      </td>
      <td>
       [97.49, 53.59]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       2
      </td>
      <td style="text-align:center">
       2
      </td>
      <td>
       RandomForest
      </td>
      <td>
       GBTRegressor
      </td>
      <td>
       2015 Q1,2,3
      </td>
      <td>
       2015 Q4
      </td>
      <td>
       Undersample (0.5)
      </td>
      <td>
       Sequential (Filtered Inference)
      </td>
      <td>
       [19.43, 11.15]
      </td>
      <td>
       [74.22, 41.97]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       3
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       RandomForest
      </td>
      <td>
       GBTRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (0.5)
      </td>
      <td>
       Threshold-Gated
      </td>
      <td>
       [37.74, 10.74]
      </td>
      <td>
       [45.38, 12.24]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       4
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       RandomForest
      </td>
      <td>
       GBTRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (0.5)
      </td>
      <td>
       Regression only
      </td>
      <td>
       [37.50, 10.96]
      </td>
      <td>
       [45.16, 12.43]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       5
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       RandomForest
      </td>
      <td>
       GBTRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (0.5)
      </td>
      <td>
       Probability-weighted
      </td>
      <td>
       [40.69, 11.73]
      </td>
      <td>
       [48.24, 13.33]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       6
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       GBTClassifier
      </td>
      <td>
       GBTRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (0.5)
      </td>
      <td>
       Threshold-Gated
      </td>
      <td>
       [38.48, 10.65]
      </td>
      <td>
       [46.21, 12.19]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       7
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       GBTClassifier
      </td>
      <td>
       GBTRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (0.5)
      </td>
      <td>
       Regression only
      </td>
      <td>
       [37.88, 11.07]
      </td>
      <td>
       [45.58, 12.57]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       8
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       GBTClassifier
      </td>
      <td>
       GBTRegressor (weighted)
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (0.5)
      </td>
      <td>
       Regression only
      </td>
      <td>
       [48.11, 17.97]
      </td>
      <td>
       [42.99, 12.89]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       9
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       SparkXGBClassifier
      </td>
      <td>
       SparkXGBRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (1.0)
      </td>
      <td>
       Threshold-Gated
      </td>
      <td>
       [35.18, 10.72]
      </td>
      <td>
       [42.85, 12.07]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       10
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       SparkXGBClassifier
      </td>
      <td>
       SparkXGBRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (1.0)
      </td>
      <td>
       Regression only
      </td>
      <td>
       [35.16, 10.95]
      </td>
      <td>
       [42.83, 12.30]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       11
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       SparkXGBClassifier
      </td>
      <td>
       SparkXGBRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (1.0)
      </td>
      <td>
       Probability-weighted
      </td>
      <td>
       [36.35, 10.15]
      </td>
      <td>
       [44.14, 11.66]
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       12
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       -
      </td>
      <td>
       SparkXGBRegressor (weighted)
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (1.0) + Sample weights
      </td>
      <td>
       Regression only
      </td>
      <td>
       [54.85, 22.80]
      </td>
      <td>
       [41.79, 13.20]
      </td>
      <td>
       [0.659, 0.697, 0.720]
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       13
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       -
      </td>
      <td>
       SparkXGBRegressor
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (1.0)
      </td>
      <td>
       Regression only
      </td>
      <td>
       -
      </td>
      <td>
       [42.40, 11.93]
      </td>
      <td>
       [0.663, 0.634, 0.735]
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       14
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       -
      </td>
      <td>
       Ensemble (Weighted + Unweighted)
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (1.0)
      </td>
      <td>
       Average
      </td>
      <td>
       -
      </td>
      <td>
       [42.05, 12.40]
      </td>
      <td>
       [0.668, 0.666, 0.731]
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       15
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       -
      </td>
      <td>
       Ensemble (Weighted + Unweighted)
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (1.0)
      </td>
      <td>
       <strong>
        Max
       </strong>
      </td>
      <td>
       -
      </td>
      <td>
       [
       <strong>
        41.69
       </strong>
       , 13.21]
      </td>
      <td>
       [0.659, 0.697, 0.722]
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       16
      </td>
      <td style="text-align:center">
       3
      </td>
      <td>
       -
      </td>
      <td>
       Ensemble (Weighted + Unweighted)
      </td>
      <td>
       2015-2018
      </td>
      <td>
       2019
      </td>
      <td>
       Undersample (1.0)
      </td>
      <td>
       Min
      </td>
      <td>
       -
      </td>
      <td>
       [42.50,
       <strong>
        11.92
       </strong>
       ]
      </td>
      <td>
       [0.663, 0.633, 0.734]
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Summary-of-Regression-only-Experiments">
    Summary of Regression only Experiments
    <a class="anchor-link" href="#Summary-of-Regression-only-Experiments">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th style="text-align:center">
       Exp #
      </th>
      <th>
       Model
      </th>
      <th>
       Strategy
      </th>
      <th>
       Test RMSE
      </th>
      <th>
       Test MAE
      </th>
      <th>
       F1
      </th>
      <th>
       F2
      </th>
      <th>
       AuPRC
      </th>
      <th>
       Best For
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:center">
       12
      </td>
      <td>
       XGB (weighted)
      </td>
      <td>
       Regression
      </td>
      <td>
       41.79
      </td>
      <td>
       13.20
      </td>
      <td>
       0.659
      </td>
      <td>
       0.697
      </td>
      <td>
       0.720
      </td>
      <td>
       Recall
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       13
      </td>
      <td>
       XGB (unweighted)
      </td>
      <td>
       Regression
      </td>
      <td>
       42.40
      </td>
      <td>
       11.93
      </td>
      <td>
       0.663
      </td>
      <td>
       0.634
      </td>
      <td>
       <strong>
        0.735
       </strong>
      </td>
      <td>
       Precision, AuPRC
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       14
      </td>
      <td>
       Ensemble
      </td>
      <td>
       Average
      </td>
      <td>
       42.05
      </td>
      <td>
       12.40
      </td>
      <td>
       <strong>
        0.668
       </strong>
      </td>
      <td>
       0.666
      </td>
      <td>
       0.731
      </td>
      <td>
       <strong>
        Best F1
       </strong>
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       15
      </td>
      <td>
       Ensemble
      </td>
      <td>
       Max
      </td>
      <td>
       <strong>
        41.69
       </strong>
      </td>
      <td>
       13.21
      </td>
      <td>
       0.659
      </td>
      <td>
       <strong>
        0.697
       </strong>
      </td>
      <td>
       0.722
      </td>
      <td>
       <strong>
        Best RMSE, F2
       </strong>
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       16
      </td>
      <td>
       Ensemble
      </td>
      <td>
       Min
      </td>
      <td>
       42.50
      </td>
      <td>
       <strong>
        11.92
       </strong>
      </td>
      <td>
       0.663
      </td>
      <td>
       0.633
      </td>
      <td>
       0.734
      </td>
      <td>
       <strong>
        Best MAE
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h4 id="Key-Findings">
    Key Findings
    <a class="anchor-link" href="#Key-Findings">
     ¶
    </a>
   </h4>
   <table>
    <thead>
     <tr>
      <th>
       Metric
      </th>
      <th>
       Best Experiment
      </th>
      <th>
       Value
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Best RMSE
       </strong>
      </td>
      <td>
       Exp #15 (Ensemble Max)
      </td>
      <td>
       <strong>
        41.69 min
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Best MAE
       </strong>
      </td>
      <td>
       Exp #16 (Ensemble Min)
      </td>
      <td>
       <strong>
        11.92 min
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Best F1
       </strong>
      </td>
      <td>
       Exp #14 (Ensemble Average)
      </td>
      <td>
       <strong>
        0.668
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Best F2
       </strong>
      </td>
      <td>
       Exp #15 (Ensemble Max)
      </td>
      <td>
       <strong>
        0.697
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Best AuPRC
       </strong>
      </td>
      <td>
       Exp #13 (Unweighted)
      </td>
      <td>
       <strong>
        0.735
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <hr/>
   <p>
    Desciption of terms used in table:
   </p>
   <ul>
    <li>
     Sequential (Filtered Training): Regressor trained only on delayed samples
    </li>
    <li>
     Sequential (Filtered Inference): Regressor trained on all data, predictions gated by classifier
    </li>
    <li>
     Threshold-Gated prediction: Returns the predicted delay value when the probability exceeds the specified threshold, otherwise returns zero
    </li>
    <li>
     Probability-weighted: P(delay) × predicted value
    </li>
    <li>
     Weighted Model : Regression Model trained using weights on delay value
    </li>
   </ul>
   <hr/>
   <h5 id="Key-Findings">
    Key Findings
    <a class="anchor-link" href="#Key-Findings">
     ¶
    </a>
   </h5>
   <h6 id="Best-Performers-(Test-RMSE)">
    Best Performers (Test RMSE)
    <a class="anchor-link" href="#Best-Performers-(Test-RMSE)">
     ¶
    </a>
   </h6>
   <table>
    <thead>
     <tr>
      <th style="text-align:center">
       Rank
      </th>
      <th style="text-align:center">
       Exp #
      </th>
      <th>
       Model Combination
      </th>
      <th>
       Strategy
      </th>
      <th>
       Test RMSE
      </th>
      <th>
       Test MAE
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:center">
       1
      </td>
      <td style="text-align:center">
       15
      </td>
      <td>
       XGBRegressor Ensemble (Weighted + Unweighted)
      </td>
      <td>
       Max
      </td>
      <td>
       <strong>
        41.69
       </strong>
      </td>
      <td>
       13.21
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       2
      </td>
      <td style="text-align:center">
       12
      </td>
      <td>
       XGBRegressor (sample weighted)
      </td>
      <td>
       Regression only
      </td>
      <td>
       41.79
      </td>
      <td>
       13.20
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       3
      </td>
      <td style="text-align:center">
       14
      </td>
      <td>
       XGBRegressor Ensemble (Weighted + Unweighted)
      </td>
      <td>
       Average
      </td>
      <td>
       42.05
      </td>
      <td>
       12.40
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       4
      </td>
      <td style="text-align:center">
       13
      </td>
      <td>
       XGBRegressor (unweighted)
      </td>
      <td>
       Regression only
      </td>
      <td>
       42.40
      </td>
      <td>
       11.93
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       5
      </td>
      <td style="text-align:center">
       10
      </td>
      <td>
       XGBClassifier + XGBRegressor
      </td>
      <td>
       Regression only
      </td>
      <td>
       42.83
      </td>
      <td>
       12.30
      </td>
     </tr>
    </tbody>
   </table>
   <h6 id="Best-Performers-(Test-MAE)">
    Best Performers (Test MAE)
    <a class="anchor-link" href="#Best-Performers-(Test-MAE)">
     ¶
    </a>
   </h6>
   <table>
    <thead>
     <tr>
      <th style="text-align:center">
       Rank
      </th>
      <th style="text-align:center">
       Exp #
      </th>
      <th>
       Model Combination
      </th>
      <th>
       Strategy
      </th>
      <th>
       Test RMSE
      </th>
      <th>
       Test MAE
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:center">
       1
      </td>
      <td style="text-align:center">
       16
      </td>
      <td>
       XGBRegressor Ensemble (Weighted + Unweighted)
      </td>
      <td>
       Min
      </td>
      <td>
       42.50
      </td>
      <td>
       <strong>
        11.92
       </strong>
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       2
      </td>
      <td style="text-align:center">
       13
      </td>
      <td>
       XGBRegressor (unweighted)
      </td>
      <td>
       Regression only
      </td>
      <td>
       42.40
      </td>
      <td>
       <strong>
        11.93
       </strong>
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       3
      </td>
      <td style="text-align:center">
       11
      </td>
      <td>
       XGBClassifier + XGBRegressor
      </td>
      <td>
       Probability-weighted
      </td>
      <td>
       44.14
      </td>
      <td>
       <strong>
        11.66
       </strong>
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       4
      </td>
      <td style="text-align:center">
       9
      </td>
      <td>
       XGBClassifier + XGBRegressor
      </td>
      <td>
       Threshold-Gated
      </td>
      <td>
       42.85
      </td>
      <td>
       12.07
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       5
      </td>
      <td style="text-align:center">
       14
      </td>
      <td>
       XGBRegressor Ensemble (Weighted + Unweighted)
      </td>
      <td>
       Average
      </td>
      <td>
       42.05
      </td>
      <td>
       12.40
      </td>
     </tr>
    </tbody>
   </table>
   <h6 id="Best-Performers-(Binary-Classification---vs-DEP_DEL15)">
    Best Performers (Binary Classification - vs DEP_DEL15)
    <a class="anchor-link" href="#Best-Performers-(Binary-Classification---vs-DEP_DEL15)">
     ¶
    </a>
   </h6>
   <table>
    <thead>
     <tr>
      <th style="text-align:center">
       Rank
      </th>
      <th style="text-align:center">
       Exp #
      </th>
      <th>
       Model Combination
      </th>
      <th>
       Strategy
      </th>
      <th>
       F1
      </th>
      <th>
       F2
      </th>
      <th>
       AuPRC
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:center">
       1
      </td>
      <td style="text-align:center">
       14
      </td>
      <td>
       XGBRegressor Ensemble
      </td>
      <td>
       Average
      </td>
      <td>
       <strong>
        0.668
       </strong>
      </td>
      <td>
       0.666
      </td>
      <td>
       0.731
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       2
      </td>
      <td style="text-align:center">
       13/16
      </td>
      <td>
       XGBRegressor (Unweighted) / Ensemble Min
      </td>
      <td>
       Regression / Min
      </td>
      <td>
       0.663
      </td>
      <td>
       0.634
      </td>
      <td>
       <strong>
        0.735
       </strong>
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       3
      </td>
      <td style="text-align:center">
       15
      </td>
      <td>
       XGBRegressor Ensemble
      </td>
      <td>
       Max
      </td>
      <td>
       0.659
      </td>
      <td>
       <strong>
        0.697
       </strong>
      </td>
      <td>
       0.722
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       4
      </td>
      <td style="text-align:center">
       12
      </td>
      <td>
       XGBRegressor (sample weighted)
      </td>
      <td>
       Regression only
      </td>
      <td>
       0.659
      </td>
      <td>
       0.697
      </td>
      <td>
       0.720
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Evolution-Across-Phases">
    Evolution Across Phases
    <a class="anchor-link" href="#Evolution-Across-Phases">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th style="text-align:center">
       Phase
      </th>
      <th>
       Key Changes
      </th>
      <th>
       Impact
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:center">
       1
      </td>
      <td>
       Baseline: Logistic + Linear, class weights
      </td>
      <td>
       High error (RMSE: 97.49)
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       2
      </td>
      <td>
       Tree-based models, undersampling
      </td>
      <td>
       Improved but overfit (Train: 19.43, Test: 74.22)
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       3
      </td>
      <td>
       Full data (2015-2018), XGBoost, 2-stage pipeline
      </td>
      <td>
       Good results (Test RMSE: ~43)
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       3
      </td>
      <td>
       Sample weighting, deeper trees (depth=11), ensemble strategies
      </td>
      <td>
       <strong>
        Best results (Test RMSE: 41.69)
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Key-Insights">
    Key Insights
    <a class="anchor-link" href="#Key-Insights">
     ¶
    </a>
   </h5>
   <ol>
    <li>
     <strong>
      Ensemble Max achieves best RMSE (41.69):
     </strong>
     Combining weighted and unweighted XGBoost models with Max strategy reduces RMSE by 2.7% vs previous best
    </li>
    <li>
     <strong>
      Ensemble Min achieves best MAE (11.92):
     </strong>
     Taking the lower prediction optimizes for average-case performance
    </li>
    <li>
     <strong>
      Trade-off between RMSE and MAE:
     </strong>
     Max strategy favors RMSE (severe delays), Min strategy favors MAE (typical delays)
    </li>
    <li>
     <strong>
      Sample weighting improves generalization:
     </strong>
     Weighting severe delays (2x-2.5x) helps capture extreme cases
    </li>
    <li>
     <strong>
      Deeper trees with regularization:
     </strong>
     max_depth=11 with reg_alpha=0.2, reg_lambda=1.0 prevents overfitting
    </li>
    <li>
     <strong>
      Two-stage classifier no longer needed:
     </strong>
     Direct regression with ensemble outperforms classifier + regressor pipeline
    </li>
    <li>
     <strong>
      Binary classification from regression:
     </strong>
     Converting regression output to binary achieves F2=0.697, AuPRC=0.722
    </li>
   </ol>
   <hr/>
   <h5 id="Recommended-Model-Configuration">
    Recommended Model Configuration
    <a class="anchor-link" href="#Recommended-Model-Configuration">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th>
       Use Case
      </th>
      <th>
       Strategy
      </th>
      <th>
       Model
      </th>
      <th>
       Test RMSE
      </th>
      <th>
       Test MAE
      </th>
      <th>
       F2
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Minimize worst-case errors
       </strong>
      </td>
      <td>
       Ensemble Max
      </td>
      <td>
       Weighted + Unweighted XGB
      </td>
      <td>
       <strong>
        41.69
       </strong>
      </td>
      <td>
       13.21
      </td>
      <td>
       <strong>
        0.697
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Minimize average errors
       </strong>
      </td>
      <td>
       Ensemble Min
      </td>
      <td>
       Weighted + Unweighted XGB
      </td>
      <td>
       42.50
      </td>
      <td>
       <strong>
        11.92
       </strong>
      </td>
      <td>
       0.633
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Balanced performance
       </strong>
      </td>
      <td>
       Ensemble Average
      </td>
      <td>
       Weighted + Unweighted XGB
      </td>
      <td>
       42.05
      </td>
      <td>
       12.40
      </td>
      <td>
       0.666
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Model-Parameters-(Regression-only)">
    Model Parameters (Regression only)
    <a class="anchor-link" href="#Model-Parameters-(Regression-only)">
     ¶
    </a>
   </h5>
   <div class="highlight">
    <pre><span></span><span class="c1"># XGBoost Configuration</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="mi">11</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">reg_alpha</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">reg_lambda</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">subsample</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">colsample_bytree</span> <span class="o">=</span> <span class="mf">0.8</span>

<span class="c1"># Sample Weights (weighted model only)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># if delay ≤ 60 min</span>
<span class="n">weight</span> <span class="o">=</span> <span class="mf">2.0</span>  <span class="c1"># if 60 &lt; delay ≤ 120 min</span>
<span class="n">weight</span> <span class="o">=</span> <span class="mf">2.5</span>  <span class="c1"># if delay &gt; 120 min</span>

<span class="c1"># Ensemble Strategies</span>
<span class="n">Max</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">pred_weighted</span><span class="p">,</span> <span class="n">pred_unweighted</span><span class="p">)</span>  <span class="c1"># Best for RMSE</span>
<span class="n">Min</span><span class="p">:</span> <span class="nb">min</span><span class="p">(</span><span class="n">pred_weighted</span><span class="p">,</span> <span class="n">pred_unweighted</span><span class="p">)</span>  <span class="c1"># Best for MAE</span>
<span class="n">Avg</span><span class="p">:</span> <span class="p">(</span><span class="n">pred_weighted</span> <span class="o">+</span> <span class="n">pred_unweighted</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>  <span class="c1"># Balanced</span>
</pre>
   </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.2.2-Regression-Value-to-Binary-Classification-Results-Summary">
    5.2.2 Regression Value to Binary Classification Results Summary
    <a class="anchor-link" href="#5.2.2-Regression-Value-to-Binary-Classification-Results-Summary">
     ¶
    </a>
   </h3>
   <h4 id="Overall-Model-Performance">
    Overall Model Performance
    <a class="anchor-link" href="#Overall-Model-Performance">
     ¶
    </a>
   </h4>
   <p>
    The ensemble model achieves
    <strong>
     86.1% accuracy
    </strong>
    in predicting whether a flight will be delayed by 15 minutes or more (DEP_DEL15). This is a strong result given the inherent unpredictability of flight delays.
   </p>
   <hr/>
   <h4 id="Core-Metrics-Interpretation">
    Core Metrics Interpretation
    <a class="anchor-link" href="#Core-Metrics-Interpretation">
     ¶
    </a>
   </h4>
   <table>
    <thead>
     <tr>
      <th>
       Metric
      </th>
      <th>
       Value
      </th>
      <th>
       Meaning
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Accuracy
       </strong>
      </td>
      <td>
       86.1%
      </td>
      <td>
       Model correctly classifies 86% of all flights
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Precision
       </strong>
      </td>
      <td>
       60.5%
      </td>
      <td>
       When model predicts a delay, it's correct 60.5% of the time
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Recall
       </strong>
      </td>
      <td>
       72.5%
      </td>
      <td>
       Model catches 72.5% of all actual delays
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        F1 Score
       </strong>
      </td>
      <td>
       65.9%
      </td>
      <td>
       Balanced measure of precision and recall
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        F2 Score
       </strong>
      </td>
      <td>
       69.7%
      </td>
      <td>
       Recall-weighted score (prioritizes catching delays)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        AuPRC
       </strong>
      </td>
      <td>
       72.3%
      </td>
      <td>
       Overall ranking quality of delay probability
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Specificity
       </strong>
      </td>
      <td>
       89.2%
      </td>
      <td>
       Model correctly identifies 89.2% of on-time flights
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Confusion-Matrix-Analysis">
    Confusion Matrix Analysis
    <a class="anchor-link" href="#Confusion-Matrix-Analysis">
     ¶
    </a>
   </h5>
   <pre><code>                      Predicted
                   No Delay  |  Delay
Actual No Delay:  5,268,354  |  639,191   (89.2% correct)
Actual Delay:       372,284  |  979,178   (72.5% correct)
</code></pre>
   <p>
    <strong>
     Key Observations:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      True Negatives (5.27M):
     </strong>
     Correctly predicted on-time flights
    </li>
    <li>
     <strong>
      True Positives (979K):
     </strong>
     Correctly predicted delays
    </li>
    <li>
     <strong>
      False Positives (639K):
     </strong>
     Predicted delay but flight was on-time (unnecessary alerts)
    </li>
    <li>
     <strong>
      False Negatives (372K):
     </strong>
     Missed delays (passengers caught off-guard)
    </li>
   </ul>
   <hr/>
   <h5 id="Ensemble-Strategy-Comparison">
    Ensemble Strategy Comparison
    <a class="anchor-link" href="#Ensemble-Strategy-Comparison">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th>
       Strategy
      </th>
      <th>
       Best For
      </th>
      <th>
       Accuracy
      </th>
      <th>
       Precision
      </th>
      <th>
       Recall
      </th>
      <th>
       F1
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Model 2: Unweighted
       </strong>
      </td>
      <td>
       Precision
      </td>
      <td>
       <strong>
        88.3%
       </strong>
      </td>
      <td>
       <strong>
        71.8%
       </strong>
      </td>
      <td>
       61.5%
      </td>
      <td>
       66.3%
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Ensemble: Average
       </strong>
      </td>
      <td>
       Balance
      </td>
      <td>
       87.7%
      </td>
      <td>
       67.2%
      </td>
      <td>
       66.4%
      </td>
      <td>
       <strong>
        66.8%
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Model 1: Weighted
       </strong>
      </td>
      <td>
       Recall
      </td>
      <td>
       86.1%
      </td>
      <td>
       60.5%
      </td>
      <td>
       <strong>
        72.4%
       </strong>
      </td>
      <td>
       65.9%
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Ensemble: Max
       </strong>
      </td>
      <td>
       Recall
      </td>
      <td>
       86.1%
      </td>
      <td>
       60.5%
      </td>
      <td>
       <strong>
        72.5%
       </strong>
      </td>
      <td>
       65.9%
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Key Finding:
    </strong>
    There's a clear trade-off:
   </p>
   <ul>
    <li>
     <strong>
      Weighted model / Max ensemble:
     </strong>
     Better at catching delays (high recall: 72.5%)
    </li>
    <li>
     <strong>
      Unweighted model / Min ensemble:
     </strong>
     Fewer false alarms (high precision: 71.8%)
    </li>
    <li>
     <strong>
      Average ensemble:
     </strong>
     Best balance (highest F1: 66.8%)
    </li>
   </ul>
   <hr/>
   <h5 id="Optimal-Threshold-Analysis">
    Optimal Threshold Analysis
    <a class="anchor-link" href="#Optimal-Threshold-Analysis">
     ¶
    </a>
   </h5>
   <p>
    The default threshold of 15 minutes (matching DEP_DEL15 definition) may not be optimal:
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Threshold
      </th>
      <th>
       Precision
      </th>
      <th>
       Recall
      </th>
      <th>
       F1
      </th>
      <th>
       F2
      </th>
      <th>
       Best For
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       8 min
      </td>
      <td>
       44.5%
      </td>
      <td>
       86.3%
      </td>
      <td>
       58.7%
      </td>
      <td>
       <strong>
        72.7%
       </strong>
      </td>
      <td>
       Catching most delays
      </td>
     </tr>
     <tr>
      <td>
       15 min
      </td>
      <td>
       60.5%
      </td>
      <td>
       72.5%
      </td>
      <td>
       65.9%
      </td>
      <td>
       69.7%
      </td>
      <td>
       Default
      </td>
     </tr>
     <tr>
      <td>
       18 min
      </td>
      <td>
       65.3%
      </td>
      <td>
       67.7%
      </td>
      <td>
       <strong>
        66.5%
       </strong>
      </td>
      <td>
       67.2%
      </td>
      <td>
       Best F1 balance
      </td>
     </tr>
     <tr>
      <td>
       25 min
      </td>
      <td>
       73.7%
      </td>
      <td>
       57.2%
      </td>
      <td>
       64.4%
      </td>
      <td>
       59.9%
      </td>
      <td>
       Fewer false alarms
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Recommendations:
    </strong>
   </p>
   <ul>
    <li>
     Use
     <strong>
      8-minute threshold
     </strong>
     if priority is catching delays (F2 optimized)
    </li>
    <li>
     Use
     <strong>
      18-minute threshold
     </strong>
     for best overall balance (F1 optimized)
    </li>
    <li>
     Use
     <strong>
      25+ minute threshold
     </strong>
     if false alarms are costly (precision optimized)
    </li>
   </ul>
   <hr/>
   <h5 id="Practical-Implications">
    Practical Implications
    <a class="anchor-link" href="#Practical-Implications">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     For Airlines/Operations:
    </strong>
   </p>
   <ul>
    <li>
     Model catches
     <strong>
      72.5% of delays
     </strong>
     before they happen
    </li>
    <li>
     <strong>
      27.5% of delays are missed
     </strong>
     (372K flights) - room for improvement
    </li>
    <li>
     <strong>
      639K false alarms
     </strong>
     - may cause unnecessary resource allocation
    </li>
   </ul>
   <p>
    <strong>
     For Passengers:
    </strong>
   </p>
   <ul>
    <li>
     If model predicts delay:
     <strong>
      60.5% chance
     </strong>
     it will actually be delayed
    </li>
    <li>
     If model predicts on-time:
     <strong>
      93.4% chance
     </strong>
     it will be on-time (high NPV)
    </li>
   </ul>
   <hr/>
   <h5 id="Summary-Statement">
    Summary Statement
    <a class="anchor-link" href="#Summary-Statement">
     ¶
    </a>
   </h5>
   <blockquote>
    <p>
     The regression-based ensemble model, when converted to binary delay prediction, achieves
     <strong>
      86% accuracy
     </strong>
     with a
     <strong>
      72.5% recall
     </strong>
     rate for catching delays. The weighted model excels at identifying delays (fewer missed), while the unweighted model excels at precision (fewer false alarms). For operational use, an
     <strong>
      18-minute prediction threshold
     </strong>
     provides the best F1 balance, while an
     <strong>
      8-minute threshold
     </strong>
     maximizes delay detection at the cost of more false positives.
    </p>
   </blockquote>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_018_0ece016f.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.2.3-Error-Analysis">
    5.2.3 Error Analysis
    <a class="anchor-link" href="#5.2.3-Error-Analysis">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Delay-Distrubtion-by-Value">
    Delay Distrubtion by Value
    <a class="anchor-link" href="#Delay-Distrubtion-by-Value">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_019_b4d31232.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Weighted-Model-Performance-by-Delay-Magnitude">
    Weighted Model Performance by Delay Magnitude
    <a class="anchor-link" href="#Weighted-Model-Performance-by-Delay-Magnitude">
     ¶
    </a>
   </h5>
   <p>
    The model shows a
    <strong>
     clear asymmetric error pattern
    </strong>
    : it overpredicts small delays and severely underpredicts large delays.
   </p>
   <h5 id="Performance-Breakdown">
    Performance Breakdown
    <a class="anchor-link" href="#Performance-Breakdown">
     ¶
    </a>
   </h5>
   <p>
    Well-Calibrated Range (11-30 min delays):
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Delay Bin
      </th>
      <th>
       Actual
      </th>
      <th>
       Predicted
      </th>
      <th>
       Bias
      </th>
      <th>
       Observation
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       11-15 min
      </td>
      <td>
       12.3
      </td>
      <td>
       12.3
      </td>
      <td>
       0.0
      </td>
      <td>
       Perfect calibration
      </td>
     </tr>
     <tr>
      <td>
       16-20 min
      </td>
      <td>
       17.9
      </td>
      <td>
       20.4
      </td>
      <td>
       +2.5
      </td>
      <td>
       Slight overprediction
      </td>
     </tr>
     <tr>
      <td>
       21-30 min
      </td>
      <td>
       25.2
      </td>
      <td>
       24.9
      </td>
      <td>
       -0.2
      </td>
      <td>
       Nearly perfect
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    Overprediction Zone (0-10 min delays):
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Delay Bin
      </th>
      <th>
       Actual
      </th>
      <th>
       Predicted
      </th>
      <th>
       Bias
      </th>
      <th>
       Issue
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       On-time
      </td>
      <td>
       0.0
      </td>
      <td>
       3.5
      </td>
      <td>
       +3.5
      </td>
      <td>
       Predicts delay when none exists
      </td>
     </tr>
     <tr>
      <td>
       1-5 min
      </td>
      <td>
       2.7
      </td>
      <td>
       6.4
      </td>
      <td>
       +3.7
      </td>
      <td>
       Overpredicts minor delays
      </td>
     </tr>
     <tr>
      <td>
       6-10 min
      </td>
      <td>
       7.4
      </td>
      <td>
       8.7
      </td>
      <td>
       +1.3
      </td>
      <td>
       Slight overprediction
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    Severe Underprediction Zone (31+ min delays):
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Delay Bin
      </th>
      <th>
       Actual
      </th>
      <th>
       Predicted
      </th>
      <th>
       Bias
      </th>
      <th>
       Issue
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       31-45 min
      </td>
      <td>
       37.4
      </td>
      <td>
       30.9
      </td>
      <td>
       -6.5
      </td>
      <td>
       Begins underpredicting
      </td>
     </tr>
     <tr>
      <td>
       46-60 min
      </td>
      <td>
       52.1
      </td>
      <td>
       36.8
      </td>
      <td>
       -15.3
      </td>
      <td>
       Significant gap
      </td>
     </tr>
     <tr>
      <td>
       61-90 min
      </td>
      <td>
       73.3
      </td>
      <td>
       43.8
      </td>
      <td>
       -29.5
      </td>
      <td>
       Large underprediction
      </td>
     </tr>
     <tr>
      <td>
       91-120 min
      </td>
      <td>
       103.8
      </td>
      <td>
       51.8
      </td>
      <td>
       -52.0
      </td>
      <td>
       Severe underprediction
      </td>
     </tr>
     <tr>
      <td>
       121-180 min
      </td>
      <td>
       145.1
      </td>
      <td>
       57.2
      </td>
      <td>
       -87.8
      </td>
      <td>
       Critical gap
      </td>
     </tr>
     <tr>
      <td>
       &gt;180 min
      </td>
      <td>
       314.8
      </td>
      <td>
       65.8
      </td>
      <td>
       -249.0
      </td>
      <td>
       Catastrophic miss
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Key-Takeaways">
    Key Takeaways
    <a class="anchor-link" href="#Key-Takeaways">
     ¶
    </a>
   </h5>
   <ol>
    <li>
     <p>
      Sweet spot exists: Model performs best for delays between 11-30 minutes (near-zero bias)
     </p>
    </li>
    <li>
     <p>
      Regression to the mean: Model predictions cluster around 30-65 minutes regardless of actual delay severity
     </p>
    </li>
    <li>
     <p>
      Extreme delays are problematic: For delays &gt;3 hours, model only predicts ~66 minutes - missing by 4+ hours on average
     </p>
    </li>
    <li>
     <p>
      Conservative predictions: Model appears to "cap" predictions around 65 minutes, unable to capture tail events
     </p>
    </li>
    <li>
     <p>
      Practical impact:
     </p>
     <ul>
      <li>
       <strong>
        For passengers:
       </strong>
       Minor delays ( less than 15 min) are not conidered as actual delay. So minimal impact
      </li>
      <li>
       <strong>
        For operations:
       </strong>
       Cannot rely on model for severe delay scenarios
      </li>
     </ul>
    </li>
   </ol>
   <h5 id="Recommendation">
    Recommendation
    <a class="anchor-link" href="#Recommendation">
     ¶
    </a>
   </h5>
   <p>
    Consider a separate model or adjustment factor for severe delays (&gt;45 min), or implement prediction intervals that widen for longer predicted delays.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Worst-Airports-and-Carriers-by-error">
    Worst Airports and Carriers by error
    <a class="anchor-link" href="#Worst-Airports-and-Carriers-by-error">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_020_d69e8dc9.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Key-Insights-Summary">
    Key Insights Summary
    <a class="anchor-link" href="#Key-Insights-Summary">
     ¶
    </a>
   </h5>
   <h5 id="Worst-Airports">
    Worst Airports
    <a class="anchor-link" href="#Worst-Airports">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th>
       Airport
      </th>
      <th>
       Avg Actual
      </th>
      <th>
       Avg Predicted
      </th>
      <th>
       Gap
      </th>
      <th>
       RMSE
      </th>
      <th>
       Issue
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       EGE (Eagle, CO)
      </td>
      <td>
       31.2
      </td>
      <td>
       13.4
      </td>
      <td>
       -17.8
      </td>
      <td>
       110.8
      </td>
      <td>
       Highest RMSE - mountain airport
      </td>
     </tr>
     <tr>
      <td>
       ACK (Nantucket)
      </td>
      <td>
       32.7
      </td>
      <td>
       16.3
      </td>
      <td>
       -16.4
      </td>
      <td>
       84.0
      </td>
      <td>
       Small island airport
      </td>
     </tr>
     <tr>
      <td>
       ASE (Aspen)
      </td>
      <td>
       29.1
      </td>
      <td>
       13.9
      </td>
      <td>
       -15.2
      </td>
      <td>
       85.8
      </td>
      <td>
       Mountain weather
      </td>
     </tr>
     <tr>
      <td>
       HYS (Hays, KS)
      </td>
      <td>
       29.7
      </td>
      <td>
       11.6
      </td>
      <td>
       -18.1
      </td>
      <td>
       103.5
      </td>
      <td>
       Severe underprediction
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Worst-Carriers">
    Worst Carriers
    <a class="anchor-link" href="#Worst-Carriers">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th>
       Carrier
      </th>
      <th>
       Avg Actual
      </th>
      <th>
       Avg Predicted
      </th>
      <th>
       Gap
      </th>
      <th>
       RMSE
      </th>
      <th>
       Issue
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       EV (ExpressJet)
      </td>
      <td>
       21.5
      </td>
      <td>
       10.2
      </td>
      <td>
       -11.3
      </td>
      <td>
       70.2
      </td>
      <td>
       Highest RMSE - regional
      </td>
     </tr>
     <tr>
      <td>
       B6 (JetBlue)
      </td>
      <td>
       21.7
      </td>
      <td>
       12.9
      </td>
      <td>
       -8.7
      </td>
      <td>
       49.8
      </td>
      <td>
       High delays, moderate error
      </td>
     </tr>
     <tr>
      <td>
       OO (SkyWest)
      </td>
      <td>
       16.3
      </td>
      <td>
       8.6
      </td>
      <td>
       -7.8
      </td>
      <td>
       57.0
      </td>
      <td>
       Regional carrier
      </td>
     </tr>
     <tr>
      <td>
       *V (Mesa)
      </td>
      <td>
       17.4
      </td>
      <td>
       9.0
      </td>
      <td>
       -8.4
      </td>
      <td>
       55.2
      </td>
      <td>
       Regional carrier
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    Pattern: Regional carriers and small/mountain airports are hardest to predict - likely due to weather sensitivity and fewer training samples.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Best-and-Worst-Routes-by-error">
    Best and Worst Routes by error
    <a class="anchor-link" href="#Best-and-Worst-Routes-by-error">
     ¶
    </a>
   </h4>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_021_57dca32d.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Top-10-Routes:-Actual-vs-Predicted-Delay-Summary">
    Top 10 Routes: Actual vs Predicted Delay Summary
    <a class="anchor-link" href="#Top-10-Routes:-Actual-vs-Predicted-Delay-Summary">
     ¶
    </a>
   </h5>
   <p>
    The model consistently underpredicts delays across all top 10 routes, with gaps ranging from -2.4 to -4.5 minutes.
   </p>
   <h5 id="Route-by-Route-Insights">
    Route-by-Route Insights
    <a class="anchor-link" href="#Route-by-Route-Insights">
     ¶
    </a>
   </h5>
   <p>
    Highest Actual Delays:
   </p>
   <ul>
    <li>
     ORD-UA (United at O'Hare): ~17.7 min actual, largest delay among top routes
    </li>
    <li>
     DFW-AA (American at Dallas): ~16.9 min actual, second highest
    </li>
    <li>
     MDW-WN (Southwest at Midway): ~15.2 min actual
    </li>
   </ul>
   <p>
    Lowest Actual Delays:
   </p>
   <ul>
    <li>
     ATL-DL (Delta at Atlanta): ~9.5 min actual, efficient hub operation
    </li>
    <li>
     SEA-AS (Alaska at Seattle): ~9.5 min actual, well-run hub
    </li>
    <li>
     MSP-DL (Delta at Minneapolis): ~10.5 min actual
    </li>
   </ul>
   <h5 id="Prediction-Gap-Analysis">
    Prediction Gap Analysis
    <a class="anchor-link" href="#Prediction-Gap-Analysis">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th>
       Gap Size
      </th>
      <th>
       Routes
      </th>
      <th>
       Observation
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       Largest (-4.5)
      </td>
      <td>
       DFW-AA, CLT-AA
      </td>
      <td>
       American Airlines hubs most underpredicted
      </td>
     </tr>
     <tr>
      <td>
       Medium (-3.3 to -4.1)
      </td>
      <td>
       ORD-UA, MDW-WN, SEA-AS, MSP-DL
      </td>
      <td>
       Mixed carriers
      </td>
     </tr>
     <tr>
      <td>
       Smallest (-2.4 to -2.8)
      </td>
      <td>
       DEN-WN, CLT-OH, ATL-DL, LAS-WN
      </td>
      <td>
       Best calibrated routes
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Key-Takeaways">
    Key Takeaways
    <a class="anchor-link" href="#Key-Takeaways">
     ¶
    </a>
   </h5>
   <ol>
    <li>
     Southwest (WN) routes are better calibrated: DEN-WN (-2.4), LAS-WN (-2.8) have smallest gaps
    </li>
    <li>
     American Airlines (AA) routes have largest errors: DFW-AA and CLT-AA both at -4.5 minutes
    </li>
    <li>
     High-volume Delta hubs perform well: ATL-DL has low delay and small gap (-2.7)
    </li>
    <li>
     Systematic underprediction: No route shows overprediction - model bias is consistent
    </li>
   </ol>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Weekend-vs-Holiday-comparison">
    Weekend vs Holiday comparison
    <a class="anchor-link" href="#Weekend-vs-Holiday-comparison">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_022_84cdf173.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Performance-Analysis-Summary">
    Performance Analysis Summary
    <a class="anchor-link" href="#Performance-Analysis-Summary">
     ¶
    </a>
   </h5>
   <h5 id="Weekend-%C3%97-Holiday-Analysis">
    Weekend × Holiday Analysis
    <a class="anchor-link" href="#Weekend-%C3%97-Holiday-Analysis">
     ¶
    </a>
   </h5>
   <p>
    Key Finding: Holiday periods reduce both actual delays and prediction errors.
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Segment
      </th>
      <th>
       Actual Delay
      </th>
      <th>
       Predicted
      </th>
      <th>
       Key Insight
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       Weekday, Non-Holiday
      </td>
      <td>
       14.6 min
      </td>
      <td>
       8.9 min
      </td>
      <td>
       Highest delays, baseline performance
      </td>
     </tr>
     <tr>
      <td>
       Weekend, Non-Holiday
      </td>
      <td>
       14.1 min
      </td>
      <td>
       8.3 min
      </td>
      <td>
       Similar to weekday
      </td>
     </tr>
     <tr>
      <td>
       Weekday, Holiday
      </td>
      <td>
       13.0 min
      </td>
      <td>
       7.7 min
      </td>
      <td>
       Lower delays, better predictions
      </td>
     </tr>
     <tr>
      <td>
       Weekend + Holiday
      </td>
      <td>
       12.0 min
      </td>
      <td>
       7.0 min
      </td>
      <td>
       Lowest delays, best predictions
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    Observations:
   </p>
   <ul>
    <li>
     Holiday effect is stronger than weekend effect: Holiday months reduce actual delays by ~1.5-2 minutes regardless of weekend status
    </li>
    <li>
     Model consistently underpredicts: All segments show 5-6 minute underprediction gap
    </li>
    <li>
     RMSE is relatively stable: Ranges from 41.7 to 44.3 across all segments
    </li>
    <li>
     Best performance: Weekend + Holiday combination (lowest MAE of 10.7 minutes)
    </li>
   </ul>
   <hr/>
   <h5 id="Top-Routes-(Origin-+-Carrier)-Analysis">
    Top Routes (Origin + Carrier) Analysis
    <a class="anchor-link" href="#Top-Routes-(Origin-+-Carrier)-Analysis">
     ¶
    </a>
   </h5>
   <p>
    Best Performing Routes:
   </p>
   <ul>
    <li>
     LAS-WN (Southwest at Las Vegas): Lowest RMSE (21.1), MAE of 9.5 minutes
    </li>
    <li>
     DEN-WN (Southwest at Denver): RMSE of 24.1, well-calibrated predictions
    </li>
    <li>
     PHX-WN (Southwest at Phoenix): RMSE of 22.7, consistent performance
    </li>
   </ul>
   <p>
    Worst Performing Routes:
   </p>
   <ul>
    <li>
     ORD-OO (SkyWest at O'Hare): Highest RMSE (54.6), highest actual delay (20.7 min)
    </li>
    <li>
     ORD-UA (United at O'Hare): High RMSE (42.2), high actual delay (17.7 min)
    </li>
    <li>
     DEN-UA (United at Denver): RMSE of 40.7, significant underprediction
    </li>
   </ul>
   <p>
    Key Patterns:
   </p>
   <ol>
    <li>
     <p>
      Southwest (WN) routes perform best: Consistently lower RMSE across LAS, DEN, PHX, MDW, DAL, BWI - likely due to point-to-point operations and predictable patterns
     </p>
    </li>
    <li>
     <p>
      O'Hare (ORD) is challenging: Multiple carriers (OO, UA, AA) show high errors at ORD - hub complexity and weather issues
     </p>
    </li>
    <li>
     <p>
      Regional carriers struggle: SkyWest (OO) at ORD has the worst performance (RMSE 54.6) - regional operations are harder to predict
     </p>
    </li>
    <li>
     <p>
      Delta hubs perform well: ATL-DL has the highest volume (243K) with reasonable RMSE (28.1) - efficient hub operation
     </p>
    </li>
    <li>
     <p>
      Consistent underprediction: All routes show predicted delays 3-6 minutes below actual - systematic bias in the model
     </p>
    </li>
   </ol>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.2.4-Feature-Importance-for-SparkXGB-Regressor-and-Classifier">
    5.2.4 Feature Importance for SparkXGB Regressor and Classifier
    <a class="anchor-link" href="#5.2.4-Feature-Importance-for-SparkXGB-Regressor-and-Classifier">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_023_faaa3716.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Top-20-Feature-Importances-Summary">
    Top 20 Feature Importances Summary
    <a class="anchor-link" href="#Top-20-Feature-Importances-Summary">
     ¶
    </a>
   </h5>
   <p>
    The top 20 features capture
    <strong>
     77.7% of total model importance
    </strong>
    , demonstrating that a relatively small subset of features drives most of the predictive power. The steep initial rise followed by a flattening curve shows:
   </p>
   <ul>
    <li>
     <strong>
      First 5 features:
     </strong>
     Capture ~55% of importance
    </li>
    <li>
     <strong>
      First 10 features:
     </strong>
     Capture ~68% of importance
    </li>
    <li>
     <strong>
      First 20 features:
     </strong>
     Capture ~78% of importance
    </li>
   </ul>
   <p>
    This indicates potential for
    <strong>
     dimensionality reduction
    </strong>
    - a model using only the top 20-40 features may perform nearly as well as one using all features, with faster training and reduced overfitting risk.
   </p>
   <p>
    <strong>
     Top 3 features account for ~45% of importance:
    </strong>
   </p>
   <ol>
    <li>
     <strong>
      prev_flight_dep_del15
     </strong>
     (~32%): Whether the previous flight was delayed is by far the strongest predictor - indicating delay propagation is the primary driver
    </li>
    <li>
     <strong>
      num_airport_wide_delays
     </strong>
     (~8%): Current airport congestion level
    </li>
    <li>
     <strong>
      prior_day_delay_rate
     </strong>
     (~5%): Historical delay patterns from the previous day
    </li>
   </ol>
   <h5 id="Feature-Categories">
    Feature Categories
    <a class="anchor-link" href="#Feature-Categories">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Delay History Features (dominant):
    </strong>
   </p>
   <ul>
    <li>
     Previous flight delay status
    </li>
    <li>
     Prior day delay rate
    </li>
    <li>
     Days since last delay on route
    </li>
    <li>
     Rolling delay averages
    </li>
   </ul>
   <p>
    <strong>
     Airport/Operational Features:
    </strong>
   </p>
   <ul>
    <li>
     Airport-wide delay counts
    </li>
    <li>
     Delay propagation score
    </li>
    <li>
     Rolling 30-day volume
    </li>
    <li>
     Origin betweenness (network centrality)
    </li>
   </ul>
   <p>
    <strong>
     Temporal Features:
    </strong>
   </p>
   <ul>
    <li>
     Hours since previous flight
    </li>
    <li>
     Departure time (sin/cos encoded)
    </li>
    <li>
     Arrival time (cos)
    </li>
    <li>
     Day of week interactions
    </li>
   </ul>
   <p>
    <strong>
     Route/Carrier Features:
    </strong>
   </p>
   <ul>
    <li>
     Destination encoded
    </li>
    <li>
     Route delay rate (30-day)
    </li>
    <li>
     Carrier-weighted rolling averages
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_024_3fb689b4.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Feature-Importance-Comparison:-Classifier-vs-Regressor">
    Feature Importance Comparison: Classifier vs Regressor
    <a class="anchor-link" href="#Feature-Importance-Comparison:-Classifier-vs-Regressor">
     ¶
    </a>
   </h4>
   <ol>
    <li>
     <p>
      Classifier focuses on binary signals: The classifier heavily relies on whether the previous flight was delayed - a strong binary indicator for predicting
      <em>
       if
      </em>
      a delay will occur.
     </p>
    </li>
    <li>
     <p>
      Regressor uses more diverse inputs: The regressor distributes importance across more features (prior_day_delay_rate, days_since_last_delay_route, rolling averages) because predicting
      <em>
       how long
      </em>
      a delay will be requires more nuanced information.
     </p>
    </li>
    <li>
     <p>
      Shared important features: Both models value:
     </p>
     <ul>
      <li>
       Previous flight delay status
      </li>
      <li>
       Airport-wide delay counts
      </li>
      <li>
       Rolling delay averages
      </li>
      <li>
       Delay propagation metrics
      </li>
     </ul>
    </li>
   </ol>
   <p>
    Dominant Feature:
Both models agree that
    <code>
     prev_flight_dep_del15
    </code>
    (whether the previous flight was delayed) is the most important predictor, but with different magnitudes:
   </p>
   <ul>
    <li>
     Classifier: ~45% importance (heavily dominant)
    </li>
    <li>
     Regressor: ~32% importance (still dominant but less extreme)
    </li>
   </ul>
   <p>
    Second Most Important:
Both models rank
    <code>
     num_airport_wide_delays
    </code>
    as the second most important feature (~10% for both).
   </p>
   <h5 id="Key-Differences">
    Key Differences
    <a class="anchor-link" href="#Key-Differences">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th>
       Aspect
      </th>
      <th>
       Classifier
      </th>
      <th>
       Regressor
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Concentration
       </strong>
      </td>
      <td>
       Highly concentrated on 1 feature
      </td>
      <td>
       More evenly distributed
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Top feature weight
       </strong>
      </td>
      <td>
       ~45%
      </td>
      <td>
       ~32%
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Feature diversity
       </strong>
      </td>
      <td>
       Few features dominate
      </td>
      <td>
       Multiple features contribute meaningfully
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Implication-for-Ensemble">
    Implication for Ensemble
    <a class="anchor-link" href="#Implication-for-Ensemble">
     ¶
    </a>
   </h5>
   <p>
    The different feature emphasis suggests the classifier and regressor capture complementary information - supporting their use together in a two-stage prediction pipeline.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Top-20-Feature-Importances-Summary">
    Top 20 Feature Importances Summary
    <a class="anchor-link" href="#Top-20-Feature-Importances-Summary">
     ¶
    </a>
   </h5>
   <p>
    The top 20 features capture
    <strong>
     77.7% of total model importance
    </strong>
    , demonstrating that a relatively small subset of features drives most of the predictive power.
   </p>
   <h5 id="Dominant-Features">
    Dominant Features
    <a class="anchor-link" href="#Dominant-Features">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Top 3 features account for ~45% of importance:
    </strong>
   </p>
   <ol>
    <li>
     <strong>
      prev_flight_dep_del15
     </strong>
     (~32%): Whether the previous flight was delayed is by far the strongest predictor - indicating delay propagation is the primary driver
    </li>
    <li>
     <strong>
      num_airport_wide_delays
     </strong>
     (~8%): Current airport congestion level
    </li>
    <li>
     <strong>
      prior_day_delay_rate
     </strong>
     (~5%): Historical delay patterns from the previous day
    </li>
   </ol>
   <h5 id="Feature-Categories">
    Feature Categories
    <a class="anchor-link" href="#Feature-Categories">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Delay History Features (dominant):
    </strong>
   </p>
   <ul>
    <li>
     Previous flight delay status
    </li>
    <li>
     Prior day delay rate
    </li>
    <li>
     Days since last delay on route
    </li>
    <li>
     Rolling delay averages
    </li>
   </ul>
   <p>
    <strong>
     Airport/Operational Features:
    </strong>
   </p>
   <ul>
    <li>
     Airport-wide delay counts
    </li>
    <li>
     Delay propagation score
    </li>
    <li>
     Rolling 30-day volume
    </li>
    <li>
     Origin betweenness (network centrality)
    </li>
   </ul>
   <p>
    <strong>
     Temporal Features:
    </strong>
   </p>
   <ul>
    <li>
     Hours since previous flight
    </li>
    <li>
     Departure time (sin/cos encoded)
    </li>
    <li>
     Arrival time (cos)
    </li>
    <li>
     Day of week interactions
    </li>
   </ul>
   <p>
    <strong>
     Route/Carrier Features:
    </strong>
   </p>
   <ul>
    <li>
     Destination encoded
    </li>
    <li>
     Route delay rate (30-day)
    </li>
    <li>
     Carrier-weighted rolling averages
    </li>
   </ul>
   <h5 id="Cumulative-Curve-Interpretation">
    Cumulative Curve Interpretation
    <a class="anchor-link" href="#Cumulative-Curve-Interpretation">
     ¶
    </a>
   </h5>
   <p>
    The steep initial rise followed by a flattening curve shows:
   </p>
   <ul>
    <li>
     <strong>
      First 5 features:
     </strong>
     Capture ~55% of importance
    </li>
    <li>
     <strong>
      First 10 features:
     </strong>
     Capture ~68% of importance
    </li>
    <li>
     <strong>
      First 20 features:
     </strong>
     Capture ~78% of importance
    </li>
   </ul>
   <p>
    This indicates potential for
    <strong>
     dimensionality reduction
    </strong>
    - a model using only the top 20-40 features may perform nearly as well as one using all features, with faster training and reduced overfitting risk.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.2.5-Summary-for-2-Stage-Ensemble-Experiments">
    5.2.5 Summary for 2 Stage Ensemble Experiments
    <a class="anchor-link" href="#5.2.5-Summary-for-2-Stage-Ensemble-Experiments">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Summary-of-2-Stage-Experiment-Evolution">
    Summary of 2-Stage Experiment Evolution
    <a class="anchor-link" href="#Summary-of-2-Stage-Experiment-Evolution">
     ¶
    </a>
   </h5>
   <h5 id="Phase-1:-Baseline-Approach">
    Phase 1: Baseline Approach
    <a class="anchor-link" href="#Phase-1:-Baseline-Approach">
     ¶
    </a>
   </h5>
   <p>
    The initial experiment used simple models (Logistic Regression + Linear Regression) with class weights to handle imbalance. This approach performed poorly with a test RMSE of 97.49 minutes and MAE of 53.59 minutes, establishing a baseline for improvement.
   </p>
   <h5 id="Phase-2:-Tree-Based-Models">
    Phase 2: Tree-Based Models
    <a class="anchor-link" href="#Phase-2:-Tree-Based-Models">
     ¶
    </a>
   </h5>
   <p>
    Switching to tree-based models (RandomForest + GBTRegressor) with undersampling at 0.5 ratio showed promise in training (RMSE: 19.43) but suffered from severe overfitting, with test RMSE jumping to 74.22 minutes. The large train-test gap indicated the model wasn't generalizing well.
   </p>
   <h5 id="Phase-3:-Scaled-Training-&amp;-Two-Stage-Pipeline">
    Phase 3: Scaled Training &amp; Two-Stage Pipeline
    <a class="anchor-link" href="#Phase-3:-Scaled-Training-&amp;-Two-Stage-Pipeline">
     ¶
    </a>
   </h5>
   <p>
    Using the full dataset (2015-2018) for training and 2019 for testing dramatically improved results. Several key findings emerged:
   </p>
   <p>
    <strong>
     Model Comparison:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      SparkXGBoost consistently outperformed
     </strong>
     RandomForest and GBTClassifier combinations
    </li>
    <li>
     XGBoost achieved test RMSE of 42.83 and MAE of 12.07-12.30
    </li>
   </ul>
   <p>
    <strong>
     Ensemble Strategy Comparison:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Regression-only
     </strong>
     achieved RMSE of 42.83 min - classifier gating provided minimal benefit
    </li>
    <li>
     <strong>
      Threshold-Gated
     </strong>
     performed nearly identically (42.85 min RMSE)
    </li>
    <li>
     <strong>
      Probability-weighted
     </strong>
     achieved MAE of 11.66 min but higher RMSE (44.14 min)
    </li>
   </ul>
   <p>
    <strong>
     Balance Strategy:
    </strong>
   </p>
   <ul>
    <li>
     Increasing undersample ratio from 0.5 to 1.0 improved performance
    </li>
    <li>
     Full balancing helped the model better learn delay patterns
    </li>
   </ul>
   <h5 id="Regression-Only-Ensemble-with-Sample-Weighting">
    Regression-Only Ensemble with Sample Weighting
    <a class="anchor-link" href="#Regression-Only-Ensemble-with-Sample-Weighting">
     ¶
    </a>
   </h5>
   <p>
    Recognizing that the two-stage classifier-regressor pipeline provided minimal benefit, we eliminated the classifier and focused on optimizing the regression model with ensemble strategies:
   </p>
   <p>
    <strong>
     Sample Weighting Strategy:
    </strong>
   </p>
   <ul>
    <li>
     Applied instance weights to emphasize severe delays during training
    </li>
    <li>
     Weight scheme: 1.0× for delays ≤60 min, 2.0× for 60-120 min, 2.5× for &gt;120 min
    </li>
    <li>
     Weighted model better captured extreme delay patterns
    </li>
   </ul>
   <p>
    <strong>
     Model Configuration:
    </strong>
   </p>
   <ul>
    <li>
     Deeper trees (max_depth=11) with regularization (reg_alpha=0.2, reg_lambda=1.0)
    </li>
    <li>
     Learning rate=0.05, n_estimators=200, subsample=0.8, colsample_bytree=0.8
    </li>
   </ul>
   <p>
    <strong>
     Ensemble Strategies:
    </strong>
    Two XGBRegressor models (one with sample weights, one without) combined using:
   </p>
   <ul>
    <li>
     <strong>
      Max:
     </strong>
     Takes higher prediction → Best for RMSE (captures severe delays)
    </li>
    <li>
     <strong>
      Min:
     </strong>
     Takes lower prediction → Best for MAE (optimizes typical cases)
    </li>
    <li>
     <strong>
      Average:
     </strong>
     Balanced approach → Best for F1 score
    </li>
   </ul>
   <p>
    <strong>
     Regression only Results:
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Strategy
      </th>
      <th>
       Test RMSE
      </th>
      <th>
       Test MAE
      </th>
      <th>
       Best For
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Ensemble Max
       </strong>
      </td>
      <td>
       <strong>
        41.69
       </strong>
      </td>
      <td>
       13.21
      </td>
      <td>
       RMSE, F2
      </td>
     </tr>
     <tr>
      <td>
       Ensemble Min
      </td>
      <td>
       42.50
      </td>
      <td>
       <strong>
        11.92
       </strong>
      </td>
      <td>
       MAE
      </td>
     </tr>
     <tr>
      <td>
       Ensemble Average
      </td>
      <td>
       42.05
      </td>
      <td>
       12.40
      </td>
      <td>
       F1 Balance
      </td>
     </tr>
     <tr>
      <td>
       Weighted Model Only
      </td>
      <td>
       41.79
      </td>
      <td>
       13.20
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td>
       Unweighted Model Only
      </td>
      <td>
       42.40
      </td>
      <td>
       11.93
      </td>
      <td>
       AuPRC
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Regression-to-Binary-Classification-Evaluation">
    Regression-to-Binary Classification Evaluation
    <a class="anchor-link" href="#Regression-to-Binary-Classification-Evaluation">
     ¶
    </a>
   </h5>
   <p>
    Converting regression outputs to binary predictions (delay ≥15 min) enabled direct comparison with classification models:
   </p>
   <p>
    <strong>
     Binary Classification Results (vs DEP_DEL15):
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Strategy
      </th>
      <th>
       Accuracy
      </th>
      <th>
       Precision
      </th>
      <th>
       Recall
      </th>
      <th>
       F1
      </th>
      <th>
       F2
      </th>
      <th>
       AuPRC
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       Ensemble Max
      </td>
      <td>
       86.1%
      </td>
      <td>
       60.5%
      </td>
      <td>
       <strong>
        72.5%
       </strong>
      </td>
      <td>
       65.9%
      </td>
      <td>
       <strong>
        69.7%
       </strong>
      </td>
      <td>
       72.2%
      </td>
     </tr>
     <tr>
      <td>
       Ensemble Average
      </td>
      <td>
       87.7%
      </td>
      <td>
       67.2%
      </td>
      <td>
       66.4%
      </td>
      <td>
       <strong>
        66.8%
       </strong>
      </td>
      <td>
       66.6%
      </td>
      <td>
       73.1%
      </td>
     </tr>
     <tr>
      <td>
       Unweighted Model
      </td>
      <td>
       <strong>
        88.3%
       </strong>
      </td>
      <td>
       <strong>
        71.8%
       </strong>
      </td>
      <td>
       61.5%
      </td>
      <td>
       66.3%
      </td>
      <td>
       63.4%
      </td>
      <td>
       <strong>
        73.5%
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       Ensemble Min
      </td>
      <td>
       88.3%
      </td>
      <td>
       71.8%
      </td>
      <td>
       61.5%
      </td>
      <td>
       66.3%
      </td>
      <td>
       63.3%
      </td>
      <td>
       73.4%
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Key-Takeaways">
    Key Takeaways
    <a class="anchor-link" href="#Key-Takeaways">
     ¶
    </a>
   </h5>
   <ol>
    <li>
     <strong>
      Regression-to-binary outperforms direct classification:
     </strong>
     XGBoost Ensemble (Max) achieves highest F2 (0.697) and AuPRC (0.723) across all approaches
    </li>
    <li>
     <strong>
      Two-stage pipeline unnecessary:
     </strong>
     Classifier + Regressor provides minimal benefit over regression-only
    </li>
    <li>
     <strong>
      Sample weighting improves severe delay prediction:
     </strong>
     Weighted model captures extreme delays better
    </li>
    <li>
     <strong>
      Ensemble strategy depends on use case:
     </strong>
     <ul>
      <li>
       <strong>
        Maximize recall / F2:
       </strong>
       Use Ensemble Max (catches more delays)
      </li>
      <li>
       <strong>
        Maximize precision / accuracy:
       </strong>
       Use Ensemble Min or Unweighted (fewer false alarms)
      </li>
      <li>
       <strong>
        Balanced performance:
       </strong>
       Use Ensemble Average (best F1)
      </li>
     </ul>
    </li>
    <li>
     <strong>
      Training efficiency:
     </strong>
     XGBoost ensemble trains 15× faster than CNN while achieving better F2 and AuPRC
    </li>
    <li>
     <strong>
      Overall improvement:
     </strong>
     From Phase 1 to Phase 3, test RMSE improved by
     <strong>
      57%
     </strong>
     (97.49 → 41.69 minutes)
    </li>
   </ol>
   <h5 id="Recommended-Model-Configuration">
    Recommended Model Configuration
    <a class="anchor-link" href="#Recommended-Model-Configuration">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th>
       Use Case
      </th>
      <th>
       Strategy
      </th>
      <th>
       RMSE
      </th>
      <th>
       MAE
      </th>
      <th>
       F2
      </th>
      <th>
       Recommendation
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Operations Planning
       </strong>
      </td>
      <td>
       Ensemble Max
      </td>
      <td>
       <strong>
        41.69
       </strong>
      </td>
      <td>
       13.21
      </td>
      <td>
       <strong>
        0.697
       </strong>
      </td>
      <td>
       Minimize missed delays
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Customer Communication
       </strong>
      </td>
      <td>
       Ensemble Min
      </td>
      <td>
       42.50
      </td>
      <td>
       <strong>
        11.92
       </strong>
      </td>
      <td>
       0.633
      </td>
      <td>
       Minimize false alarms
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Balanced Reporting
       </strong>
      </td>
      <td>
       Ensemble Average
      </td>
      <td>
       42.05
      </td>
      <td>
       12.40
      </td>
      <td>
       0.668
      </td>
      <td>
       Best overall F1
      </td>
     </tr>
    </tbody>
   </table>
   <h5 id="Error-Analysis-Insights">
    Error Analysis Insights
    <a class="anchor-link" href="#Error-Analysis-Insights">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     By Delay Severity:
    </strong>
   </p>
   <ul>
    <li>
     Model performs well for mild delays (&lt;30 min): ~80% recall
    </li>
    <li>
     Performance degrades for severe delays (&gt;2 hr): ~50% recall
    </li>
    <li>
     Sample weighting helps but extreme delays remain challenging
    </li>
   </ul>
   <p>
    <strong>
     By Carrier:
    </strong>
   </p>
   <ul>
    <li>
     Best: Hawaiian (HA), Alaska (AS), Delta (DL) - &gt;89% accuracy
    </li>
    <li>
     Worst: ExpressJet (EV), SkyWest (OO), Mesa (YV) - &lt;83% accuracy
    </li>
    <li>
     Regional carriers are hardest to predict
    </li>
   </ul>
   <p>
    <strong>
     By Time/Season:
    </strong>
   </p>
   <ul>
    <li>
     Summer months (Jun-Aug) have highest error rates
    </li>
    <li>
     Morning flights more predictable than evening flights
    </li>
    <li>
     Weekends slightly harder to predict than weekdays
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="5.3-Tree-Ensemble-(Classification)">
    5.3 Tree Ensemble (Classification)
    <a class="anchor-link" href="#5.3-Tree-Ensemble-(Classification)">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.3.1-Loss-Function">
    5.3.1 Loss Function
    <a class="anchor-link" href="#5.3.1-Loss-Function">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.3.1.1-Gradient-Boosted-Trees-(GBT)-Loss-Function">
    5.3.1.1 Gradient Boosted Trees (GBT) Loss Function
    <a class="anchor-link" href="#5.3.1.1-Gradient-Boosted-Trees-(GBT)-Loss-Function">
     ¶
    </a>
   </h4>
   <p>
    The GBT model minimizes a logistic loss function with gradient-based optimization:
$$
L(y, F(x)) = \log\left(1 + e^{-2yF(x)}\right)
$$
where:
   </p>
   <ul>
    <li>
     y ∈ {-1, +1} is the true label (mapped from 0/1)
    </li>
    <li>
     F(x) = sum from m=1 to M of (gamma_m times h_m(x)) is the ensemble prediction
    </li>
    <li>
     h_m(x) is the m-th decision tree (weak learner)
    </li>
    <li>
     gamma_m is the learning rate-adjusted weight (stepSize parameter)
    </li>
   </ul>
   <p>
    <strong>
     Gradient Update at iteration m:
    </strong>
   </p>
   <p>
    $$h_m(x) = \arg\min_{h} \sum_{i=1}^{N} \left( -\frac{\partial L(y_i, F_{m-1}(x_i))}{\partial F_{m-1}(x_i)} - h(x_i) \right)^2$$
   </p>
   <p>
    <strong>
     Regularization Update:
    </strong>
   </p>
   <p>
    $$F_m(x) = F_{m-1}(x) + \text{stepSize} \cdot h_m(x)$$
   </p>
   <p>
    <strong>
     Regularization in GBT:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Learning rate
     </strong>
     (
     <code>
      stepSize
     </code>
     ): Controls contribution of each tree
    </li>
    <li>
     <strong>
      Subsampling
     </strong>
     (
     <code>
      subsamplingRate
     </code>
     ): Randomly samples fraction of data for each tree
    </li>
    <li>
     <strong>
      Tree depth
     </strong>
     (
     <code>
      maxDepth
     </code>
     ): Limits complexity of individual trees
    </li>
    <li>
     <strong>
      Early stopping
     </strong>
     : Monitors validation performance to prevent overfitting
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.3.1.2-Random-Forest-Loss-Function">
    5.3.1.2 Random Forest Loss Function
    <a class="anchor-link" href="#5.3.1.2-Random-Forest-Loss-Function">
     ¶
    </a>
   </h4>
   <p>
    The Random Forest model optimizes a
    <strong>
     Gini impurity
    </strong>
    criterion for each decision tree in the ensemble:
   </p>
   <p>
    <strong>
     Data Loss (Gini Impurity):
    </strong>
    $$
\text{Gini}(t) = 1 - \sum_{k=1}^{K} p_k^2
$$
where:
   </p>
   <ul>
    <li>
     t is a node in the decision tree
    </li>
    <li>
     K is the number of classes (2 for binary classification)
    </li>
    <li>
     p_k is the proportion of samples of class k at node t
    </li>
   </ul>
   <p>
    <strong>
     Split Quality Measure:
    </strong>
   </p>
   <p>
    $$
\Delta \text{Gini}(s, t) = \text{Gini}(t) - \left( \frac{N_{\text{left}}}{N} \text{Gini}(t_{\text{left}}) + \frac{N_{\text{right}}}{N} \text{Gini}(t_{\text{right}}) \right)
$$
   </p>
   <p>
    where:
   </p>
   <ul>
    <li>
     s is a candidate split
    </li>
    <li>
     N is the total number of samples at node t
    </li>
    <li>
     N_left and N_right are the numbers of samples in left and right child nodes
    </li>
   </ul>
   <p>
    <strong>
     Regularization in RF:
    </strong>
   </p>
   <ul>
    <li>
     <code>
      maxDepth
     </code>
     parameter (limits tree depth)
    </li>
    <li>
     <code>
      maxBins
     </code>
     parameter (limits feature granularity)
    </li>
    <li>
     Random feature subset selection (
     <code>
      featureSubsetStrategy="sqrt"
     </code>
     )
    </li>
    <li>
     Bootstrap sampling for each tree
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.3.2.-Early-Stopping-Discussion">
    5.3.2. Early Stopping Discussion
    <a class="anchor-link" href="#5.3.2.-Early-Stopping-Discussion">
     ¶
    </a>
   </h3>
   <h4 id="Data-Used-for-Early-Stopping">
    Data Used for Early Stopping
    <a class="anchor-link" href="#Data-Used-for-Early-Stopping">
     ¶
    </a>
   </h4>
   <ul>
    <li>
     <strong>
      Validation Set:
     </strong>
     2018 flight data (
     <code>
      df_val_2018
     </code>
     )
    </li>
    <li>
     <strong>
      Training Set:
     </strong>
     2015-2017 undersampled flight data
     <ul>
      <li>
       Undersampling ratio: delayed-to-on-time = 1:2 (33.3% delayed, 66.7% on-time)
      </li>
      <li>
       Original train set: 17.9% delayed → Undersampled: 33.3% delayed
      </li>
      <li>
       Total rows: 9,009,126
      </li>
     </ul>
    </li>
    <li>
     <strong>
      Test Set (Blind):
     </strong>
     2019 flight data (held out until final evaluation)
    </li>
   </ul>
   <h4 id="Metrics-Used">
    Metrics Used
    <a class="anchor-link" href="#Metrics-Used">
     ¶
    </a>
   </h4>
   <p>
    <strong>
     ML Metrics:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Primary metric:
     </strong>
     AUC-PR (Area Under Precision-Recall Curve)
    </li>
    <li>
     <strong>
      Secondary metrics:
     </strong>
     AUC-ROC, F0.5 score, Precision, Recall
    </li>
   </ul>
   <p>
    <strong>
     Rationale:
    </strong>
    AUC-PR is more informative than AUC-ROC for imbalanced datasets. It directly measures the trade-off between precision and recall across different classification thresholds.
   </p>
   <p>
    <strong>
     Business Metric Consideration:
    </strong>
    F0.5 score weighs precision twice as heavily as recall, reflecting the business context where false positives (incorrectly predicting a delay) are more costly than false negatives (missing a delay prediction).
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.3.2.1-Early-Stopping-Strategy-for-GBT">
    5.3.2.1 Early Stopping Strategy for GBT
    <a class="anchor-link" href="#5.3.2.1-Early-Stopping-Strategy-for-GBT">
     ¶
    </a>
   </h4>
   <p>
    <strong>
     Approach:
    </strong>
    Progressive stopping with
    <strong>
     patience=2
    </strong>
    and
    <strong>
     min_delta=0.001
    </strong>
    .
   </p>
   <p>
    <strong>
     Implementation:
    </strong>
   </p>
   <div class="highlight">
    <pre><span></span><span class="k">if</span> <span class="n">auc_pr</span> <span class="o">&gt;</span> <span class="n">best_score</span> <span class="o">+</span> <span class="n">min_delta</span><span class="p">:</span>
    <span class="n">best_score</span> <span class="o">=</span> <span class="n">auc_pr</span>
    <span class="n">no_improve_rounds</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">no_improve_rounds</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">if</span> <span class="n">no_improve_rounds</span> <span class="o">&gt;=</span> <span class="n">patience</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Early stopping triggered at numIters=</span><span class="si">{</span><span class="n">num_iters</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">break</span>
</pre>
   </div>
   <p>
    <strong>
     Decision Logic:
    </strong>
   </p>
   <ul>
    <li>
     We do NOT quit at the first sign of poor performance
    </li>
    <li>
     We allow
     <strong>
      2 consecutive rounds without improvement
     </strong>
     before stopping
    </li>
    <li>
     Improvement is defined as AUC-PR gain &gt; 0.001 (0.1%)
    </li>
    <li>
     This gives the model more patience to explore the iteration space
    </li>
   </ul>
   <p>
    <strong>
     GBT Hyperparameter Grid:
    </strong>
   </p>
   <ul>
    <li>
     <code>
      num_iter_grid
     </code>
     : [70, 80, 90]
    </li>
    <li>
     <code>
      max_depth
     </code>
     : [3, 5]
    </li>
    <li>
     <code>
      step_size
     </code>
     : [0.05, 0.1]
    </li>
    <li>
     <code>
      subsampling_rate
     </code>
     : 0.8
    </li>
   </ul>
   <p>
    <strong>
     Example from GBT Experiments:
    </strong>
    All three configurations completed all iterations without early stopping, indicating steady improvement throughout.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.3.2.2-Early-Stopping-Strategy-for-RF">
    5.3.2.2 Early Stopping Strategy for RF
    <a class="anchor-link" href="#5.3.2.2-Early-Stopping-Strategy-for-RF">
     ¶
    </a>
   </h4>
   <p>
    <strong>
     Approach:
    </strong>
    Progressive stopping with
    <strong>
     tolerance threshold of 0.001
    </strong>
    in AUC-PR improvement.
   </p>
   <p>
    <strong>
     Implementation:
    </strong>
   </p>
   <div class="highlight">
    <pre><span></span><span class="k">if</span> <span class="n">auc_pr</span> <span class="o">&gt;</span> <span class="n">last_best_for_this_depth</span> <span class="o">+</span> <span class="mf">0.001</span><span class="p">:</span>
    <span class="n">last_best_for_this_depth</span> <span class="o">=</span> <span class="n">auc_pr</span>
    <span class="n">no_improve_rounds</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">no_improve_rounds</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">if</span> <span class="n">no_improve_rounds</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  -&gt; early stop on numTrees for depth=</span><span class="si">{</span><span class="n">maxDepth</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">break</span>
</pre>
   </div>
   <p>
    <strong>
     Decision Logic:
    </strong>
   </p>
   <ul>
    <li>
     We allow
     <strong>
      one round without improvement
     </strong>
     before stopping
    </li>
    <li>
     More aggressive than GBT (patience=1 vs patience=2)
    </li>
    <li>
     Rationale: RF trees are independent, so adding more trees without improvement is less likely to help
    </li>
   </ul>
   <p>
    <strong>
     RF Hyperparameter Grid:
    </strong>
   </p>
   <ul>
    <li>
     <code>
      numTrees_grid
     </code>
     : [10, 15, 20]
    </li>
    <li>
     <code>
      maxDepth_grid
     </code>
     : [5, 8, 10, 15]
    </li>
   </ul>
   <p>
    <strong>
     Example from RF Experiments:
    </strong>
   </p>
   <ul>
    <li>
     depth=5: Stopped after numTrees=15 (no improvement from 10→15)
    </li>
    <li>
     depth=8: Stopped after numTrees=15 (no improvement from 10→15)
    </li>
    <li>
     depth=10: Stopped after numTrees=15 (no improvement from 10→15)
    </li>
    <li>
     depth=15: Continued through numTrees=20 (steady improvement)
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.3.2.3-How-Early-Stopping-Helps">
    5.3.2.3 How Early Stopping Helps
    <a class="anchor-link" href="#5.3.2.3-How-Early-Stopping-Helps">
     ¶
    </a>
   </h4>
   <ol>
    <li>
     <strong>
      Computational Efficiency:
     </strong>
     Saves training time by avoiding unpromising hyperparameter configurations
    </li>
    <li>
     <strong>
      Prevents Overfitting:
     </strong>
     <ul>
      <li>
       <strong>
        GBT
       </strong>
       : Stops adding boosting iterations when validation performance plateaus
      </li>
      <li>
       <strong>
        RF
       </strong>
       : Stops adding trees when ensemble diversity no longer improves performance
      </li>
     </ul>
    </li>
    <li>
     <strong>
      Resource Optimization:
     </strong>
     Reduces cluster usage for large-scale experiments (saved ~3 RF experiments)
    </li>
    <li>
     <strong>
      Informed Search:
     </strong>
     Guides hyperparameter search toward more promising regions
    </li>
   </ol>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.3.3-Cross-Fold-Validation-Metrics">
    5.3.3 Cross-Fold Validation Metrics
    <a class="anchor-link" href="#5.3.3-Cross-Fold-Validation-Metrics">
     ¶
    </a>
   </h3>
   <p>
    <strong>
     Status:
    </strong>
    Cross-fold validation was
    <strong>
     not implemented
    </strong>
    in this phase.
   </p>
   <p>
    <strong>
     Current Approach:
    </strong>
   </p>
   <ul>
    <li>
     Single train/validation/test split
    </li>
    <li>
     Training: 2015-2017 (undersampled to 33.3% delayed, 66.7% on-time)
    </li>
    <li>
     Validation: 2018 (natural distribution: ~18% delayed)
    </li>
    <li>
     Test: 2019 (natural distribution: ~18% delayed)
    </li>
   </ul>
   <p>
    <strong>
     Rationale for Skipping Cross-Validation:
    </strong>
   </p>
   <ol>
    <li>
     <strong>
      Temporal Nature:
     </strong>
     Time-series data should not be shuffled; future data must not leak into training
    </li>
    <li>
     <strong>
      Computational Cost:
     </strong>
     Cross-fold validation on 9M+ training samples with GBT (iter=90) and RF (depth=15, numTrees=20) would require 3-5× the compute time
    </li>
    <li>
     <strong>
      Validation Strategy:
     </strong>
     Chronological split (2015-2017 → 2018 → 2019) better reflects real-world deployment scenario
    </li>
   </ol>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.3.4-Comprehensive-Experiment-Table">
    5.3.4 Comprehensive Experiment Table
    <a class="anchor-link" href="#5.3.4-Comprehensive-Experiment-Table">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.3.4.1-Gradient-Boosted-Trees-Experiments">
    5.3.4.1 Gradient Boosted Trees Experiments
    <a class="anchor-link" href="#5.3.4.1-Gradient-Boosted-Trees-Experiments">
     ¶
    </a>
   </h4>
   <table>
    <thead>
     <tr>
      <th>
       Experiment ID
      </th>
      <th>
       Model
      </th>
      <th>
       maxDepth
      </th>
      <th>
       stepSize
      </th>
      <th>
       subsamplingRate
      </th>
      <th>
       maxIter
      </th>
      <th>
       Val AUC-PR
      </th>
      <th>
       Val AUC-ROC
      </th>
      <th>
       Val F0.5
      </th>
      <th>
       Early Stop?
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       GBT-1
      </td>
      <td>
       GBT
      </td>
      <td>
       3
      </td>
      <td>
       0.1
      </td>
      <td>
       0.8
      </td>
      <td>
       70
      </td>
      <td>
       0.6668
      </td>
      <td>
       0.8761
      </td>
      <td>
       0.6259
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       GBT-2
      </td>
      <td>
       GBT
      </td>
      <td>
       3
      </td>
      <td>
       0.1
      </td>
      <td>
       0.8
      </td>
      <td>
       80
      </td>
      <td>
       0.6706
      </td>
      <td>
       0.8779
      </td>
      <td>
       0.6275
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       GBT-3
      </td>
      <td>
       GBT
      </td>
      <td>
       3
      </td>
      <td>
       0.1
      </td>
      <td>
       0.8
      </td>
      <td>
       90
      </td>
      <td>
       0.6771
      </td>
      <td>
       0.8802
      </td>
      <td>
       0.6295
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       GBT-4
      </td>
      <td>
       GBT
      </td>
      <td>
       5
      </td>
      <td>
       0.1
      </td>
      <td>
       0.8
      </td>
      <td>
       70
      </td>
      <td>
       0.7128
      </td>
      <td>
       0.8916
      </td>
      <td>
       0.6384
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       GBT-5
      </td>
      <td>
       GBT
      </td>
      <td>
       5
      </td>
      <td>
       0.1
      </td>
      <td>
       0.8
      </td>
      <td>
       80
      </td>
      <td>
       0.7162
      </td>
      <td>
       0.8933
      </td>
      <td>
       0.6400
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        GBT-6 (Best)
       </strong>
      </td>
      <td>
       <strong>
        GBT
       </strong>
      </td>
      <td>
       <strong>
        5
       </strong>
      </td>
      <td>
       <strong>
        0.1
       </strong>
      </td>
      <td>
       <strong>
        0.8
       </strong>
      </td>
      <td>
       <strong>
        90
       </strong>
      </td>
      <td>
       <strong>
        0.7191
       </strong>
      </td>
      <td>
       <strong>
        0.8945
       </strong>
      </td>
      <td>
       <strong>
        0.6415
       </strong>
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       GBT-7
      </td>
      <td>
       GBT
      </td>
      <td>
       5
      </td>
      <td>
       0.05
      </td>
      <td>
       0.8
      </td>
      <td>
       70
      </td>
      <td>
       0.6923
      </td>
      <td>
       0.8825
      </td>
      <td>
       0.6300
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       GBT-8
      </td>
      <td>
       GBT
      </td>
      <td>
       5
      </td>
      <td>
       0.05
      </td>
      <td>
       0.8
      </td>
      <td>
       80
      </td>
      <td>
       0.6955
      </td>
      <td>
       0.8842
      </td>
      <td>
       0.6310
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       GBT-9
      </td>
      <td>
       GBT
      </td>
      <td>
       5
      </td>
      <td>
       0.05
      </td>
      <td>
       0.8
      </td>
      <td>
       90
      </td>
      <td>
       0.6993
      </td>
      <td>
       0.8859
      </td>
      <td>
       0.6329
      </td>
      <td>
       No
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     GBT Configuration Details:
    </strong>
   </p>
   <ul>
    <li>
     <code>
      maxBins
     </code>
     : 64 (all experiments)
    </li>
    <li>
     <code>
      seed
     </code>
     : 42 (all experiments)
    </li>
    <li>
     Training data: 2015-2017 undersampled (9,009,126 rows)
    </li>
   </ul>
   <p>
    <strong>
     GBT Best Validation Config:
    </strong>
   </p>
   <ul>
    <li>
     maxDepth=5, stepSize=0.1, subsamplingRate=0.8, maxIter=90
    </li>
    <li>
     Val AUC-PR=0.7191, Val AUC-ROC=0.8945, Val F0.5=0.6415
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.3.4.2-Random-Forest-Experiments">
    5.3.4.2 Random Forest Experiments
    <a class="anchor-link" href="#5.3.4.2-Random-Forest-Experiments">
     ¶
    </a>
   </h4>
   <table>
    <thead>
     <tr>
      <th>
       Experiment ID
      </th>
      <th>
       Model Type
      </th>
      <th>
       maxDepth
      </th>
      <th>
       numTrees
      </th>
      <th>
       maxBins
      </th>
      <th>
       featureSubsetStrategy
      </th>
      <th>
       Val AUC-PR
      </th>
      <th>
       Val AUC-ROC
      </th>
      <th>
       Val F0.5
      </th>
      <th>
       Val Precision
      </th>
      <th>
       Val Recall
      </th>
      <th>
       Early Stop?
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       RF-1
      </td>
      <td>
       Random Forest
      </td>
      <td>
       5
      </td>
      <td>
       10
      </td>
      <td>
       64
      </td>
      <td>
       sqrt
      </td>
      <td>
       0.5722
      </td>
      <td>
       0.8318
      </td>
      <td>
       0.5747
      </td>
      <td>
       -
      </td>
      <td>
       -
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       RF-2
      </td>
      <td>
       Random Forest
      </td>
      <td>
       5
      </td>
      <td>
       15
      </td>
      <td>
       64
      </td>
      <td>
       sqrt
      </td>
      <td>
       0.5642
      </td>
      <td>
       0.8299
      </td>
      <td>
       0.5557
      </td>
      <td>
       -
      </td>
      <td>
       -
      </td>
      <td>
       <strong>
        Yes
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       RF-3
      </td>
      <td>
       Random Forest
      </td>
      <td>
       8
      </td>
      <td>
       10
      </td>
      <td>
       64
      </td>
      <td>
       sqrt
      </td>
      <td>
       0.6113
      </td>
      <td>
       0.8485
      </td>
      <td>
       0.6036
      </td>
      <td>
       -
      </td>
      <td>
       -
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       RF-4
      </td>
      <td>
       Random Forest
      </td>
      <td>
       8
      </td>
      <td>
       15
      </td>
      <td>
       64
      </td>
      <td>
       sqrt
      </td>
      <td>
       0.6075
      </td>
      <td>
       0.8480
      </td>
      <td>
       0.6026
      </td>
      <td>
       -
      </td>
      <td>
       -
      </td>
      <td>
       <strong>
        Yes
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       RF-5
      </td>
      <td>
       Random Forest
      </td>
      <td>
       10
      </td>
      <td>
       10
      </td>
      <td>
       64
      </td>
      <td>
       sqrt
      </td>
      <td>
       0.6340
      </td>
      <td>
       0.8576
      </td>
      <td>
       0.6142
      </td>
      <td>
       -
      </td>
      <td>
       -
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       RF-6
      </td>
      <td>
       Random Forest
      </td>
      <td>
       10
      </td>
      <td>
       15
      </td>
      <td>
       64
      </td>
      <td>
       sqrt
      </td>
      <td>
       0.6318
      </td>
      <td>
       0.8582
      </td>
      <td>
       0.6211
      </td>
      <td>
       -
      </td>
      <td>
       -
      </td>
      <td>
       <strong>
        Yes
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       RF-7
      </td>
      <td>
       Random Forest
      </td>
      <td>
       15
      </td>
      <td>
       10
      </td>
      <td>
       64
      </td>
      <td>
       sqrt
      </td>
      <td>
       0.6728
      </td>
      <td>
       0.8726
      </td>
      <td>
       0.6353
      </td>
      <td>
       -
      </td>
      <td>
       -
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       RF-8
      </td>
      <td>
       Random Forest
      </td>
      <td>
       15
      </td>
      <td>
       15
      </td>
      <td>
       64
      </td>
      <td>
       sqrt
      </td>
      <td>
       0.6757
      </td>
      <td>
       0.8747
      </td>
      <td>
       0.6412
      </td>
      <td>
       -
      </td>
      <td>
       -
      </td>
      <td>
       No
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        RF-9 (Best)
       </strong>
      </td>
      <td>
       <strong>
        Random Forest
       </strong>
      </td>
      <td>
       <strong>
        15
       </strong>
      </td>
      <td>
       <strong>
        20
       </strong>
      </td>
      <td>
       <strong>
        64
       </strong>
      </td>
      <td>
       <strong>
        sqrt
       </strong>
      </td>
      <td>
       <strong>
        0.6796
       </strong>
      </td>
      <td>
       <strong>
        0.8758
       </strong>
      </td>
      <td>
       <strong>
        0.6417
       </strong>
      </td>
      <td>
       <strong>
        0.6500
       </strong>
      </td>
      <td>
       <strong>
        0.6107
       </strong>
      </td>
      <td>
       No
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     RF Configuration Details:
    </strong>
   </p>
   <ul>
    <li>
     <code>
      seed
     </code>
     : 42 (all experiments)
    </li>
    <li>
     Training data: 2015-2017 undersampled (9,009,126 rows)
    </li>
   </ul>
   <p>
    <strong>
     RF Best Validation Config:
    </strong>
   </p>
   <ul>
    <li>
     maxDepth=15, numTrees=20
    </li>
    <li>
     Val AUC-PR=0.6796, Val AUC-ROC=0.8758, Val F0.5=0.6417
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.3.4.3-Final-Models---Test-Set-Performance-(2019)">
    5.3.4.3 Final Models - Test Set Performance (2019)
    <a class="anchor-link" href="#5.3.4.3-Final-Models---Test-Set-Performance-(2019)">
     ¶
    </a>
   </h4>
   <table>
    <thead>
     <tr>
      <th>
       Model
      </th>
      <th>
       Best Config
      </th>
      <th>
       Test AUC-PR
      </th>
      <th>
       Test AUC-ROC
      </th>
      <th>
       Test F0.5
      </th>
      <th>
       Test Precision
      </th>
      <th>
       Test Recall
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        GBT-Final
       </strong>
      </td>
      <td>
       depth=5, step=0.1, subs=0.8, iter=90
      </td>
      <td>
       <strong>
        0.6832
       </strong>
      </td>
      <td>
       <strong>
        0.8818
       </strong>
      </td>
      <td>
       <strong>
        0.6366
       </strong>
      </td>
      <td>
       <strong>
        0.6407
       </strong>
      </td>
      <td>
       <strong>
        0.6206
       </strong>
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        RF-Final
       </strong>
      </td>
      <td>
       depth=15, numTrees=20
      </td>
      <td>
       <strong>
        0.6639
       </strong>
      </td>
      <td>
       <strong>
        0.8711
       </strong>
      </td>
      <td>
       <strong>
        0.6376
       </strong>
      </td>
      <td>
       <strong>
        0.6474
       </strong>
      </td>
      <td>
       <strong>
        0.6013
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Key Observations:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      GBT achieves higher AUC-PR (0.6832 vs 0.6639)
     </strong>
     → Better at ranking positive predictions
    </li>
    <li>
     <strong>
      RF achieves higher Test F0.5 (0.6376 vs 0.6366)
     </strong>
     → Slightly better precision-recall balance
    </li>
    <li>
     <strong>
      GBT has higher Recall (0.6206 vs 0.6013)
     </strong>
     → Catches more delayed flights
    </li>
    <li>
     <strong>
      RF has higher Precision (0.6474 vs 0.6407)
     </strong>
     → Fewer false alarms
    </li>
    <li>
     Both models show minimal overfitting (validation → test performance is stable)
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.3.5-Cluster-Size-and-Experiment-Times">
    5.3.5 Cluster Size and Experiment Times
    <a class="anchor-link" href="#5.3.5-Cluster-Size-and-Experiment-Times">
     ¶
    </a>
   </h3>
   <h4 id="Cluster-Configuration">
    Cluster Configuration
    <a class="anchor-link" href="#Cluster-Configuration">
     ¶
    </a>
   </h4>
   <p>
    <strong>
     Status:
    </strong>
    Cluster size information
    <strong>
     not explicitly logged
    </strong>
    in the notebook.
   </p>
   <p>
    <strong>
     Typical Databricks Setup (to be verified):
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Driver Node:
     </strong>
     Standard_DS3_v2 (4 cores, 14 GB RAM)
    </li>
    <li>
     <strong>
      Worker Nodes:
     </strong>
     2-4 × Standard_DS3_v2 (4 cores, 14 GB RAM each)
    </li>
    <li>
     <strong>
      Total Cores:
     </strong>
     ~12-20 cores
    </li>
    <li>
     <strong>
      Spark Version:
     </strong>
     Runtime with MLlib support
    </li>
   </ul>
   <h4 id="Wall-Time-Estimates">
    Wall Time Estimates
    <a class="anchor-link" href="#Wall-Time-Estimates">
     ¶
    </a>
   </h4>
   <table>
    <thead>
     <tr>
      <th>
       Experiment Phase
      </th>
      <th>
       Estimated Wall Time
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       Data Loading &amp; Caching (9M rows)
      </td>
      <td>
       2 minutes
      </td>
     </tr>
     <tr>
      <td>
       Single GBT Training (depth=3, iter=70)
      </td>
      <td>
       ~10-15 minutes
      </td>
     </tr>
     <tr>
      <td>
       Single GBT Training (depth=5, iter=90)
      </td>
      <td>
       ~15-25 minutes
      </td>
     </tr>
     <tr>
      <td>
       Full GBT Grid (9 experiments)
      </td>
      <td>
       122 minutes
      </td>
     </tr>
     <tr>
      <td>
       Single RF Training (depth=5, numTrees=10)
      </td>
      <td>
       ~5-8 minutes
      </td>
     </tr>
     <tr>
      <td>
       Single RF Training (depth=15, numTrees=20)
      </td>
      <td>
       ~15-20 minutes
      </td>
     </tr>
     <tr>
      <td>
       Full RF Grid (9 experiments)
      </td>
      <td>
       63 minutes
      </td>
     </tr>
     <tr>
      <td>
       Final GBT Model Training on Test
      </td>
      <td>
       6 minutes
      </td>
     </tr>
     <tr>
      <td>
       Final RF Model Training on Test
      </td>
      <td>
       11 minutes
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Total Experiment Time (Both Models)
       </strong>
      </td>
      <td>
       <strong>
        ~4 hours
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="5.4-MLP-Ensemble-(Classification)">
    5.4 MLP Ensemble (Classification)
    <a class="anchor-link" href="#5.4-MLP-Ensemble-(Classification)">
     ¶
    </a>
   </h2>
   <p>
    This section documents the end-to-end workflow implemented in the notebook
    <strong>
     MLP_Ensemble_v2
    </strong>
    . The objective is to train and evaluate a
    <strong>
     3-model MLP ensemble
    </strong>
    for
    <strong>
     binary delay classification
    </strong>
    using
    <code>
     DEP_DEL15
    </code>
    (1 = departure delayed ≥ 15 minutes). Each MLP is trained under a different
    <strong>
     class imbalance strategy
    </strong>
    , and the final prediction is generated via a
    <strong>
     simple average of predicted probabilities
    </strong>
    with
    <strong>
     threshold optimization
    </strong>
    (primary metric:
    <strong>
     F2
    </strong>
    ).
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.1-Data-Sources-and-Splits">
    5.4.1 Data Sources and Splits
    <a class="anchor-link" href="#5.4.1-Data-Sources-and-Splits">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    The notebook loads three Parquet datasets aligned with the project’s time-aware split strategy:
   </p>
   <ul>
    <li>
     Train:
     <code>
      cp6_train_2015_2017_refined.parquet
     </code>
    </li>
    <li>
     Validation:
     <code>
      cp6_val_2018_refined.parquet
     </code>
    </li>
    <li>
     Test:
     <code>
      cp6_test_2019_refined.parquet
     </code>
    </li>
   </ul>
   <p>
    The time-based separation ensures that model evaluation reflects operational deployment conditions (predicting future behavior from past data).
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.2-Leakage-Control-and-Column-Filtering">
    5.4.2 Leakage Control and Column Filtering
    <a class="anchor-link" href="#5.4.2-Leakage-Control-and-Column-Filtering">
     ¶
    </a>
   </h3>
   <p>
    A leakage scan was applied to remove known or suspected
    <strong>
     post-departure / post-observation
    </strong>
    columns. The notebook removes 8 columns flagged as leakage/ID or timing artifacts:
   </p>
   <ul>
    <li>
     <code>
      CRS_ARR_TIME
     </code>
    </li>
    <li>
     <code>
      DEP_DELAY
     </code>
    </li>
    <li>
     <code>
      FL_DATE
     </code>
    </li>
    <li>
     <code>
      OP_CARRIER_FL_NUM
     </code>
    </li>
    <li>
     <code>
      arr_time_cos
     </code>
    </li>
    <li>
     <code>
      arr_time_sin
     </code>
    </li>
    <li>
     <code>
      origin_obs_utc
     </code>
    </li>
    <li>
     <code>
      prediction_utc
     </code>
    </li>
   </ul>
   <p>
    After leakage removal, the modeling datasets retain a consistent schema used throughout feature engineering and training.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.3-Feature-Engineering-and-Vectorization-Pipeline">
    5.4.3 Feature Engineering and Vectorization Pipeline
    <a class="anchor-link" href="#5.4.3-Feature-Engineering-and-Vectorization-Pipeline">
     ¶
    </a>
   </h3>
   <p>
    The notebook constructs a Spark ML pipeline to produce a standardized feature vector suitable for MLP training.
   </p>
   <h4 id="5.4.3.1-Feature-Type-Handling">
    5.4.3.1 Feature Type Handling
    <a class="anchor-link" href="#5.4.3.1-Feature-Type-Handling">
     ¶
    </a>
   </h4>
   <p>
    Features are partitioned into:
   </p>
   <ul>
    <li>
     Numeric columns
    </li>
    <li>
     Categorical string columns
    </li>
    <li>
     Pre-indexed categorical columns (already numeric)
    </li>
   </ul>
   <p>
    Because the dataset includes pre-indexed categorical features, the notebook uses a simplified pipeline rather than performing full
    <code>
     StringIndexer
    </code>
    +
    <code>
     OneHotEncoder
    </code>
    within this notebook.
   </p>
   <h4 id="5.4.3.2-Pipeline-Stages">
    5.4.3.2 Pipeline Stages
    <a class="anchor-link" href="#5.4.3.2-Pipeline-Stages">
     ¶
    </a>
   </h4>
   <p>
    The implemented pipeline includes:
   </p>
   <ol>
    <li>
     <code>
      VectorAssembler
     </code>
     →
     <code>
      features_raw
     </code>
    </li>
    <li>
     <code>
      StandardScaler
     </code>
     (withMean=True, withStd=True) →
     <code>
      features
     </code>
    </li>
   </ol>
   <p>
    The result is a fixed-length numeric vector used as input to all MLP models.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.4-Class-Imbalance-Diagnosis">
    5.4.4 Class Imbalance Diagnosis
    <a class="anchor-link" href="#5.4.4-Class-Imbalance-Diagnosis">
     ¶
    </a>
   </h3>
   <p>
    The training set exhibits substantial imbalance (majority = on-time flights). The notebook prints class proportions and the imbalance ratio, motivating explicit rebalancing strategies for improved delay detection performance (especially recall-focused metrics).
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.5-Training-Set-Construction-for-Ensemble-Members">
    5.4.5 Training Set Construction for Ensemble Members
    <a class="anchor-link" href="#5.4.5-Training-Set-Construction-for-Ensemble-Members">
     ¶
    </a>
   </h3>
   <p>
    Three training datasets are created to induce complementary decision boundaries across ensemble members.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_025_331c1fe7.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.4.5.1-Model-1-%E2%80%94-50:50-Undersampling">
    5.4.5.1 Model 1 — 50:50 Undersampling
    <a class="anchor-link" href="#5.4.5.1-Model-1-%E2%80%94-50:50-Undersampling">
     ¶
    </a>
   </h4>
   <p>
    A balanced dataset is formed by undersampling the majority class to match the minority class.
   </p>
   <h4 id="5.4.5.2-Model-2-%E2%80%94-40:60-Undersampling-(Delay-Favored)">
    5.4.5.2 Model 2 — 40:60 Undersampling (Delay-Favored)
    <a class="anchor-link" href="#5.4.5.2-Model-2-%E2%80%94-40:60-Undersampling-(Delay-Favored)">
     ¶
    </a>
   </h4>
   <p>
    A delay-favored dataset is formed where the minority (delayed) class is intentionally overrepresented relative to the majority class (40% vs 60%).
   </p>
   <h4 id="5.4.5.3-Model-3-%E2%80%94-Original-Distribution">
    5.4.5.3 Model 3 — Original Distribution
    <a class="anchor-link" href="#5.4.5.3-Model-3-%E2%80%94-Original-Distribution">
     ¶
    </a>
   </h4>
   <p>
    The third model is trained on the full original dataset.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.6-Hyperparameter-Optimization-(Optuna)">
    5.4.6 Hyperparameter Optimization (Optuna)
    <a class="anchor-link" href="#5.4.6-Hyperparameter-Optimization-(Optuna)">
     ¶
    </a>
   </h3>
   <p>
    Optuna-based tuning is enabled to search over a small hyperparameter space efficiently using sampled subsets of training and validation data.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_026_69f45ee7.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.4.6.1-Search-Space">
    5.4.6.1 Search Space
    <a class="anchor-link" href="#5.4.6.1-Search-Space">
     ¶
    </a>
   </h4>
   <p>
    The notebook tunes:
   </p>
   <ul>
    <li>
     Number of hidden layers (1-2 or 1-3, as configured)
    </li>
    <li>
     Hidden layer sizes
    </li>
    <li>
     Number of iterations
    </li>
   </ul>
   <h4 id="5.4.6.2-Optimization-Metric">
    5.4.6.2 Optimization Metric
    <a class="anchor-link" href="#5.4.6.2-Optimization-Metric">
     ¶
    </a>
   </h4>
   <p>
    During tuning, trials are evaluated using
    <strong>
     AUC-PR (Average Precision)
    </strong>
    computed from predicted probabilities on the sampled validation split. This is aligned with the project’s emphasis on imbalanced classification.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.7-Final-Model-Training">
    5.4.7 Final Model Training
    <a class="anchor-link" href="#5.4.7-Final-Model-Training">
     ¶
    </a>
   </h3>
   <p>
    All three MLPs are trained using the tuned architecture:
   </p>
   <ul>
    <li>
     Model 1: trained on 50:50 undersampled data
    </li>
    <li>
     Model 2: trained on 40:60 undersampled data
    </li>
    <li>
     Model 3: trained on the original distribution
    </li>
   </ul>
   <p>
    Training times are recorded in the notebook for each model to quantify runtime cost.
   </p>
   <p>
    Because Spark’s
    <code>
     MultilayerPerceptronClassifier
    </code>
    is not trained in epochs (it is optimized in batch mode with L-BFGS), the notebook does not implement “early stopping” in the PyTorch sense (i.e., stopping after
    <em>
     N
    </em>
    epochs without validation improvement). Instead, we control training length with a tuned
    <code>
     maxIter
    </code>
    cap and rely on the optimizer’s own convergence behavior: training terminates when L-BFGS converges (no meaningful loss improvement) or when
    <code>
     maxIter
    </code>
    is reached. In practice, this serves the same goal as early stopping—preventing unnecessary compute once marginal gains flatten—while validation-based model selection during Optuna tuning further guards against overfitting by choosing the configuration that generalizes best on the held-out validation split.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_027_219d9cd2.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.8-Inference-and-Probability-Extraction">
    5.4.8 Inference and Probability Extraction
    <a class="anchor-link" href="#5.4.8-Inference-and-Probability-Extraction">
     ¶
    </a>
   </h3>
   <p>
    Each trained model generates predictions on the test split. The notebook extracts the
    <strong>
     class-1 probability
    </strong>
    for each record, enabling:
   </p>
   <ul>
    <li>
     AUC-PR computation
    </li>
    <li>
     threshold sweeps
    </li>
    <li>
     ensemble probability aggregation
    </li>
   </ul>
   <h3 id="5.4.9-Ensemble-Method">
    5.4.9 Ensemble Method
    <a class="anchor-link" href="#5.4.9-Ensemble-Method">
     ¶
    </a>
   </h3>
   <p>
    The ensemble prediction is computed as a
    <strong>
     simple average
    </strong>
    of predicted probabilities:
   </p>
   <p>
    $$
p_{ensemble} = \frac{p_1 + p_2 + p_3}{3}
$$
   </p>
   <p>
    This approach is intended to reduce variance and leverage diversity created by different imbalance treatments.
   </p>
   <h3 id="5.4.10-Threshold-Optimization-and-Metric-Selection">
    5.4.10 Threshold Optimization and Metric Selection
    <a class="anchor-link" href="#5.4.10-Threshold-Optimization-and-Metric-Selection">
     ¶
    </a>
   </h3>
   <p>
    Because the deployment objective is
    <strong>
     delay detection
    </strong>
    , the notebook performs an explicit threshold sweep and selects the threshold that maximizes
    <strong>
     F2
    </strong>
    .
   </p>
   <ul>
    <li>
     <strong>
      Primary decision metric:
     </strong>
     F2 (recall-weighted)
    </li>
    <li>
     <strong>
      Supporting metrics:
     </strong>
     Precision, Recall, F1, AUC-PR
    </li>
    <li>
     Threshold grid includes values from ~0.15 upward (as shown in the notebook).
    </li>
   </ul>
   <p>
    The selected threshold reflects a recall-prioritizing operational stance, accepting increased false positives in exchange for capturing a larger share of true delays.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <table>
    <thead>
     <tr>
      <th style="text-align:right">
       Threshold
      </th>
      <th style="text-align:right">
       Precision
      </th>
      <th style="text-align:right">
       Recall
      </th>
      <th style="text-align:right">
       F1
      </th>
      <th style="text-align:right">
       F2
      </th>
      <th style="text-align:right">
       TP
      </th>
      <th style="text-align:right">
       FP
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:right">
       0.15
      </td>
      <td style="text-align:right">
       0.3939
      </td>
      <td style="text-align:right">
       0.7721
      </td>
      <td style="text-align:right">
       0.5216
      </td>
      <td style="text-align:right">
       0.6477
      </td>
      <td style="text-align:right">
       1,033,420
      </td>
      <td style="text-align:right">
       1,590,393
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.20
      </td>
      <td style="text-align:right">
       0.4831
      </td>
      <td style="text-align:right">
       0.6395
      </td>
      <td style="text-align:right">
       0.5504
      </td>
      <td style="text-align:right">
       0.6006
      </td>
      <td style="text-align:right">
       855,942
      </td>
      <td style="text-align:right">
       915,729
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.25
      </td>
      <td style="text-align:right">
       0.5552
      </td>
      <td style="text-align:right">
       0.5337
      </td>
      <td style="text-align:right">
       0.5442
      </td>
      <td style="text-align:right">
       0.5378
      </td>
      <td style="text-align:right">
       714,289
      </td>
      <td style="text-align:right">
       572,296
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.30
      </td>
      <td style="text-align:right">
       0.6194
      </td>
      <td style="text-align:right">
       0.4449
      </td>
      <td style="text-align:right">
       0.5178
      </td>
      <td style="text-align:right">
       0.4715
      </td>
      <td style="text-align:right">
       595,466
      </td>
      <td style="text-align:right">
       365,964
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.35
      </td>
      <td style="text-align:right">
       0.6790
      </td>
      <td style="text-align:right">
       0.3681
      </td>
      <td style="text-align:right">
       0.4774
      </td>
      <td style="text-align:right">
       0.4052
      </td>
      <td style="text-align:right">
       492,686
      </td>
      <td style="text-align:right">
       232,911
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.40
      </td>
      <td style="text-align:right">
       0.7327
      </td>
      <td style="text-align:right">
       0.3020
      </td>
      <td style="text-align:right">
       0.4277
      </td>
      <td style="text-align:right">
       0.3423
      </td>
      <td style="text-align:right">
       404,256
      </td>
      <td style="text-align:right">
       147,492
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.45
      </td>
      <td style="text-align:right">
       0.7742
      </td>
      <td style="text-align:right">
       0.2448
      </td>
      <td style="text-align:right">
       0.3720
      </td>
      <td style="text-align:right">
       0.2836
      </td>
      <td style="text-align:right">
       327,649
      </td>
      <td style="text-align:right">
       95,546
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.50
      </td>
      <td style="text-align:right">
       0.8066
      </td>
      <td style="text-align:right">
       0.1948
      </td>
      <td style="text-align:right">
       0.3138
      </td>
      <td style="text-align:right">
       0.2296
      </td>
      <td style="text-align:right">
       260,696
      </td>
      <td style="text-align:right">
       62,515
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.55
      </td>
      <td style="text-align:right">
       0.8317
      </td>
      <td style="text-align:right">
       0.1506
      </td>
      <td style="text-align:right">
       0.2550
      </td>
      <td style="text-align:right">
       0.1801
      </td>
      <td style="text-align:right">
       201,584
      </td>
      <td style="text-align:right">
       40,797
      </td>
     </tr>
     <tr>
      <td style="text-align:right">
       0.60
      </td>
      <td style="text-align:right">
       0.8564
      </td>
      <td style="text-align:right">
       0.1128
      </td>
      <td style="text-align:right">
       0.1994
      </td>
      <td style="text-align:right">
       0.1365
      </td>
      <td style="text-align:right">
       150,995
      </td>
      <td style="text-align:right">
       25,318
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Best F2:
    </strong>
    0.6477 at threshold
    <strong>
     0.15
    </strong>
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.11-Results-Summary-(Single-Models-vs-Ensemble)">
    5.4.11 Results Summary (Single Models vs Ensemble)
    <a class="anchor-link" href="#5.4.11-Results-Summary-(Single-Models-vs-Ensemble)">
     ¶
    </a>
   </h3>
   <p>
    The notebook compares:
   </p>
   <ul>
    <li>
     Best-threshold performance for each single model
    </li>
    <li>
     Best-threshold performance for the ensemble
    </li>
    <li>
     AUC-PR across models
    </li>
   </ul>
   <p>
    Key observed pattern:
   </p>
   <ul>
    <li>
     The
     <strong>
      delay-favored undersampling model (40:60)
     </strong>
     achieves the strongest recall and best F2 among individual models.
    </li>
    <li>
     The ensemble improves probability stability and precision relative to the most recall-heavy single model, but may not exceed the best single model on F2 depending on the final trade-off.
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <table>
    <thead>
     <tr>
      <th>
       Model / Item
      </th>
      <th>
       Training data strategy
      </th>
      <th style="text-align:right">
       Train samples
      </th>
      <th style="text-align:right">
       Training time (s)
      </th>
      <th>
       Ensemble combo
      </th>
      <th style="text-align:right">
       Optimal threshold
      </th>
      <th style="text-align:right">
       Precision
      </th>
      <th style="text-align:right">
       Recall
      </th>
      <th style="text-align:right">
       F1
      </th>
      <th style="text-align:right">
       F2
      </th>
      <th style="text-align:right">
       AUC-PR
      </th>
      <th style="text-align:right">
       TP
      </th>
      <th style="text-align:right">
       FP
      </th>
      <th style="text-align:right">
       TN
      </th>
      <th style="text-align:right">
       FN
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       Model 1
      </td>
      <td>
       50:50 undersampling
      </td>
      <td style="text-align:right">
       5,945,573
      </td>
      <td style="text-align:right">
       1345.19
      </td>
      <td>
       Simple average (M1+M2+M3)
      </td>
      <td style="text-align:right">
       0.15
      </td>
      <td style="text-align:right">
       0.3939
      </td>
      <td style="text-align:right">
       0.7721
      </td>
      <td style="text-align:right">
       0.5216
      </td>
      <td style="text-align:right">
       0.6477
      </td>
      <td style="text-align:right">
       0.5831
      </td>
      <td style="text-align:right">
       1,033,420
      </td>
      <td style="text-align:right">
       1,590,393
      </td>
      <td style="text-align:right">
       4,200,375
      </td>
      <td style="text-align:right">
       305,037
      </td>
     </tr>
     <tr>
      <td>
       Model 2
      </td>
      <td>
       40:60 undersampling
      </td>
      <td style="text-align:right">
       4,965,869
      </td>
      <td style="text-align:right">
       1050.73
      </td>
      <td>
       Simple average (M1+M2+M3)
      </td>
      <td style="text-align:right">
       0.15
      </td>
      <td style="text-align:right">
       0.3939
      </td>
      <td style="text-align:right">
       0.7721
      </td>
      <td style="text-align:right">
       0.5216
      </td>
      <td style="text-align:right">
       0.6477
      </td>
      <td style="text-align:right">
       0.5831
      </td>
      <td style="text-align:right">
       1,033,420
      </td>
      <td style="text-align:right">
       1,590,393
      </td>
      <td style="text-align:right">
       4,200,375
      </td>
      <td style="text-align:right">
       305,037
      </td>
     </tr>
     <tr>
      <td>
       Model 3
      </td>
      <td>
       Original data
      </td>
      <td style="text-align:right">
       16,454,983
      </td>
      <td style="text-align:right">
       2340.69
      </td>
      <td>
       Simple average (M1+M2+M3)
      </td>
      <td style="text-align:right">
       0.15
      </td>
      <td style="text-align:right">
       0.3939
      </td>
      <td style="text-align:right">
       0.7721
      </td>
      <td style="text-align:right">
       0.5216
      </td>
      <td style="text-align:right">
       0.6477
      </td>
      <td style="text-align:right">
       0.5831
      </td>
      <td style="text-align:right">
       1,033,420
      </td>
      <td style="text-align:right">
       1,590,393
      </td>
      <td style="text-align:right">
       4,200,375
      </td>
      <td style="text-align:right">
       305,037
      </td>
     </tr>
     <tr>
      <td>
       Ensemble (overall)
      </td>
      <td>
       Avg of M1/M2/M3 predictions
      </td>
      <td style="text-align:right">
       27,366,425
      </td>
      <td style="text-align:right">
       4736.61
      </td>
      <td>
       Simple average
      </td>
      <td style="text-align:right">
       0.15
      </td>
      <td style="text-align:right">
       0.3939
      </td>
      <td style="text-align:right">
       0.7721
      </td>
      <td style="text-align:right">
       0.5216
      </td>
      <td style="text-align:right">
       0.6477
      </td>
      <td style="text-align:right">
       0.5831
      </td>
      <td style="text-align:right">
       1,033,420
      </td>
      <td style="text-align:right">
       1,590,393
      </td>
      <td style="text-align:right">
       4,200,375
      </td>
      <td style="text-align:right">
       305,037
      </td>
     </tr>
    </tbody>
   </table>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.12-Confusion-Matrix-and-Error-Profile">
    5.4.12 Confusion Matrix and Error Profile
    <a class="anchor-link" href="#5.4.12-Confusion-Matrix-and-Error-Profile">
     ¶
    </a>
   </h3>
   <p>
    At the selected optimal threshold, the notebook produces:
   </p>
   <ul>
    <li>
     Confusion matrix (TP, FP, TN, FN)
    </li>
    <li>
     Precision–Recall curve
    </li>
    <li>
     Probability distribution plots by class
    </li>
   </ul>
   <p>
    These diagnostics confirm that optimizing F2 drives a low threshold decision policy, yielding:
   </p>
   <ul>
    <li>
     High recall for delayed flights
    </li>
    <li>
     High false-positive volume (on-time flights predicted as delayed)
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_028_9da83059.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.4.13-Saved-Artifacts">
    5.4.13 Saved Artifacts
    <a class="anchor-link" href="#5.4.13-Saved-Artifacts">
     ¶
    </a>
   </h3>
   <p>
    The notebook saves the trained models to DBFS for reproducibility and downstream integration:
   </p>
   <ul>
    <li>
     <code>
      .../mlp/model_1_50_50_2
     </code>
    </li>
    <li>
     <code>
      .../mlp/model_2_40_60_2
     </code>
    </li>
    <li>
     <code>
      .../mlp/model_3_weights_2
     </code>
    </li>
   </ul>
   <h3 id="5.4.14-Multilayer-Perceptron-(Spark-MLPC)-Loss-Function">
    5.4.14 Multilayer Perceptron (Spark MLPC) Loss Function
    <a class="anchor-link" href="#5.4.14-Multilayer-Perceptron-(Spark-MLPC)-Loss-Function">
     ¶
    </a>
   </h3>
   <p>
    The MLP classifier (PySpark
    <code>
     MultilayerPerceptronClassifier
    </code>
    ) minimizes a
    <strong>
     softmax cross-entropy (logistic) loss
    </strong>
    for 2-class classification:
   </p>
   <p>
    $$
L(\mathbf{y}, \hat{\mathbf{p}}) = - \sum_{c \in \{0,1\}} y_c \, \log(\hat{p}_c)
$$
   </p>
   <p>
    where:
$$\mathbf{y} = [y_0, y_1]$$ is the one-hot encoded true label (derived from
    <code>
     DEP_DEL15
    </code>
    )
$$\hat{\mathbf{p}} = [\hat{p}_0, \hat{p}_1] = \mathrm{softmax}(\mathbf{z})$$ are predicted class probabilities
$$\mathbf{z} = [z_0, z_1]$$ are the network output logits (pre-softmax)
   </p>
   <p>
    In Spark MLPC, hidden layers use
    <strong>
     sigmoid activations
    </strong>
    and the output layer uses
    <strong>
     softmax
    </strong>
    ; training uses
    <strong>
     backpropagation
    </strong>
    and optimizes the logistic loss with
    <strong>
     L-BFGS
    </strong>
    .
   </p>
   <p>
    <strong>
     Class imbalance handling in this notebook (MLP Ensemble):
    </strong>
    <br/>
    Rather than using a class-weighted cross-entropy like: $$- \sum_c w_c y_c \log(\hat{p}_c)$$  The notebook addresses imbalance primarily through
    <strong>
     data rebalancing (undersampling)
    </strong>
    to create multiple training distributions (e.g., 50:50 and 40:60) for the ensemble. This is consistent with the Spark MLPC API, which does not expose a
    <code>
     weightCol
    </code>
    parameter in the estimator signature.
   </p>
   <h3 id="5.4.15-Summary">
    5.4.15 Summary
    <a class="anchor-link" href="#5.4.15-Summary">
     ¶
    </a>
   </h3>
   <p>
    This notebook establishes the project’s MLP classification deliverable by implementing:
   </p>
   <ul>
    <li>
     Leakage control to prevent post-event information entering features
    </li>
    <li>
     A standardized feature vector pipeline suitable for neural models in Spark
    </li>
    <li>
     Three imbalance strategies to create ensemble diversity
    </li>
    <li>
     Optuna tuning (AUC-PR-based) to select a performant architecture efficiently
    </li>
    <li>
     A probability-averaging ensemble with
     <strong>
      F2-optimized
     </strong>
     decision thresholding
    </li>
    <li>
     Full test diagnostics (AUC-PR, PR curve, confusion matrix) to evaluate operational trade-offs
    </li>
   </ul>
   <p>
    The overall outcome is a recall-oriented classifier suitable for identifying delayed flights under imbalanced conditions, with a configurable threshold that can be adjusted depending on stakeholder tolerance for false alarms versus missed delays.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="5.5-1D-CNN-Classifier-(PyTorch,-Databricks-Optimized)">
    5.5 1D CNN Classifier (PyTorch, Databricks-Optimized)
    <a class="anchor-link" href="#5.5-1D-CNN-Classifier-(PyTorch,-Databricks-Optimized)">
     ¶
    </a>
   </h2>
   <p>
    We evaluated an alternative deep-learning classifier using a
    <strong>
     tabular 1D CNN in PyTorch
    </strong>
    to predict
    <strong>
     DEP_DEL15
    </strong>
    . The implementation is optimized for Databricks execution by (i) producing a Spark-native
    <code>
     features
    </code>
    vector, and (ii) converting Spark outputs into a
    <strong>
     high-throughput streaming dataset
    </strong>
    with
    <strong>
     sharding
    </strong>
    to keep GPUs fed efficiently at scale.
   </p>
   <p>
    A key enabler for the full-scale run was the use of
    <strong>
     MDS streaming + sharded datasets
    </strong>
    , which allowed the full-scale model to train on large volumes of data without repeatedly materializing Spark outputs on the driver or exhausting cluster memory during batch preparation.
   </p>
   <h3 id="5.5.1-Objective-and-Rationale">
    5.5.1 Objective and Rationale
    <a class="anchor-link" href="#5.5.1-Objective-and-Rationale">
     ¶
    </a>
   </h3>
   <p>
    The goal is to benchmark a neural alternative to Spark ML baselines (e.g., MLPs) for
    <strong>
     binary delay classification (DEP_DEL15)
    </strong>
    . A 1D CNN is used to learn non-linear interactions through stacked convolutional blocks while maintaining a scalable training pipeline suitable for Databricks.
   </p>
   <h3 id="5.5.2-Data-Inputs,-Splits,-and-Label">
    5.5.2 Data Inputs, Splits, and Label
    <a class="anchor-link" href="#5.5.2-Data-Inputs,-Splits,-and-Label">
     ¶
    </a>
   </h3>
   <p>
    Both notebooks read parquet datasets from DBFS using time-consistent splits:
   </p>
   <ul>
    <li>
     <strong>
      Train:
     </strong>
     <code>
      dbfs:/student-groups/Group_4_4/cp6_train_2015_2017_refined.parquet
     </code>
    </li>
    <li>
     <strong>
      Validation:
     </strong>
     <code>
      dbfs:/student-groups/Group_4_4/cp6_val_2018_refined.parquet
     </code>
    </li>
    <li>
     <strong>
      Test:
     </strong>
     <code>
      dbfs:/student-groups/Group_4_4/cp6_test_2019_refined.parquet
     </code>
    </li>
    <li>
     <strong>
      Label:
     </strong>
     <code>
      DEP_DEL15
     </code>
     (binary)
    </li>
   </ul>
   <p>
    Two training regimes were used across the notebooks:
   </p>
   <ul>
    <li>
     A
     <strong>
      tiny (0.5%) subset
     </strong>
     workflow for rapid pipeline validation and architecture iteration.
    </li>
    <li>
     A
     <strong>
      full-scale workflow
     </strong>
     (full validation + full test), with
     <strong>
      50:50 undersampling applied to the training split
     </strong>
     to mitigate class imbalance and reduce training cost.
    </li>
   </ul>
   <p>
    To control overfitting and reduce unnecessary compute, training used an
    <strong>
     early stopping
    </strong>
    criterion based on validation loss. After each epoch, the model was evaluated on the validation set and training was halted when
    <strong>
     <code>
      val_loss
     </code>
     failed to improve by at least
     <code>
      min_delta = 0.001
     </code>
     for
     <code>
      patience
     </code>
     consecutive epochs
    </strong>
    . The
    <strong>
     subset model used
     <code>
      patience = 20
     </code>
    </strong>
    , while the
    <strong>
     full-scale model used
     <code>
      patience = 5
     </code>
    </strong>
    to converge faster under full-data runtime constraints. In both cases, the best-performing checkpoint (lowest validation loss) was saved and later used for final test inference and threshold optimization.
   </p>
   <h3 id="5.5.3-Leakage-Prevention-and-High-Risk-Column-Exclusion">
    5.5.3 Leakage Prevention and High-Risk Column Exclusion
    <a class="anchor-link" href="#5.5.3-Leakage-Prevention-and-High-Risk-Column-Exclusion">
     ¶
    </a>
   </h3>
   <p>
    A leakage-prevention routine removes columns that could encode post-event information (e.g., arrival/actual timing signals) and excludes high-risk identifiers/timestamps that are not appropriate for forward-looking prediction. This enforces a “predict-from-known-information” constraint consistent with deployment requirements.
   </p>
   <h3 id="5.5.4-Spark-Feature-Engineering-Pipeline">
    5.5.4 Spark Feature Engineering Pipeline
    <a class="anchor-link" href="#5.5.4-Spark-Feature-Engineering-Pipeline">
     ¶
    </a>
   </h3>
   <p>
    A Spark ML pipeline produces a dense numeric feature vector compatible with PyTorch:
   </p>
   <ul>
    <li>
     <code>
      StringIndexer(handleInvalid="keep")
     </code>
     for categorical columns
    </li>
    <li>
     <code>
      OneHotEncoder(handleInvalid="keep", dropLast=False)
     </code>
    </li>
    <li>
     <code>
      Imputer(strategy="median")
     </code>
     for numeric columns (explicitly added to address NaNs / corrupt columns)
    </li>
    <li>
     <code>
      VectorAssembler
     </code>
     →
     <code>
      features_raw
     </code>
    </li>
    <li>
     <code>
      StandardScaler(withMean=True, withStd=True)
     </code>
     →
     <code>
      features
     </code>
    </li>
   </ul>
   <p>
    The final input dimension (
    <code>
     INPUT_DIM
    </code>
    ) is derived from the length of the assembled feature vector.
   </p>
   <h3 id="5.5.5-High-Throughput-PyTorch-Input-Pipeline-(MDS-Streaming-+-Sharding)">
    5.5.5 High-Throughput PyTorch Input Pipeline (MDS Streaming + Sharding)
    <a class="anchor-link" href="#5.5.5-High-Throughput-PyTorch-Input-Pipeline-(MDS-Streaming-+-Sharding)">
     ¶
    </a>
   </h3>
   <p>
    To avoid repeated Spark→Python conversions and to prevent driver bottlenecks, the pipeline converts Spark data into
    <strong>
     MosaicML Streaming (MDS)
    </strong>
    format and trains from disk-backed shards. This was essential to make the
    <strong>
     full-scale model
    </strong>
    feasible.
   </p>
   <p>
    <strong>
     Conversion
    </strong>
   </p>
   <ul>
    <li>
     Sharded datasets are written under:
     <ul>
      <li>
       <code>
        /dbfs/student-groups/Group_4_4/mds_data/train
       </code>
      </li>
      <li>
       <code>
        /dbfs/student-groups/Group_4_4/mds_data/val
       </code>
      </li>
      <li>
       <code>
        /dbfs/student-groups/Group_4_4/mds_data/test
       </code>
      </li>
     </ul>
    </li>
    <li>
     A local staging directory (e.g.,
     <code>
      /local_disk0/tmp_mds_conversion
     </code>
     ) is used to build shards before copying to DBFS.
    </li>
    <li>
     Sharding is paired with repartitioning and iterator-based writing to keep memory usage stable and ensure consistent throughput.
    </li>
   </ul>
   <p>
    <strong>
     Loading
    </strong>
   </p>
   <ul>
    <li>
     <code>
      StreamingDataset
     </code>
     with a local cache directory
    </li>
    <li>
     Custom
     <code>
      collate_fn
     </code>
     reconstructs
     <code>
      float32
     </code>
     tensors from stored bytes and returns
     <code>
      (X, y)
     </code>
     efficiently
    </li>
   </ul>
   <p>
    This approach enables large-scale training runs without collecting feature matrices to the driver and keeps GPU utilization higher by minimizing I/O stalls.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="5.5.6-CNN-Models-Implemented-(Two-Configurations)">
    5.5.6 CNN Models Implemented (Two Configurations)
    <a class="anchor-link" href="#5.5.6-CNN-Models-Implemented-(Two-Configurations)">
     ¶
    </a>
   </h3>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_029_8e3da59d.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="5.5.6.1-Model-A-%E2%80%94-%E2%80%9CIteration-Model%E2%80%9D-(Tiny-subset-for-rapid-validation)">
    5.5.6.1 Model A — “Iteration Model” (Tiny subset for rapid validation)
    <a class="anchor-link" href="#5.5.6.1-Model-A-%E2%80%94-%E2%80%9CIteration-Model%E2%80%9D-(Tiny-subset-for-rapid-validation)">
     ¶
    </a>
   </h4>
   <p>
    This configuration prioritizes quick iteration on a
    <strong>
     tiny (0.5%) subset
    </strong>
    (train/val/test) to validate:
   </p>
   <ul>
    <li>
     end-to-end data pipeline (Spark → MDS)
    </li>
    <li>
     training loop correctness
    </li>
    <li>
     metric computation and threshold selection
    </li>
   </ul>
   <p>
    <strong>
     Architecture
    </strong>
   </p>
   <ul>
    <li>
     Convolution blocks:
     <ul>
      <li>
       (filters=253, kernel=7, pool=2)
      </li>
      <li>
       (filters=163, kernel=5, pool=2)
      </li>
      <li>
       (filters=33, kernel=5, pool=2)
      </li>
     </ul>
    </li>
    <li>
     Dense layers:
     <code>
      [93]
     </code>
    </li>
    <li>
     Dropout:
     <code>
      0.3031
     </code>
    </li>
   </ul>
   <p>
    <strong>
     Training configuration
    </strong>
   </p>
   <ul>
    <li>
     Batch size:
     <code>
      32
     </code>
    </li>
    <li>
     Optimizer: Adam (
     <code>
      lr ≈ 4.5e-4
     </code>
     )
    </li>
    <li>
     Early stopping:
     <code>
      patience=20
     </code>
     ,
     <code>
      min_delta=0.001
     </code>
    </li>
   </ul>
   <h4 id="5.5.6.2-Model-B-%E2%80%94-%E2%80%9CFull-Scale-Model%E2%80%9D-(Full-val/test;-undersampled-training)">
    5.5.6.2 Model B — “Full-Scale Model” (Full val/test; undersampled training)
    <a class="anchor-link" href="#5.5.6.2-Model-B-%E2%80%94-%E2%80%9CFull-Scale-Model%E2%80%9D-(Full-val/test;-undersampled-training)">
     ¶
    </a>
   </h4>
   <p>
    This configuration completes training and testing at full evaluation scale:
   </p>
   <ul>
    <li>
     <strong>
      Training split is undersampled to 50:50
     </strong>
     and persisted to:
     <ul>
      <li>
       <code>
        dbfs:/student-groups/Group_4_4/undersampled_cp6_train_2015_2017_refined.parquet
       </code>
      </li>
     </ul>
    </li>
    <li>
     <strong>
      Validation and test are evaluated on the full datasets
     </strong>
     , with the full 2019 test set used for final metrics.
    </li>
    <li>
     The full-scale run relies on
     <strong>
      MDS streaming + sharding
     </strong>
     to remain operationally feasible in Databricks.
    </li>
   </ul>
   <p>
    <strong>
     Architecture
    </strong>
   </p>
   <ul>
    <li>
     Convolution blocks:
     <ul>
      <li>
       (filters=64, kernel=5, pool=2)
      </li>
      <li>
       (filters=32, kernel=3, pool=2)
      </li>
      <li>
       (filters=16, kernel=3, pool=2)
      </li>
     </ul>
    </li>
    <li>
     Dense layers:
     <code>
      [32]
     </code>
    </li>
    <li>
     Dropout:
     <code>
      0.2
     </code>
    </li>
   </ul>
   <p>
    <strong>
     Training configuration
    </strong>
   </p>
   <ul>
    <li>
     Batch size:
     <code>
      2048
     </code>
    </li>
    <li>
     Optimizer: Adam (
     <code>
      lr=0.001
     </code>
     )
    </li>
    <li>
     Epoch budget:
     <code>
      30
     </code>
    </li>
    <li>
     (Full-scale model architecture had to be optimized to be able to train in a reasonable time)
    </li>
   </ul>
   <h3 id="5.5.7-Checkpointing-and-Run-Artifacts">
    5.5.7 Checkpointing and Run Artifacts
    <a class="anchor-link" href="#5.5.7-Checkpointing-and-Run-Artifacts">
     ¶
    </a>
   </h3>
   <p>
    Each notebook persists model and training artifacts to DBFS:
   </p>
   <p>
    <strong>
     Model A
    </strong>
   </p>
   <ul>
    <li>
     Best checkpoint:
     <code>
      /dbfs/student-groups/Group_4_4/best_model.pth
     </code>
    </li>
    <li>
     Training history:
     <code>
      /dbfs/student-groups/Group_4_4/training_history.json
     </code>
    </li>
    <li>
     Results report:
     <code>
      /dbfs/student-groups/Group_4_4/cnn_pytorch_results.json
     </code>
    </li>
   </ul>
   <p>
    <strong>
     Model B
    </strong>
   </p>
   <ul>
    <li>
     Best checkpoint:
     <code>
      /dbfs/student-groups/Group_4_4/best_model_single.pth
     </code>
    </li>
    <li>
     Training history:
     <code>
      /dbfs/student-groups/Group_4_4/training_history_single.json
     </code>
    </li>
    <li>
     Results report:
     <code>
      /dbfs/student-groups/Group_4_4/cnn_pytorch_results_single.json
     </code>
    </li>
   </ul>
   <h3 id="5.5.8-Test-Evaluation-and-Threshold-Optimization">
    5.5.8 Test Evaluation and Threshold Optimization
    <a class="anchor-link" href="#5.5.8-Test-Evaluation-and-Threshold-Optimization">
     ¶
    </a>
   </h3>
   <p>
    After training, both models run inference on the test MDS dataset, compute classification metrics, and then perform a
    <strong>
     threshold sweep
    </strong>
    over
    <code>
     [0.01 … 0.99]
    </code>
    to select an inference threshold optimized for
    <strong>
     F2
    </strong>
    (β=2), emphasizing recall under class imbalance.
   </p>
   <h4 id="5.5.9-1D-CNN-(PyTorch)-Loss-Function">
    5.5.9 1D CNN (PyTorch) Loss Function
    <a class="anchor-link" href="#5.5.9-1D-CNN-(PyTorch)-Loss-Function">
     ¶
    </a>
   </h4>
   <p>
    The CNN classifier minimizes the
    <strong>
     cross-entropy loss
    </strong>
    for binary classification (implemented as a 2-class softmax in PyTorch):
   </p>
   <p>
    $$
L(\mathbf{y}, \hat{\mathbf{p}}) = - \sum_{c \in \{0,1\}} y_c \, \log(\hat{p}_c)
$$
   </p>
   <p>
    In the notebook, this is implemented with
    <strong>
     class-weighted cross entropy
    </strong>
    to address class imbalance:
   </p>
   <p>
    $$
L(\mathbf{y}, \hat{\mathbf{p}}) = - \sum_{c \in \{0,1\}} w_c \, y_c \, \log(\hat{p}_c)
$$
   </p>
   <p>
    where:
$$\mathbf{y} = [y_0, y_1]\$$ is the one-hot encoded true label (derived from `DEP_DEL15`)
$$\hat{\mathbf{p}} = [\hat{p}_0, \hat{p}_1] = \mathrm{softmax}(\mathbf{z})$$ are predicted class probabilities
$$\mathbf{z} = [z_0, z_1]\$$ are the CNN output logits (pre-softmax)
$$w_c$$ is the class weight for class (c), computed from the training distribution and passed as
    <code>
     weight
    </code>
    to
    <code>
     nn.CrossEntropyLoss
    </code>
   </p>
   <ul>
    <li>
     The model parameters are optimized with Adam via backpropagation to minimize the average loss over minibatches
    </li>
   </ul>
   <h3 id="5.5.10-Results-Summary-(Two-CNN-Models)">
    5.5.10 Results Summary (Two CNN Models)
    <a class="anchor-link" href="#5.5.10-Results-Summary-(Two-CNN-Models)">
     ¶
    </a>
   </h3>
   <p>
    <strong>
     Test-set size context
    </strong>
   </p>
   <ul>
    <li>
     Model A results are on a
     <strong>
      tiny test subset
     </strong>
     (N=36,349; ~0.5% of test).
    </li>
    <li>
     Model B results are on the
     <strong>
      full 2019 test set
     </strong>
     (N=7,259,007).
    </li>
   </ul>
   <table>
    <thead>
     <tr>
      <th>
       Metric
      </th>
      <th style="text-align:right">
       Model A (Tiny subset)
      </th>
      <th style="text-align:right">
       Model B (Full test; undersampled training)
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       Conv blocks
      </td>
      <td style="text-align:right">
       (253,7,2) → (163,5,2) → (33,5,2)
      </td>
      <td style="text-align:right">
       (64,5,2) → (32,3,2) → (16,3,2)
      </td>
     </tr>
     <tr>
      <td>
       Dense layers / Dropout
      </td>
      <td style="text-align:right">
       [93] / 0.3031
      </td>
      <td style="text-align:right">
       [32] / 0.2
      </td>
     </tr>
     <tr>
      <td>
       Batch size / LR
      </td>
      <td style="text-align:right">
       32 / ~4.5e-4
      </td>
      <td style="text-align:right">
       2048 / 1e-3
      </td>
     </tr>
     <tr>
      <td>
       Test AUC-ROC
      </td>
      <td style="text-align:right">
       0.8543
      </td>
      <td style="text-align:right">
       0.8658
      </td>
     </tr>
     <tr>
      <td>
       Test AUC-PR
      </td>
      <td style="text-align:right">
       0.6525
      </td>
      <td style="text-align:right">
       0.6639
      </td>
     </tr>
     <tr>
      <td>
       Default threshold (0.50) Precision
      </td>
      <td style="text-align:right">
       0.5362
      </td>
      <td style="text-align:right">
       0.7232
      </td>
     </tr>
     <tr>
      <td>
       Default threshold (0.50) Recall
      </td>
      <td style="text-align:right">
       0.6528
      </td>
      <td style="text-align:right">
       0.4926
      </td>
     </tr>
     <tr>
      <td>
       Default threshold (0.50) F1
      </td>
      <td style="text-align:right">
       0.5888
      </td>
      <td style="text-align:right">
       0.5860
      </td>
     </tr>
     <tr>
      <td>
       Default threshold (0.50) F2
      </td>
      <td style="text-align:right">
       0.6256
      </td>
      <td style="text-align:right">
       0.5262
      </td>
     </tr>
     <tr>
      <td>
       Best F1 (threshold)
      </td>
      <td style="text-align:right">
       0.5972 (0.57)
      </td>
      <td style="text-align:right">
       0.6175 (0.35)
      </td>
     </tr>
     <tr>
      <td>
       Best F2 (threshold)
      </td>
      <td style="text-align:right">
       0.6630 (0.31)
      </td>
      <td style="text-align:right">
       0.6802 (0.17)
      </td>
     </tr>
     <tr>
      <td>
       Recommended inference threshold (F2)
      </td>
      <td style="text-align:right">
       0.31
      </td>
      <td style="text-align:right">
       0.17
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Confusion matrix at default threshold (0.50)
    </strong>
   </p>
   <ul>
    <li>
     Model A (tiny subset):
     <code>
      [[25702, 3842], [2363, 4442]]
     </code>
    </li>
    <li>
     Model B (full test):
     <code>
      [[5652701, 254844], [685686, 665776]]
     </code>
    </li>
   </ul>
   <h3 id="5.5.11-Interpretation-and-Follow-On-Improvements">
    5.5.11 Interpretation and Follow-On Improvements
    <a class="anchor-link" href="#5.5.11-Interpretation-and-Follow-On-Improvements">
     ¶
    </a>
   </h3>
   <ul>
    <li>
     <strong>
      MDS streaming + sharding enabled the full-scale run:
     </strong>
     Without sharded streaming datasets, the full model would not be feasible due to Spark→Python conversion costs and driver memory pressure. The MDS approach stabilized throughput and reduced training I/O bottlenecks.
    </li>
    <li>
     <strong>
      Full-scale model shows strong ranking quality:
     </strong>
     Model B achieves strong AUC-ROC and AUC-PR, but at default threshold (0.50) it is
     <strong>
      precision-heavy
     </strong>
     and
     <strong>
      recall-limited
     </strong>
     . Threshold optimization is therefore required to align with a recall-prioritizing objective.
    </li>
    <li>
     <strong>
      F2-optimized threshold materially changes operating behavior:
     </strong>
     For Model B, selecting the F2-optimal threshold (0.17) yields the strongest recall-weighted performance and provides a clearer operational configuration for stakeholders.
    </li>
   </ul>
   <p>
    <strong>
     Follow-on improvements (if time permits)
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Revisit distributed training for the full-scale model:
     </strong>
     The “big model” could not be run in distributed mode due to
     <strong>
      GPU memory pressure and synchronization instability
     </strong>
     (DDP overhead, state synchronization, and intermittent failures). Future work should explore:
     <ul>
      <li>
       smaller per-GPU batch sizes + gradient accumulation
      </li>
      <li>
       mixed precision (AMP)
      </li>
      <li>
       activation checkpointing
      </li>
      <li>
       simplified metric synchronization (reduce all-gathers) and checkpointing frequency
      </li>
     </ul>
    </li>
    <li>
     Add explicit AMP/mixed precision using
     <code>
      torch.cuda.amp.autocast()
     </code>
     +
     <code>
      GradScaler
     </code>
     to reduce memory footprint and increase throughput.
    </li>
    <li>
     Consider probability calibration (e.g., temperature scaling) to stabilize threshold selection across time.
    </li>
    <li>
     Because CNNs are order-sensitive, test feature ordering/grouping strategies (temporal/weather/network/rolling-stat blocks) and compare against a PyTorch MLP trained on the exact same MDS pipeline for a controlled architecture comparison.
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="5.6-Regression">
    5.6 Regression
    <a class="anchor-link" href="#5.6-Regression">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="5.6.1-Data-Preparation-for-Regression-Model">
    5.6.1 Data Preparation for Regression Model
    <a class="anchor-link" href="#5.6.1-Data-Preparation-for-Regression-Model">
     ¶
    </a>
   </h5>
   <p>
    We started with the cleaned and feature engineered custom joined 5 year data for 2015-2019. The last 1 year was used for evaluation. The first four years (2015-2018) were used for training. The categorical features were one hot encoded.
   </p>
   <h6 id="High-Cardinal-Features">
    High Cardinal Features
    <a class="anchor-link" href="#High-Cardinal-Features">
     ¶
    </a>
   </h6>
   <p>
    High Cardinal features like
    <strong>
     origin
    </strong>
    ,
    <strong>
     dest
    </strong>
    ,
    <strong>
     origin_state
    </strong>
    ,
    <strong>
     dest_state
    </strong>
    were replaced with their target encoded feature. So, for origin, we encoded using the average value for the target feature which is delay value at the origin. Similarly, destination was encoded using the average value for delay at the destination.
    <strong>
     Flight_Id
    </strong>
    and
    <strong>
     tail_num
    </strong>
    was dropped as it is very high cardinal value and does not provide as much useful information for predicting delay. Later, time permitting, we may revisit flight_id and tail_num to encode it using Binarizer logic.
   </p>
   <h6 id="Class-Imbalance">
    Class Imbalance
    <a class="anchor-link" href="#Class-Imbalance">
     ¶
    </a>
   </h6>
   <p>
    Class Imbalance was handled using a few approaches. Class-weights was used initially, followed by undersampling of the majority class. Undersampling makes sense because we have a lot of data for the flights on time, so if reduce some of the ontime flight data, not much information is lost. If we were to try the approach of oversampling the minority class, then we would have too much data volume which would make it hard to process efficiently. Further, the synthetic data created for oversampling would risk introducing overfitting or unreal patterns. So. we decided to go with undersampling of majority class.
We decided to undersample the majority class such that the ratio of minority class to majority class is
    <strong>
     0.5
    </strong>
    . We also tried
    <strong>
     1.0
    </strong>
    sampling ratio.
   </p>
   <h6 id="Outlier-Data">
    Outlier Data
    <a class="anchor-link" href="#Outlier-Data">
     ¶
    </a>
   </h6>
   <p>
    DEP_DELAY: The target variable Departure delay has a wide range of values ranging from negative numbers (early) to hundreds of minutes. To prevent the effect of the outliers, first, we replaced the
    <strong>
     negative values with zero
    </strong>
    , then we took the
    <strong>
     log(DEP_DELAY + 1)
    </strong>
    to prevent log(0) error. This reduced the impact of outliers.
   </p>
   <p>
    Rolling_Averages: The rolling averages calculated for the departure delay should also be based on the log value to minimize impact of outlier data.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="5.6.2-Regression-Model-Tuning-Results">
    5.6.2 Regression Model Tuning Results
    <a class="anchor-link" href="#5.6.2-Regression-Model-Tuning-Results">
     ¶
    </a>
   </h5>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    From Phase 2, we had concluded that SparkXGBRegressor gave the performance. We explored this model further in Phase 3.  Results are summarized below.
   </p>
   <h5 id="Grid-Search-Results:-XGBoost-Regressor-with-Time-Series-Cross-Validation-for-Train-2015-2018-and-Holdout-2019">
    Grid Search Results: XGBoost Regressor with Time Series Cross-Validation for Train 2015-2018 and Holdout 2019
    <a class="anchor-link" href="#Grid-Search-Results:-XGBoost-Regressor-with-Time-Series-Cross-Validation-for-Train-2015-2018-and-Holdout-2019">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     Configuration
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Method:
     </strong>
     Rolling Window (train size: 2 chunks)
    </li>
    <li>
     <strong>
      Data Source
     </strong>
     checkpoint_5_final_clean_2015-2019.parquet
    </li>
    <li>
     <strong>
      Train:
     </strong>
     2015-2018
    </li>
    <li>
     <strong>
      Test:
     </strong>
     2019
    </li>
    <li>
     <strong>
      Total Data:
     </strong>
     23,869,884 rows
    </li>
    <li>
     <strong>
      Fold Size:
     </strong>
     4,773,976 rows per fold
    </li>
    <li>
     <strong>
      Number of Folds:
     </strong>
     3
    </li>
    <li>
     <strong>
      Balance Strategy:
     </strong>
     Undersample to 1:1 ratio
    </li>
    <li>
     <strong>
      Selection Metric:
     </strong>
     Weighted average RMSE (more weight on recent folds)
    </li>
   </ul>
   <hr/>
   <h5 id="Parameter-Search-Results">
    Parameter Search Results
    <a class="anchor-link" href="#Parameter-Search-Results">
     ¶
    </a>
   </h5>
   <div class="table-wrapper">
   <table>
    <thead>
     <tr>
      <th>
       #
      </th>
      <th>
       max_depth
      </th>
      <th>
       learning_rate
      </th>
      <th>
       num_round
      </th>
      <th>
       Fold 1 RMSE
      </th>
      <th>
       Fold 2 RMSE
      </th>
      <th>
       Fold 3 RMSE
      </th>
      <th>
       Unweighted Avg RMSE
      </th>
      <th>
       Weighted Avg RMSE
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       1
      </td>
      <td>
       3
      </td>
      <td>
       0.05
      </td>
      <td>
       50
      </td>
      <td>
       1.4790
      </td>
      <td>
       1.4679
      </td>
      <td>
       1.5293
      </td>
      <td>
       1.4921
      </td>
      <td>
       1.5046
      </td>
     </tr>
     <tr>
      <td>
       2
      </td>
      <td>
       3
      </td>
      <td>
       0.05
      </td>
      <td>
       100
      </td>
      <td>
       1.4290
      </td>
      <td>
       1.4124
      </td>
      <td>
       1.4781
      </td>
      <td>
       1.4398
      </td>
      <td>
       1.4523
      </td>
     </tr>
     <tr>
      <td>
       3
      </td>
      <td>
       3
      </td>
      <td>
       0.10
      </td>
      <td>
       50
      </td>
      <td>
       1.4305
      </td>
      <td>
       1.4130
      </td>
      <td>
       1.4801
      </td>
      <td>
       1.4412
      </td>
      <td>
       1.4538
      </td>
     </tr>
     <tr>
      <td>
       4
      </td>
      <td>
       3
      </td>
      <td>
       0.10
      </td>
      <td>
       100
      </td>
      <td>
       1.3929
      </td>
      <td>
       1.3751
      </td>
      <td>
       1.4371
      </td>
      <td>
       1.4017
      </td>
      <td>
       1.4131
      </td>
     </tr>
     <tr>
      <td>
       5
      </td>
      <td>
       5
      </td>
      <td>
       0.05
      </td>
      <td>
       50
      </td>
      <td>
       1.4167
      </td>
      <td>
       1.4084
      </td>
      <td>
       1.4679
      </td>
      <td>
       1.4310
      </td>
      <td>
       1.4436
      </td>
     </tr>
     <tr>
      <td>
       6
      </td>
      <td>
       5
      </td>
      <td>
       0.05
      </td>
      <td>
       100
      </td>
      <td>
       1.3723
      </td>
      <td>
       1.3589
      </td>
      <td>
       1.4176
      </td>
      <td>
       1.3829
      </td>
      <td>
       1.3944
      </td>
     </tr>
     <tr>
      <td>
       7
      </td>
      <td>
       5
      </td>
      <td>
       0.10
      </td>
      <td>
       50
      </td>
      <td>
       1.3700
      </td>
      <td>
       1.3577
      </td>
      <td>
       1.4177
      </td>
      <td>
       1.3818
      </td>
      <td>
       1.3937
      </td>
     </tr>
     <tr>
      <td>
       8
      </td>
      <td>
       5
      </td>
      <td>
       0.10
      </td>
      <td>
       100
      </td>
      <td>
       1.3384
      </td>
      <td>
       1.3213
      </td>
      <td>
       1.3786
      </td>
      <td>
       1.3461
      </td>
      <td>
       1.3565
      </td>
     </tr>
     <tr>
      <td>
       9
      </td>
      <td>
       7
      </td>
      <td>
       0.05
      </td>
      <td>
       50
      </td>
      <td>
       1.3838
      </td>
      <td>
       1.3735
      </td>
      <td>
       1.4260
      </td>
      <td>
       1.3944
      </td>
      <td>
       1.4050
      </td>
     </tr>
     <tr>
      <td>
       10
      </td>
      <td>
       7
      </td>
      <td>
       0.05
      </td>
      <td>
       100
      </td>
      <td>
       1.3384
      </td>
      <td>
       1.3232
      </td>
      <td>
       1.3737
      </td>
      <td>
       1.3451
      </td>
      <td>
       1.3542
      </td>
     </tr>
     <tr>
      <td>
       11
      </td>
      <td>
       7
      </td>
      <td>
       0.10
      </td>
      <td>
       50
      </td>
      <td>
       1.3375
      </td>
      <td>
       1.3239
      </td>
      <td>
       1.3740
      </td>
      <td>
       1.3451
      </td>
      <td>
       1.3545
      </td>
     </tr>
     <tr>
      <td>
       12
      </td>
      <td>
       7
      </td>
      <td>
       0.10
      </td>
      <td>
       100
      </td>
      <td>
       1.3066
      </td>
      <td>
       1.2866
      </td>
      <td>
       1.3396
      </td>
      <td>
       1.3109
      </td>
      <td>
       <strong>
        1.3197
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
   </div>
   <hr/>
   <h5 id="Best-Parameters">
    Best Parameters
    <a class="anchor-link" href="#Best-Parameters">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th>
       Parameter
      </th>
      <th>
       Value
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        max_depth
       </strong>
      </td>
      <td>
       7
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        learning_rate
       </strong>
      </td>
      <td>
       0.1
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        num_round
       </strong>
      </td>
      <td>
       100
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        Best Weighted RMSE
       </strong>
      </td>
      <td>
       1.3197
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Key-Observations">
    Key Observations
    <a class="anchor-link" href="#Key-Observations">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     1. Parameter Impact:
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Parameter
      </th>
      <th>
       Effect
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        max_depth
       </strong>
      </td>
      <td>
       Deeper trees (7 &gt; 5 &gt; 3) consistently improved performance
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        learning_rate
       </strong>
      </td>
      <td>
       Higher rate (0.1 &gt; 0.05) performed better
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        num_round
       </strong>
      </td>
      <td>
       More rounds (100 &gt; 50) improved performance
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     2. Fold Pattern:
    </strong>
   </p>
   <ul>
    <li>
     Fold 2 consistently had the lowest RMSE across all parameter sets
    </li>
    <li>
     Fold 3 (most recent) consistently had the highest RMSE
    </li>
    <li>
     This suggests slight performance degradation over time (data drift)
    </li>
   </ul>
   <p>
    <strong>
     3. Weighted vs Unweighted:
    </strong>
   </p>
   <ul>
    <li>
     Weighted average was consistently ~0.01 higher than unweighted
    </li>
    <li>
     This is because Fold 3 (weighted more heavily) had higher errors
    </li>
    <li>
     Difference ranged from 0.0088 to 0.0126
    </li>
   </ul>
   <p>
    <strong>
     4. Improvement Progression:
    </strong>
   </p>
   <table>
    <thead>
     <tr>
      <th>
       Parameter Set
      </th>
      <th>
       Weighted RMSE
      </th>
      <th>
       Improvement from Baseline
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       #1 (baseline)
      </td>
      <td>
       1.5046
      </td>
      <td>
       -
      </td>
     </tr>
     <tr>
      <td>
       #12 (best)
      </td>
      <td>
       1.3197
      </td>
      <td>
       <strong>
        12.3% improvement
       </strong>
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Training-Details">
    Training Details
    <a class="anchor-link" href="#Training-Details">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th style="text-align:center">
       Fold
      </th>
      <th>
       Train Range
      </th>
      <th>
       Test Range
      </th>
      <th style="text-align:right">
       Training Points (after balance)
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:center">
       1
      </td>
      <td>
       Rows 1 - 9.5M
      </td>
      <td>
       Rows 9.5M - 14.3M
      </td>
      <td style="text-align:right">
       ~3.46M
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       2
      </td>
      <td>
       Rows 4.8M - 14.3M
      </td>
      <td>
       Rows 14.3M - 19.1M
      </td>
      <td style="text-align:right">
       ~3.44M
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       3
      </td>
      <td>
       Rows 9.5M - 19.1M
      </td>
      <td>
       Rows 19.1M - 23.9M
      </td>
      <td style="text-align:right">
       ~3.34M
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Recommendation">
    Recommendation
    <a class="anchor-link" href="#Recommendation">
     ¶
    </a>
   </h5>
   <p>
    The optimal configuration
    <code>
     {max_depth: 7, learning_rate: 0.1, num_round: 100}
    </code>
    should be used for final model training. Consider:
   </p>
   <ol>
    <li>
     Testing even deeper trees (max_depth: 9)
    </li>
    <li>
     Adding regularization (reg_alpha, reg_lambda) to prevent overfitting with deeper trees
    </li>
    <li>
     Increasing num_round with lower learning_rate for potentially better generalization
    </li>
   </ol>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <table>
    <thead>
     <tr>
      <th>
       Metric
      </th>
      <th>
       CV Average (2015-2018)
      </th>
      <th>
       Holdout (2019)
      </th>
      <th>
       Difference
      </th>
      <th>
       % Change
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        RMSE
       </strong>
      </td>
      <td>
       35.1809
      </td>
      <td>
       42.9074
      </td>
      <td>
      </td>
      <td>
       ** %**
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        MAE
       </strong>
      </td>
      <td>
       10.9483
      </td>
      <td>
       12.27
      </td>
      <td>
      </td>
      <td>
       ** %**
      </td>
     </tr>
    </tbody>
   </table>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="5.7-Summary-of-all-ML-Experiments">
    5.7 Summary of all ML Experiments
    <a class="anchor-link" href="#5.7-Summary-of-all-ML-Experiments">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Comprehensive-Modeling-Approach-Summary">
    Comprehensive Modeling Approach Summary
    <a class="anchor-link" href="#Comprehensive-Modeling-Approach-Summary">
     ¶
    </a>
   </h5>
   <p>
    Our flight delay prediction project explored two parallel approaches:
    <strong>
     direct classification
    </strong>
    and
    <strong>
     regression-to-classification
    </strong>
    .
   </p>
   <p>
    <strong>
     Direct Classification Approaches:
    </strong>
    We implemented multiple classification architectures to directly predict delay occurrence (DEP_DEL15). Baseline
    <strong>
     Logistic Regression
    </strong>
    with engineered features achieved F2=0.595 and AuPRC=0.566. Traditional tree-based classifiers including
    <strong>
     Random Forest
    </strong>
    (F2=0.610, AuPRC=0.664) and
    <strong>
     Gradient Boosted Trees
    </strong>
    (F2=0.625, AuPRC=0.719) showed moderate improvement.
    <strong>
     Multi-Layer Perceptron (MLP)
    </strong>
    neural networks with various undersampling strategies (40:60 and 50:50) achieved F2 scores of 0.662 and 0.658 respectively, with high recall (~82%) but lower precision. A
    <strong>
     3-model MLP ensemble
    </strong>
    averaging predictions from multiple configurations yielded F2=0.648. The best direct classification result came from a
    <strong>
     1D Convolutional Neural Network (CNN)
    </strong>
    trained on full-scale data with MDS streaming, achieving F2=0.680, recall=0.843, and AuPRC=0.664, though requiring 9,516 seconds of GPU training time.
   </p>
   <p>
    <strong>
     Regression-to-Classification Approach:
    </strong>
    Our regression approach evolved through several phases. We initially implemented a
    <strong>
     two-stage pipeline
    </strong>
    combining a classifier (RandomForest, GBTClassifier, or SparkXGBClassifier) with a regressor (GBTRegressor or SparkXGBRegressor), experimenting with threshold-gated, probability-weighted, and sequential ensemble strategies—achieving test RMSE of ~43 minutes but finding the classifier provided minimal benefit. We then transitioned to a
    <strong>
     regression-only ensemble
    </strong>
    using two SparkXGBRegressor models: one trained with sample weights (1x/2x/2.5x for delays ≤60min/60-120min/&gt;120min) to emphasize severe delays, and one without weights for balanced predictions. These were combined using Max, Min, or Average strategies, with deeper trees (max_depth=11) and regularization (reg_alpha=0.2, reg_lambda=1.0). The
    <strong>
     Max ensemble achieved the best RMSE (41.69 minutes)
    </strong>
    while the
    <strong>
     Min ensemble achieved the best MAE (11.92 minutes)
    </strong>
    . Converting regression outputs to binary predictions using a 15-minute threshold, the
    <strong>
     XGBoost Ensemble (Max) achieved F2=0.697, recall=0.725, and AuPRC=0.723
    </strong>
    —the highest F2 and AuPRC scores across all approaches.
   </p>
   <p>
    <strong>
     Key Findings:
    </strong>
    The regression-to-binary approach outperformed direct classification on F2 score (0.697 vs 0.680 for CNN) and AuPRC (0.723 vs 0.719 for GBT), while the CNN achieved higher recall (0.843 vs 0.725). This demonstrates that optimizing for continuous delay prediction and then thresholding can be more effective than direct binary classification, as the regression model learns richer representations of delay severity that transfer well to the classification task.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <table>
    <thead>
     <tr>
      <th>
       Model
      </th>
      <th>
       Approach
      </th>
      <th>
       Strategy / Notes
      </th>
      <th style="text-align:right">
       Train time (s)
      </th>
      <th style="text-align:right">
       F2_test
      </th>
      <th style="text-align:right">
       Recall_test
      </th>
      <th style="text-align:right">
       AUC_PR
      </th>
      <th>
       Worker configuration
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       MLP 40:60
      </td>
      <td>
       Neural network Classification
      </td>
      <td>
       MLP with 40:60 undersampling
      </td>
      <td style="text-align:right">
       1050.73
      </td>
      <td style="text-align:right">
       0.6620
      </td>
      <td style="text-align:right">
       0.8287
      </td>
      <td style="text-align:right">
       0.5990
      </td>
      <td>
       8× m5d.2xlarge (32GB, 8 cores)
      </td>
     </tr>
     <tr>
      <td>
       MLP 50:50
      </td>
      <td>
       Neural network Classification
      </td>
      <td>
       MLP with 50:50 undersampling
      </td>
      <td style="text-align:right">
       1345.19
      </td>
      <td style="text-align:right">
       0.6582
      </td>
      <td style="text-align:right">
       0.8208
      </td>
      <td style="text-align:right">
       0.6017
      </td>
      <td>
       8× m5d.2xlarge (32GB, 8 cores)
      </td>
     </tr>
     <tr>
      <td>
       3-model Ensemble
      </td>
      <td>
       Neural network ensemble Classification
      </td>
      <td>
       Average of 50:50, 40:60, class-weighted MLPs
      </td>
      <td style="text-align:right">
       4736.61
      </td>
      <td style="text-align:right">
       0.6477
      </td>
      <td style="text-align:right">
       0.7721
      </td>
      <td style="text-align:right">
       0.5831
      </td>
      <td>
       8× m5d.2xlarge (32GB, 8 cores)
      </td>
     </tr>
     <tr>
      <td>
       CNN (PyTorch) — Model B (full-scale)
      </td>
      <td>
       Neural network Classification
      </td>
      <td>
       1D CNN + MDS streaming &amp; sharding; training on 50:50 undersampled train; evaluated on full 2019 test;
       <strong>
        F2-optimal threshold=0.17
       </strong>
      </td>
      <td style="text-align:right">
       9516
      </td>
      <td style="text-align:right">
       0.6802
      </td>
      <td style="text-align:right">
       0.8428
      </td>
      <td style="text-align:right">
       0.6639
      </td>
      <td>
       1× g4dn.xlarge (T4, 16GB, 1 GPU)
      </td>
     </tr>
     <tr>
      <td>
       CNN (PyTorch) — Model A (subset)
      </td>
      <td>
       Neural network Classification
      </td>
      <td>
       1D CNN + MDS streaming; trained/evaluated on 0.5% subset for architecture validation;
       <strong>
        F2-optimal threshold=0.31
       </strong>
      </td>
      <td style="text-align:right">
       2880
      </td>
      <td style="text-align:right">
       0.6630
      </td>
      <td style="text-align:right">
       0.6516
      </td>
      <td style="text-align:right">
       0.6525
      </td>
      <td>
       2× g4dn.xlarge (T4, 16GB, 1 GPU)
      </td>
     </tr>
     <tr>
      <td>
       GBT
      </td>
      <td>
       Tree-based
      </td>
      <td>
       Gradient-Boosted Trees, tuned config
      </td>
      <td style="text-align:right">
       1232
      </td>
      <td style="text-align:right">
       0.6245
      </td>
      <td style="text-align:right">
       0.6206
      </td>
      <td style="text-align:right">
       0.7191
      </td>
      <td>
       12× m5d.2xlarge (32GB, 8 cores) + 2× g4dn.xlarge (T4, 16GB, 1 GPU)
      </td>
     </tr>
     <tr>
      <td>
       RF (Phase 3)
      </td>
      <td>
       Tree-based
      </td>
      <td>
       Random Forest, depth=15, 20 trees
      </td>
      <td style="text-align:right">
       679
      </td>
      <td style="text-align:right">
       0.6100
      </td>
      <td style="text-align:right">
       0.6013
      </td>
      <td style="text-align:right">
       0.6639
      </td>
      <td>
       12× m5d.2xlarge (32GB, 8 cores) + 2× g4dn.xlarge (T4, 16GB, 1 GPU)
      </td>
     </tr>
     <tr>
      <td>
       LR + features
      </td>
      <td>
       Linear model
      </td>
      <td>
       Logistic regression, engineered features
      </td>
      <td style="text-align:right">
       161
      </td>
      <td style="text-align:right">
       0.5950
      </td>
      <td style="text-align:right">
       0.6450
      </td>
      <td style="text-align:right">
       0.5662
      </td>
      <td>
       12× m5d.2xlarge (32GB, 8 cores) + 2× g4dn.xlarge (T4, 16GB, 1 GPU)
      </td>
     </tr>
     <tr>
      <td>
       RF (Phase 2)
      </td>
      <td>
       Tree-based
      </td>
      <td>
       Random Forest, engineered features
      </td>
      <td style="text-align:right">
       211
      </td>
      <td style="text-align:right">
       0.4046
      </td>
      <td style="text-align:right">
       0.3611
      </td>
      <td style="text-align:right">
       0.6244
      </td>
      <td>
       12× m5d.2xlarge (32GB, 8 cores) + 2× g4dn.xlarge (T4, 16GB, 1 GPU)
      </td>
     </tr>
     <tr>
      <td>
       MLP (class weights)
      </td>
      <td>
       Neural network Classification
      </td>
      <td>
       MLP with class weights
      </td>
      <td style="text-align:right">
       2340.69
      </td>
      <td style="text-align:right">
       0.1545
      </td>
      <td style="text-align:right">
       0.1387
      </td>
      <td style="text-align:right">
       0.2347
      </td>
      <td>
       8× m5d.2xlarge (32GB, 8 cores)
      </td>
     </tr>
     <tr>
      <td>
       Baseline LR
      </td>
      <td>
       Linear model
      </td>
      <td>
       Logistic regression, non-engineered features
      </td>
      <td style="text-align:right">
       329
      </td>
      <td style="text-align:right">
      </td>
      <td style="text-align:right">
      </td>
      <td style="text-align:right">
       0.5149
      </td>
      <td>
       12× m5d.2xlarge (32GB, 8 cores) + 2× g4dn.xlarge (T4, 16GB, 1 GPU)
      </td>
     </tr>
     <tr>
      <td>
       XGBoost Ensemble (Max)
      </td>
      <td>
       Tree-based Regression → Classification
      </td>
      <td>
       Ensemble of weighted + unweighted XGBRegressor; binary threshold at 15 min; max_depth=11, lr=0.05, n_est=200
      </td>
      <td style="text-align:right">
       1619
      </td>
      <td style="text-align:right">
       0.6970
      </td>
      <td style="text-align:right">
       0.7245
      </td>
      <td style="text-align:right">
       0.7225
      </td>
      <td>
       8× m5d.2xlarge (32GB, 8 cores)
      </td>
     </tr>
    </tbody>
   </table>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_030_5dad8fbe.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h5 id="Ranking-by-F2-Score">
    Ranking by F2 Score
    <a class="anchor-link" href="#Ranking-by-F2-Score">
     ¶
    </a>
   </h5>
   <table>
    <thead>
     <tr>
      <th style="text-align:center">
       Rank
      </th>
      <th>
       Model
      </th>
      <th>
       F2_test
      </th>
      <th>
       Recall_test
      </th>
      <th>
       AUC_PR
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td style="text-align:center">
       1
      </td>
      <td>
       <strong>
        XGBoost Ensemble (Max)
       </strong>
      </td>
      <td>
       <strong>
        0.6970
       </strong>
      </td>
      <td>
       0.7245
      </td>
      <td>
       <strong>
        0.7225
       </strong>
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       2
      </td>
      <td>
       CNN (PyTorch) — Model B
      </td>
      <td>
       0.6802
      </td>
      <td>
       <strong>
        0.8428
       </strong>
      </td>
      <td>
       0.6639
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       3
      </td>
      <td>
       CNN (PyTorch) — Model A
      </td>
      <td>
       0.6630
      </td>
      <td>
       0.6516
      </td>
      <td>
       0.6525
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       4
      </td>
      <td>
       MLP 40:60
      </td>
      <td>
       0.6620
      </td>
      <td>
       0.8287
      </td>
      <td>
       0.5990
      </td>
     </tr>
     <tr>
      <td style="text-align:center">
       5
      </td>
      <td>
       MLP 50:50
      </td>
      <td>
       0.6582
      </td>
      <td>
       0.8208
      </td>
      <td>
       0.6017
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h5 id="Key-Observations">
    Key Observations
    <a class="anchor-link" href="#Key-Observations">
     ¶
    </a>
   </h5>
   <p>
    <strong>
     XGBoost Ensemble (Max) achieves:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Highest F2 score (0.6970)
     </strong>
     among all models
    </li>
    <li>
     <strong>
      Highest AuPRC (0.7225)
     </strong>
     - best overall ranking quality
    </li>
    <li>
     <strong>
      Good recall (72.5%)
     </strong>
     - catches most delays
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_031_565ffe90.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <p>
    <strong>
     Trade-off:
    </strong>
   </p>
   <ul>
    <li>
     CNN Model B has higher recall (84.3% vs 72.5%)
    </li>
    <li>
     But XGBoost has better F2 and AuPRC
    </li>
   </ul>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="5.8-Future-proofing--(time,-graph,-MLP)">
    5.8 Future-proofing  (time, graph, MLP)
    <a class="anchor-link" href="#5.8-Future-proofing--(time,-graph,-MLP)">
     ¶
    </a>
   </h2>
   <p>
    The client wants to see
    <strong>
     three
    </strong>
    things and we are already aligned with them:
   </p>
   <ol>
    <li>
     <strong>
      Time series
     </strong>
     : we are already doing time-ordered CV and “as-of” weather joins, so we can legitimately say we are treating the data as time-dependent.
    </li>
    <li>
     <strong>
      Graph
     </strong>
     : we built the airport/carrier network  (nodes = airports or carriers; edges = historical flights; weights = volume or delay rate), to compute PageRank/degree/centrality and
     <strong>
      feed those as extra columns
     </strong>
     to the same Stage-1 classifier. That gives us the “graph” angle without rewriting everything.
    </li>
    <li>
     <strong>
      MLP / NN
     </strong>
     : In phase 3, once we have the stable, leakage-free feature table in Spark, we can train
     <strong>
      Spark ML’s MLP classifier
     </strong>
     on the same target and compare it to the trees.
    </li>
   </ol>
   <p>
    On top of that — and to keep the spirit of the original plan — we can add an
    <strong>
     experimental multi-task MLP
    </strong>
    in Phase 3: same shared layers,
    <strong>
     two heads
    </strong>
    (one for
    <code>
     DEP_DEL15
    </code>
    with binary cross-entropy, one for delay minutes with MSE), and a
    <strong>
     weighted sum
    </strong>
    of both losses so we can still optimize for “don’t miss delays” while also learning magnitudes. That gives us a modern model to show, but it still respects
    <strong>
     all
    </strong>
    the  leakage rules.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="6.-Metrics:">
    6. Metrics:
    <a class="anchor-link" href="#6.-Metrics:">
     ¶
    </a>
   </h2>
   <p>
    Because our target is
    <strong>
     “predict a 15-minute-or-more departure delay two hours before pushback,”
    </strong>
    the main risk is
    <strong>
     predicting a false delay
    </strong>
    , not missing a real delay. The 3-month OTPW sample is imbalanced (≈20% delayed vs. 80% on time), so accuracy alone would hide bad models — a classifier that always says “on time” would score ~0.80 and still be useless for operations. For that reason we will use a
    <strong>
     precision-friendly primary metric
    </strong>
    and then add a small set of secondary metrics so we can compare across models and across airports.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="6.1-Primary-classification-metric:-F0.5">
    6.1 Primary classification metric: F0.5
    <a class="anchor-link" href="#6.1-Primary-classification-metric:-F0.5">
     ¶
    </a>
   </h4>
   <p>
    We will use
    <strong>
     F0.5
    </strong>
    as the main metric because it weights
    <strong>
     precision
    </strong>
    higher than recall. Our dataset is highly imbalanced (≈20% delayed flights). Unlike F1, which gives equal importance to Precision and Recall, and unlike F2, which gives preference to Recall over Precision, F0.5 gives higher weight to Precision over Recall which is what we need for our problem and is therefore more reliable for this task.
   </p>
   <p>
    In operational terms, F0.5 reflects the model’s ability to precisely flag delayed flights without being dominated by the majority “on-time” class. We compute F0.5 using time-ordered validation splits (train on earlier months → validate on later months) so that performance reflects real-world sequencing rather than random shuffling.
First recall the basic definitions:
   </p>
   <p>
    $$
\text{Precision} = \frac{TP}{TP + FP}
$$
   </p>
   <p>
    $$
\text{Recall} = \frac{TP}{TP + FN}
$$
   </p>
   <p>
    The general F-score is
   </p>
   <p>
    $$
F_{\beta} = (1 + \beta^2)\,\frac{\text{Precision} \cdot \text{Recall}}{(\beta^2 \cdot \text{Precision}) + \text{Recall}}
$$
   </p>
   <p>
    For our case, with (\beta = 0.5),
   </p>
   <p>
    $$
F_{0.5} = 1.25 \cdot \frac{\text{Precision} \cdot \text{Recall}}{0.25 \cdot \text{Precision} + \text{Recall}}
$$
   </p>
   <p>
    We prefer F0.5 because in airline operations a
    <strong>
     false positive
    </strong>
    (we said “will be late” and it wasn’t) causes more downstream cost than a
    <strong>
     false negative
    </strong>
    (we said “on time” but the flight was actually 15+ minutes late, status quo). We will compute (F0.5) on
    <strong>
     time-ordered validation splits
    </strong>
    (train on earlier months → validate on later months) so that the score reflects real-world sequencing.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="6.2-Secondary-classification-metric:-PR-AUC">
    6.2 Secondary classification metric: PR-AUC
    <a class="anchor-link" href="#6.2-Secondary-classification-metric:-PR-AUC">
     ¶
    </a>
   </h4>
   <p>
    We use Precision–Recall AUC (PR-AUC) as our primary evaluation metric because our dataset is highly imbalanced (≈20% delayed flights). Unlike ROC-AUC, which can appear overly optimistic under class imbalance, PR-AUC directly measures how well the model identifies the minority class across all probability thresholds and is therefore more reliable for this task.
   </p>
   <p>
    In operational terms, PR-AUC reflects the model’s ability to correctly flag delayed flights without being dominated by the majority “on-time” class. We compute PR-AUC using time-ordered validation splits (train on earlier months → validate on later months) so that performance reflects real-world sequencing rather than random shuffling.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="6.3-Per-segment-confusion:-carrier-and-airport">
    6.3 Per-segment confusion: carrier and airport
    <a class="anchor-link" href="#6.3-Per-segment-confusion:-carrier-and-airport">
     ¶
    </a>
   </h4>
   <p>
    Because we have
    <strong>
     carrier
    </strong>
    and
    <strong>
     origin airport
    </strong>
    in the features, we will also break down
    <strong>
     confusion matrices
    </strong>
    by carrier and by origin for the top-N airports. This is the answer to the stakeholder question:
    <em>
     “does it work on my hub?”
    </em>
    It also helps us detect join problems (e.g. one airport always missing weather, always predicted “on time”).
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="6.4-Regression-metrics-(Stage-2-only):-MAE-first,-then-RMSE">
    6.4 Regression metrics (Stage 2 only): MAE first, then RMSE
    <a class="anchor-link" href="#6.4-Regression-metrics-(Stage-2-only):-MAE-first,-then-RMSE">
     ¶
    </a>
   </h4>
   <p>
    When we run the
    <strong>
     Stage-2 regression
    </strong>
    (only on flights that Stage 1 marked as delayed), we will evaluate it with
    <strong>
     MAE
    </strong>
    and
    <strong>
     RMSE
    </strong>
    .
   </p>
   <p>
    Mean Absolute Error:
   </p>
   <p>
    $$
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} \lvert y_i - \hat{y}_i \rvert
$$
   </p>
   <p>
    Root Mean Squared Error:
   </p>
   <p>
    $$
\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 }
$$
   </p>
   <ul>
    <li>
     <strong>
      MAE
     </strong>
     is easier to explain to ops (“we’re off by ~6–8 minutes on average”).
    </li>
    <li>
     <strong>
      RMSE
     </strong>
     is good for comparison with prior work and penalizes large errors more.
    </li>
   </ul>
   <p>
    This fits the two-stage design:
    <strong>
     classification
    </strong>
    solves the imbalanced detection problem;
    <strong>
     regression
    </strong>
    is only for the ~20% delayed flights.
   </p>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="6.5-Operational-/-domain-level-views">
    6.5 Operational / domain-level views
    <a class="anchor-link" href="#6.5-Operational-/-domain-level-views">
     ¶
    </a>
   </h4>
   <p>
    To keep the “airline consortium” narrative, we will also show two derived, human-readable metrics:
   </p>
   <ol>
    <li>
     <p>
      <strong>
       Delay coverage at T–2h
      </strong>
      <br/>
      “Out of all flights that actually departed 15+ minutes late, how many did we flag?”
      <br/>
      This is just
      <strong>
       recall
      </strong>
      written in airline language.
     </p>
    </li>
    <li>
     <p>
      <strong>
       Alert volume
      </strong>
      <br/>
      “How many flights per day would we have pinged?”
      <br/>
      This is just the
      <strong>
       count of positive predictions
      </strong>
      and tells ops whether the model is too noisy.
     </p>
    </li>
   </ol>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="8.-Pipeline:">
    8. Pipeline:
    <a class="anchor-link" href="#8.-Pipeline:">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h3 id="Seven-stage-Spark-ML-pipeline-with-explicit-checkpoints">
    Seven-stage Spark ML pipeline with explicit checkpoints
    <a class="anchor-link" href="#Seven-stage-Spark-ML-pipeline-with-explicit-checkpoints">
     ¶
    </a>
   </h3>
   <p>
    In Phase 3, we implemented an
    <strong>
     extended seven-stage Spark ML pipeline
    </strong>
    with
    <strong>
     explicit data checkpoints
    </strong>
    to process 31.1M records (2015-2019) across distributed infrastructure.
At each major stage we
    <strong>
     materialize checkpointed Parquet tables
    </strong>
    to enable iterative experimentation, fault tolerance, and reproducible audit trails:
   </p>
   <ul>
    <li>
     <strong>
      Stage 0
     </strong>
     -
     <code>
      OTPW_60M_Backup.parquet
     </code>
     <br/>
     <em>
      Raw OTPW data: 31,673,119 rows x 214 columns (~50 GB)
     </em>
    </li>
    <li>
     <strong>
      Checkpoint 1
     </strong>
     -
     <code>
      checkpoint_1_initial_joined_5Y_2015-2019.parquet
     </code>
     <br/>
     <em>
      Weather joined: 31,746,841 rows x 75 columns (~18.5 GB)
     </em>
    </li>
    <li>
     <strong>
      Checkpoint 2
     </strong>
     -
     <code>
      checkpoint_2_cleaned_imputed_2015-2019.parquet
     </code>
     <br/>
     <em>
      Cleaned/imputed: 31,128,891 rows x 59 columns (~12.3 GB)
     </em>
    </li>
    <li>
     <strong>
      Checkpoint 3
     </strong>
     -
     <code>
      checkpoint_3_basic_features_2015-2019.parquet
     </code>
     <br/>
     <em>
      Basic features: 31,128,891 rows x 95 columns (~14.8 GB)
     </em>
    </li>
    <li>
     <strong>
      Checkpoint 4
     </strong>
     -
     <code>
      checkpoint_4_advanced_features_2015-2019.parquet
     </code>
     <br/>
     <em>
      Advanced features: 31,128,891 rows x 186 columns (~22.4 GB)
     </em>
    </li>
    <li>
     <strong>
      Checkpoint 5
     </strong>
     -
     <code>
      checkpoint_5_comprehensive_2015-2019.parquet
     </code>
     <br/>
     <em>
      Optimized: 31,128,891 rows x 153 columns (~19.2 GB)
     </em>
    </li>
    <li>
     <strong>
      Checkpoint 5a
     </strong>
     -
     <code>
      checkpoint_5_comprehensive_2015_2019_refined.parquet
     </code>
     <br/>
     <em>
      <strong>
       Production dataset: 31,128,891 rows x 112 columns (~18.2 GB)
      </strong>
     </em>
     <br/>
     <em>
      <strong>
       Used for all Phase 3 modeling
      </strong>
     </em>
    </li>
   </ul>
   <p>
    <strong>
     Processing Infrastructure:
    </strong>
   </p>
   <ul>
    <li>
     Cluster: 8-node Databricks (Standard_DS3_v2: 4 cores, 14GB RAM per node)
    </li>
    <li>
     Total pipeline runtime: ~15 hours (Stage 0 → CP5a)
    </li>
    <li>
     Weather join runtime: ~6 hours on 31.7M records with haversine calculations
    </li>
    <li>
     Storage location:
     <code>
      dbfs:/student-groups/Group_4_4/
     </code>
    </li>
   </ul>
   <hr/>
   <h3 id="Train/Validation/Test-Splits">
    Train/Validation/Test Splits
    <a class="anchor-link" href="#Train/Validation/Test-Splits">
     ¶
    </a>
   </h3>
   <p>
    <strong>
     Temporal splits preserve chronological ordering
    </strong>
    to prevent data leakage:
   </p>
   <ul>
    <li>
     <strong>
      Training Set (2015-2017)
     </strong>
     : 16,804,113 rows (54.0%) - Used for model training with undersampling
    </li>
    <li>
     <strong>
      Validation Set (2018)
     </strong>
     : 7,127,586 rows (22.9%) - Used for hyperparameter tuning with natural distribution
    </li>
    <li>
     <strong>
      Blind Test Set (2019)
     </strong>
     : 7,197,192 rows (23.1%) - Used for final model evaluation with natural distribution
    </li>
   </ul>
   <p>
    <strong>
     Class Balance Strategy:
    </strong>
   </p>
   <ul>
    <li>
     Training: Apply 50:50 and 40:60 undersampling to balance on-time vs. delayed flights
    </li>
    <li>
     Validation/Test: Preserve natural 81.85% / 18.15% distribution for realistic performance metrics
    </li>
   </ul>
   <hr/>
   <h3 id="Stage-1---Delay-classification-(Binary-prediction)">
    Stage 1 - Delay classification (Binary prediction)
    <a class="anchor-link" href="#Stage-1---Delay-classification-(Binary-prediction)">
     ¶
    </a>
   </h3>
   <p>
    Stage 1 implements
    <strong>
     binary delay classification
    </strong>
    (DEP_DEL15: on-time vs. delayed ≥15 minutes) using multiple model families, evaluated on
    <strong>
     time-ordered validation and test splits
    </strong>
    using:
   </p>
   <p>
    <strong>
     Models Trained:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Baseline Logistic Regression
     </strong>
     (non-engineered features): AUC-PR = 0.515
    </li>
    <li>
     <strong>
      Logistic Regression + features
     </strong>
     (112 engineered features): F₂ = 0.595, Recall = 64.5%
    </li>
    <li>
     <strong>
      Random Forest (Phase 3)
     </strong>
     : F₂ = 0.610, Recall = 60.1%, depth=15, 20 trees
    </li>
    <li>
     <strong>
      Gradient Boosted Trees
     </strong>
     : F₂ = 0.625, Recall = 62.1%, tuned configuration
    </li>
    <li>
     <strong>
      MLP 50:50
     </strong>
     (50:50 undersampling): F₂ = 0.658, Recall = 82.1%
    </li>
    <li>
     <strong>
      MLP 40:60
     </strong>
     (40:60 undersampling,
     <strong>
      BEST
     </strong>
     ): F₂ = 0.662, Recall = 82.9%
    </li>
    <li>
     <strong>
      3-model MLP Ensemble
     </strong>
     : F₂ = 0.648, Recall = 77.2%
    </li>
    <li>
     <strong>
      1D CNN (PyTorch) — Model A (tiny subset, architecture validation)
     </strong>
     : AUC-PR = 0.6525, Best F₂ = 0.663 @ threshold=0.31 (test on 0.5% subset)
    </li>
    <li>
     <strong>
      1D CNN (PyTorch) — Model B (full test, undersampled training, production-scale)
     </strong>
     : AUC-PR = 0.6639, Best F₂ = 0.680 @ threshold=0.17 (full 2019 test set)
    </li>
   </ul>
   <p>
    <strong>
     Evaluation Metrics (Primary: F₂-score):
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      F₂-score
     </strong>
     : Weights recall 2x higher than precision (optimized for catching risky flights)
    </li>
    <li>
     <strong>
      Precision
     </strong>
     : Fraction of predicted delays that are actual delays
    </li>
    <li>
     <strong>
      Recall
     </strong>
     : Fraction of actual delays that are caught by the model
    </li>
    <li>
     <strong>
      AUC-PR
     </strong>
     : Area under precision-recall curve (class-imbalance aware)
    </li>
   </ul>
   <p>
    <strong>
     Operational Strategy:
    </strong>
   </p>
   <ul>
    <li>
     Flights predicted as
     <strong>
      delayed
     </strong>
     → Flagged for operational intervention (crew scheduling, gate management, passenger notifications)
    </li>
    <li>
     Flights predicted as
     <strong>
      on-time
     </strong>
     → Standard processing
    </li>
   </ul>
   <hr/>
   <h3 id="Stage-2---Delay-minutes-regression-(Duration-prediction)">
    Stage 2 - Delay-minutes regression (Duration prediction)
    <a class="anchor-link" href="#Stage-2---Delay-minutes-regression-(Duration-prediction)">
     ¶
    </a>
   </h3>
   <p>
    Stage 2 implements
    <strong>
     two-tier regression
    </strong>
    to predict delay duration in minutes for flights flagged as delayed:
   </p>
   <p>
    <strong>
     Two-Tier Approach:
    </strong>
   </p>
   <ol>
    <li>
     <strong>
      Tier 1
     </strong>
     : Predict whether flight will be delayed (binary classification from Stage 1)
    </li>
    <li>
     <strong>
      Tier 2
     </strong>
     : For flights predicted as delayed, predict delay duration using regression
    </li>
   </ol>
   <p>
    <strong>
     Regression Model:
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      Linear Regression
     </strong>
     trained on flights with DEP_DELAY &gt; 0 (actual delayed flights)
    </li>
    <li>
     Features: Same 112 engineered features from CP5a
    </li>
   </ul>
   <p>
    <strong>
     Evaluation Metrics (on 2019 blind test set):
    </strong>
   </p>
   <ul>
    <li>
     <strong>
      RMSE
     </strong>
     : 42.83 minutes (root mean squared error)
    </li>
   </ul>
   <p>
    <strong>
     Operational Value:
    </strong>
   </p>
   <ul>
    <li>
     Provides
     <strong>
      minute-level estimates
     </strong>
     for delay duration
    </li>
    <li>
     Enables
     <strong>
      resource allocation
     </strong>
     : crew reassignments, gate reallocations, passenger rebooking
    </li>
    <li>
     Supports
     <strong>
      cascade delay planning
     </strong>
     : downstream flight impacts, connection risk assessment
    </li>
   </ul>
   <hr/>
   <h3 id="Final-evaluation-&amp;-model-management">
    Final evaluation &amp; model management
    <a class="anchor-link" href="#Final-evaluation-&amp;-model-management">
     ¶
    </a>
   </h3>
   <p>
    A
    <strong>
     final evaluation layer
    </strong>
    aggregates outputs from both stages, reporting:
   </p>
   <p>
    <strong>
     Stage 1 Classification Metrics (all 7.2M flights in 2019 test set):
    </strong>
   </p>
   <ul>
    <li>
     F₂-score, Precision, Recall, AUC-PR
    </li>
    <li>
     Confusion matrix (True Positives, False Positives, True Negatives, False Negatives)
    </li>
    <li>
     ROC curves and Precision-Recall curves
    </li>
   </ul>
   <p>
    <strong>
     Stage 2 Regression Metrics (subset predicted as delayed by Stage 1):
    </strong>
   </p>
   <ul>
    <li>
     RMSE, MAE on predicted-delayed flights only
    </li>
    <li>
     Residual analysis and error distribution
    </li>
    <li>
     Stratified performance by delay severity bins
    </li>
   </ul>
   <p>
    <strong>
     Model Versioning and Storage:
    </strong>
   </p>
   <ul>
    <li>
     All intermediate checkpoints saved in Databricks:
     <code>
      dbfs:/student-groups/Group_4_4/
     </code>
    </li>
    <li>
     Final models exported as MLflow artifacts with metadata (hyperparameters, training time, metrics)
    </li>
    <li>
     Feature importance rankings saved for interpretability:
     <code>
      feature_importance_analysis.csv
     </code>
    </li>
    <li>
     Reproducibility guaranteed via checkpoint lineage and version control
    </li>
   </ul>
   <p>
    <strong>
     Production Deployment Readiness:
    </strong>
   </p>
   <ul>
    <li>
     Models trained on 24.9M records (2015-2017) with T-2h feature constraints
    </li>
    <li>
     Validated on 7.1M records (2018) for hyperparameter tuning
    </li>
    <li>
     Blind tested on 7.2M records (2019) for production performance simulation
    </li>
    <li>
     Real-time prediction feasible: all features available at T-2h before scheduled departure
    </li>
    <li>
     Explainability: Feature importance rankings from Random Forest inform operational decisions
    </li>
   </ul>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
<div class="output_wrapper">
  <div class="output">
   <div class="output_area">
    <div class="prompt">
    </div>
    <div class="output_png output_subarea">
     <img alt="No description has been provided for this image" src="images/image_033_63bd8ce0.png"/>
    </div>
   
  </div>
 </div>
  
  </div>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="9.-Conclusion">
    9. Conclusion
    <a class="anchor-link" href="#9.-Conclusion">
     ¶
    </a>
   </h2>
   <p>
    This project successfully developed a production-ready flight delay prediction system processing 31.1 million flights (2015-2019) with 112 optimized features and rigorous temporal validation. We scaled our pipeline 6x from Phase 2's 5.7M records to 31.1M records, achieving 98.3% data retention while reducing missing data from 49.39% to less than one percent. Our custom T-2 hour weather join integrated 634 NOAA stations with 369 airports, enforcing strict temporal ordering to eliminate data leakage. We engineered 153 features across 8 families, then optimized to 112 production-ready features through correlation analysis and importance filtering. Top predictors include 24-hour weighted rolling average delay by origin airport (14.2% importance), Random Forest probability meta-feature (11.8%), and previous flight delay status (9.5%), validating that delays are complex phenomena requiring temporal, operational, environmental, and network perspectives.
   </p>
   <p>
    We implemented four modeling approaches using F₂-score as the primary metric to prioritize recall over precision. Models were trained on 2015-2017 data (16.8M flights), validated on 2018 (7.1M flights), and tested on 2019 as blind holdout (7.3M flights). The MLP with 40:60 undersampling achieved best performance with F₂ of 0.73, precision of 66.20%, and recall of 82.87% (AUC-PR: 0.599), training in just 105 seconds on 8 worker nodes. MLP 50:50 undersampling achieved F₂ of 0.658 with 82.08% recall (AUC-PR: 0.602). The 3-model MLP ensemble achieved F₂ of 0.648 with 77.21% recall (AUC-PR: 0.583). Tree-based models showed competitive performance: Gradient-Boosted Trees achieved F₂ of 0.625 with 62.06% recall (AUC-PR: 0.719, highest among all models), and Random Forest Phase 3 achieved F₂ of 0.610 with 60.13% recall (AUC-PR: 0.664). Logistic Regression with engineered features achieved F₂ of 0.595 with 64.50% recall (AUC-PR: 0.566), substantially outperforming the baseline LR (F₂: 0.515) and demonstrating the value of feature engineering. Our two-tier regression model predicts delay duration for flights classified as delayed. Our final dataset passed all quality validations: 99.99% completeness, zero leakage, indexed categoricals, and balanced sampling strategies.
   </p>
   <p>
    Aircraft delay propagation and airport congestion dominate prediction, confirming delays cascade through the system. Delays accumulate from 6-7% in early morning to 26% by 11PM, validating temporal accumulation patterns. Geographic analysis reveals Northeast corridor airports (EWR, LGA, JFK) consistently underperform (20-24%) while Western hubs (HNL, SLC) maintain efficiency (13-15%). Carrier performance spans 17.4 percentage points from Hawaiian Airlines (7.61%) to JetBlue (25.01%), proving operational practices matter more than volume. Weather shows weak individual correlations (-0.04 to +0.05) but strong composite features, with extreme conditions (temperature less than 25°F, wind gusts &gt;30 units) driving disproportionate delays.
   </p>
   <p>
    For deployment, we recommend real-time feature computation infrastructure for the T-2 hour window, MLflow-based model versioning with carrier-specific threshold calibration, and data drift monitoring to detect performance degradation. The MLP 40:60 model offers the best balance of recall (82.87% of delays caught) and precision (66.20% accuracy when predicting delay), making it suitable for operational deployment where catching delays is prioritized. Extended validation on 2020-2021 data will assess robustness to COVID-19 disruptions. This system demonstrates that flight delays can be predicted with actionable accuracy 2 hours before departure, enabling airlines to transform reactive delay management into predictive operational planning through proactive crew scheduling, gate assignments, and passenger notifications.
   </p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="10.-Open-Issues-or-Problems:">
    10. Open Issues or Problems:
    <a class="anchor-link" href="#10.-Open-Issues-or-Problems:">
     ¶
    </a>
   </h2>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h4 id="Remaining-Problems-and-Future-Work:">
    Remaining Problems and Future Work:
    <a class="anchor-link" href="#Remaining-Problems-and-Future-Work:">
     ¶
    </a>
   </h4>
   <p>
    <strong>
     1. Model Deployment Infrastructure
    </strong>
   </p>
   <p>
    The current system is research-focused with models trained on historical data. Deployment requires building production infrastructure for real-time predictions at T-2 hours before scheduled departure. This includes developing feature computation pipelines that calculate rolling statistics, network metrics, and RFM features within operational timeframes (seconds, not hours). Real-time weather integration from NOAA APIs must replace batch processing. Model serving infrastructure via MLflow or similar platforms is needed for A/B testing and gradual rollout.
   </p>
   <p>
    <strong>
     2. Data Drift and Model Degradation Monitoring
    </strong>
   </p>
   <p>
    While our temporal validation (2019 holdout) demonstrates generalization to unseen years, we lack continuous monitoring of feature distributions and model performance in production. Airline operations evolve through schedule changes, new routes, carrier mergers, airport renovations, and external shocks (weather events, pandemics, economic shifts). Automated monitoring must track feature drift (distribution changes in rolling averages, carrier performance, airport congestion) and prediction drift (calibration degradation, recall decay) to trigger retraining when performance degrades beyond acceptable thresholds.
   </p>
   <p>
    <strong>
     3. COVID-19 Impact Validation
    </strong>
   </p>
   <p>
    Our model is trained on 2015-2019 data representing normal airline operations. The 2020-2021 period saw unprecedented disruptions: dramatically reduced flight schedules, altered route networks, different passenger loads, changed operational procedures, and behavioral shifts. Validating model performance on 2020-2021 data is critical to understanding robustness to extreme operational changes. This validation will reveal whether features like rolling averages, carrier performance metrics, and network centrality adapt to crisis conditions or whether fundamental retraining is required.
   </p>
   <p>
    <strong>
     4. Carrier-Specific Threshold Calibration
    </strong>
   </p>
   <p>
    The current F₂-optimized threshold (prioritizing recall) applies uniformly across all carriers. Different airlines have different operational priorities and cost structures. Budget carriers operating on thin margins may tolerate higher false positive rates (unnecessary delay preparations) to avoid missing actual delays that cascade into expensive disruptions. Premium carriers focused on schedule reliability may prefer precision to minimize unnecessary gate changes and crew reassignments. Developing carrier-specific decision thresholds through collaboration with operations teams will maximize business value.
   </p>
   <p>
    <strong>
     5. Confidence Intervals and Uncertainty Quantification
    </strong>
   </p>
   <p>
    Current predictions provide point estimates (delayed/on-time, expected delay minutes) without uncertainty quantification. Operations teams would benefit from confidence intervals indicating prediction reliability. High-confidence predictions (morning flights with stable patterns, reliable carriers, clear weather) warrant different operational responses than low-confidence predictions (evening flights with accumulated delays, congested airports, marginal weather). Implementing prediction intervals via ensemble methods, quantile regression, or conformal prediction would enable risk-aware decision-making.
   </p>
   <p>
    <strong>
     6. Enhanced Feature Engineering
    </strong>
   </p>
   <p>
    While our 112 features capture substantial predictive power, several promising directions remain unexplored. Real-time airport congestion metrics from FAA System Operations (not just historical patterns) could improve predictions during developing weather events. Slot coordination data at high-density airports (JFK, LGA, EWR) could capture schedule congestion effects. Passenger load factors and aircraft utilization rates (available from carriers) may explain variance in delay tolerance. Social media sentiment and flight review data could proxy carrier operational stress.
   </p>
   <p>
    <strong>
     7. Multi-Task and Hierarchical Models
    </strong>
   </p>
   <p>
    Current classification (delayed/on-time) and regression (delay minutes) models are trained independently. Multi-task learning could share representations between these related tasks, potentially improving both. Hierarchical models predicting delay categories (0-15min, 15-30min, 30-60min, 60+min) might better align with operational decision points than binary classification. Investigating whether certain feature sets specialize in extreme delays versus marginal delays could guide operational interventions.
   </p>
   <p>
    <strong>
     8. Route-Specific and Time-of-Day Models
    </strong>
   </p>
   <p>
    Current models are global across all routes and times. Route-specific models for high-traffic corridors (LAX-SFO, BOS-DCA, ORD-LGA) trained on dense data might outperform global models by capturing localized operational patterns. Similarly, time-of-day-specific models (morning departure model, evening departure model) could better capture the distinct dynamics of delay accumulation versus fresh starts. Evaluating whether increased specificity improves predictions or leads to overfitting on sparse segments is necessary.
   </p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="Appendix">
    Appendix
    <a class="anchor-link" href="#Appendix">
     ¶
    </a>
   </h2>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <hr/>
   <h2 id="Appendix-A:-Complete-Feature-Inventory-(2015-2019)">
    Appendix A: Complete Feature Inventory (2015-2019)
    <a class="anchor-link" href="#Appendix-A:-Complete-Feature-Inventory-(2015-2019)">
     ¶
    </a>
   </h2>
   <p>
    This appendix provides a comprehensive listing of all 112 features in the final production-ready dataset (Checkpoint 5a), organized by category.
   </p>
   <h2 id="A.1-Target-Variables-(2)">
    A.1 Target Variables (2)
    <a class="anchor-link" href="#A.1-Target-Variables-(2)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       DEP_DEL15
      </td>
      <td>
       Binary
      </td>
      <td>
       Flight departure delay indicator (1=delayed ≥15min, 0=on-time)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       DEP_DELAY
      </td>
      <td>
       Numeric
      </td>
      <td>
       Actual departure delay in minutes (reference only, not used for training)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.2-Core-Identifiers-and-Temporal-References-(11)">
    A.2 Core Identifiers and Temporal References (11)
    <a class="anchor-link" href="#A.2-Core-Identifiers-and-Temporal-References-(11)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       DEST
      </td>
      <td>
       String
      </td>
      <td>
       Destination airport IATA code
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       ORIGIN
      </td>
      <td>
       String
      </td>
      <td>
       Origin airport IATA code
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       OP_UNIQUE_CARRIER
      </td>
      <td>
       String
      </td>
      <td>
       Operating carrier code
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       FL_DATE
      </td>
      <td>
       Date
      </td>
      <td>
       Flight date
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       prediction_utc
      </td>
      <td>
       Timestamp
      </td>
      <td>
       Prediction timestamp (T-2h before scheduled departure)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_obs_utc
      </td>
      <td>
       Timestamp
      </td>
      <td>
       Origin weather observation timestamp
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       asof_minutes
      </td>
      <td>
       Numeric
      </td>
      <td>
       Minutes between weather observation and prediction time
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       DAY_OF_MONTH
      </td>
      <td>
       Integer
      </td>
      <td>
       Day of month (1-31)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       DAY_OF_WEEK
      </td>
      <td>
       Integer
      </td>
      <td>
       Day of week (1=Monday, 7=Sunday)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       OP_CARRIER_FL_NUM
      </td>
      <td>
       Integer
      </td>
      <td>
       Flight number
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       CRS_ARR_TIME
      </td>
      <td>
       Integer
      </td>
      <td>
       Scheduled arrival time (HHMM format)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.3-Airport-Geographic-Identifiers-(10)">
    A.3 Airport Geographic Identifiers (10)
    <a class="anchor-link" href="#A.3-Airport-Geographic-Identifiers-(10)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       ORIGIN_AIRPORT_ID
      </td>
      <td>
       Integer
      </td>
      <td>
       Origin airport unique ID
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       DEST_AIRPORT_ID
      </td>
      <td>
       Integer
      </td>
      <td>
       Destination airport unique ID
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       ORIGIN_STATE_ABR
      </td>
      <td>
       String
      </td>
      <td>
       Origin state abbreviation
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       DEST_STATE_ABR
      </td>
      <td>
       String
      </td>
      <td>
       Destination state abbreviation
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_airport_lat
      </td>
      <td>
       Numeric
      </td>
      <td>
       Origin airport latitude
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_airport_lon
      </td>
      <td>
       Numeric
      </td>
      <td>
       Origin airport longitude
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dest_airport_lat
      </td>
      <td>
       Numeric
      </td>
      <td>
       Destination airport latitude
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dest_airport_lon
      </td>
      <td>
       Numeric
      </td>
      <td>
       Destination airport longitude
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_station_dis
      </td>
      <td>
       Numeric
      </td>
      <td>
       Distance from origin airport to weather station (km)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dest_station_dis
      </td>
      <td>
       Numeric
      </td>
      <td>
       Distance from destination airport to weather station (km)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.4-Airport-Type-and-Seasonal-(2)">
    A.4 Airport Type and Seasonal (2)
    <a class="anchor-link" href="#A.4-Airport-Type-and-Seasonal-(2)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       origin_type
      </td>
      <td>
       String
      </td>
      <td>
       Origin airport type (hub/spoke/regional)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       season
      </td>
      <td>
       String
      </td>
      <td>
       Season (spring/summer/fall/winter)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.5-Raw-Weather-Measurements-(8)">
    A.5 Raw Weather Measurements (8)
    <a class="anchor-link" href="#A.5-Raw-Weather-Measurements-(8)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       HourlyDryBulbTemperature
      </td>
      <td>
       Numeric
      </td>
      <td>
       Ambient temperature (°F)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       HourlyDewPointTemperature
      </td>
      <td>
       Numeric
      </td>
      <td>
       Dew point temperature (°F)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       HourlyWindDirection
      </td>
      <td>
       Numeric
      </td>
      <td>
       Wind direction (degrees)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       HourlyWindGustSpeed
      </td>
      <td>
       Numeric
      </td>
      <td>
       Wind gust speed (mph)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       HourlyVisibility
      </td>
      <td>
       Numeric
      </td>
      <td>
       Visibility distance (miles)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       HourlyRelativeHumidity
      </td>
      <td>
       Numeric
      </td>
      <td>
       Relative humidity (%)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       HourlyStationPressure
      </td>
      <td>
       Numeric
      </td>
      <td>
       Station pressure (inHg)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       HourlyAltimeterSetting
      </td>
      <td>
       Numeric
      </td>
      <td>
       Altimeter setting (inHg)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.6-Engineered-Weather-Features-(3)">
    A.6 Engineered Weather Features (3)
    <a class="anchor-link" href="#A.6-Engineered-Weather-Features-(3)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       weather_condition_category
      </td>
      <td>
       String
      </td>
      <td>
       Weather severity category (clear/moderate/severe)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       sky_condition_parsed
      </td>
      <td>
       String
      </td>
      <td>
       Parsed sky condition (clear/cloudy/overcast/etc.)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       temp_anomaly
      </td>
      <td>
       Numeric
      </td>
      <td>
       Deviation from monthly average temperature
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.7-Distance-Features-(2)">
    A.7 Distance Features (2)
    <a class="anchor-link" href="#A.7-Distance-Features-(2)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       log_distance
      </td>
      <td>
       Numeric
      </td>
      <td>
       Log-transformed flight distance
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       distance_very_long
      </td>
      <td>
       Binary
      </td>
      <td>
       Very long distance flight (&gt;2000 miles)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.8-Rolling-Aggregates-(8)">
    A.8 Rolling Aggregates (8)
    <a class="anchor-link" href="#A.8-Rolling-Aggregates-(8)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       rolling_origin_num_delays_24h
      </td>
      <td>
       Numeric
      </td>
      <td>
       Number of delays at origin in past 24 hours
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dep_delay15_24h_rolling_avg_by_origin_dayofweek
      </td>
      <td>
       Numeric
      </td>
      <td>
       Rolling 24h delay rate by origin and day of week
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dep_delay15_24h_rolling_avg_by_origin_log
      </td>
      <td>
       Numeric
      </td>
      <td>
       Log-transformed rolling 24h delay rate by origin
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dep_delay15_24h_rolling_avg_by_origin_carrier_log
      </td>
      <td>
       Numeric
      </td>
      <td>
       Log-transformed rolling 24h delay rate by origin-carrier
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dep_delay15_24h_rolling_avg_by_origin_dayofweek_log
      </td>
      <td>
       Numeric
      </td>
      <td>
       Log-transformed rolling 24h delay rate by origin-dayofweek
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dep_delay15_24h_rolling_avg_by_origin_weighted
      </td>
      <td>
       Numeric
      </td>
      <td>
       Importance-weighted rolling 24h delay rate by origin
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dep_delay15_24h_rolling_avg_by_origin_carrier_weighted
      </td>
      <td>
       Numeric
      </td>
      <td>
       Importance-weighted rolling 24h delay rate by origin-carrier
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       rolling_30day_volume
      </td>
      <td>
       Numeric
      </td>
      <td>
       30-day flight volume at origin
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.9-Event-Indicators-(4)">
    A.9 Event Indicators (4)
    <a class="anchor-link" href="#A.9-Event-Indicators-(4)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       is_superbowl_week
      </td>
      <td>
       Binary
      </td>
      <td>
       Super Bowl week indicator
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       is_major_event
      </td>
      <td>
       Binary
      </td>
      <td>
       Major event indicator (holidays, sports)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       is_airport_maintenance
      </td>
      <td>
       Binary
      </td>
      <td>
       Airport maintenance period indicator
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       is_natural_disaster
      </td>
      <td>
       Binary
      </td>
      <td>
       Natural disaster indicator (hurricanes, etc.)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.10-Airline-Reputation-(2)">
    A.10 Airline Reputation (2)
    <a class="anchor-link" href="#A.10-Airline-Reputation-(2)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       airline_reputation_score
      </td>
      <td>
       Numeric
      </td>
      <td>
       Carrier reputation score (0-100)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       airline_reputation_category
      </td>
      <td>
       String
      </td>
      <td>
       Carrier reputation category (low/medium/high)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.11-Congestion-Features-(6)">
    A.11 Congestion Features (6)
    <a class="anchor-link" href="#A.11-Congestion-Features-(6)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       airport_traffic_density
      </td>
      <td>
       Numeric
      </td>
      <td>
       Percentage of daily flights in this hour
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       carrier_flight_count
      </td>
      <td>
       Numeric
      </td>
      <td>
       Total flights by carrier
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       num_airport_wide_delays
      </td>
      <td>
       Numeric
      </td>
      <td>
       Delays at airport in 2-hour window
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       oncoming_flights
      </td>
      <td>
       Numeric
      </td>
      <td>
       Arrivals at origin in 2-hour window
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       prior_flights_today
      </td>
      <td>
       Numeric
      </td>
      <td>
       Flights at origin so far today
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       time_based_congestion_ratio
      </td>
      <td>
       Numeric
      </td>
      <td>
       Current vs historical traffic ratio
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.12-Aircraft-Lag-Features-(4)">
    A.12 Aircraft Lag Features (4)
    <a class="anchor-link" href="#A.12-Aircraft-Lag-Features-(4)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       prev_flight_dep_del15
      </td>
      <td>
       Numeric
      </td>
      <td>
       Previous flight delay status (same aircraft)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       prev_flight_crs_elapsed_time
      </td>
      <td>
       Numeric
      </td>
      <td>
       Previous flight scheduled duration
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       hours_since_prev_flight
      </td>
      <td>
       Numeric
      </td>
      <td>
       Aircraft turnaround time in hours
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       turnaround_category
      </td>
      <td>
       String
      </td>
      <td>
       Turnaround time category (quick/normal/long/overnight)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.13-Same-Day-Temporal-Features-(4)">
    A.13 Same-Day Temporal Features (4)
    <a class="anchor-link" href="#A.13-Same-Day-Temporal-Features-(4)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       day_hour_interaction
      </td>
      <td>
       String
      </td>
      <td>
       Day of week × hour interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       prior_day_delay_rate
      </td>
      <td>
       Numeric
      </td>
      <td>
       Previous day's delay rate at origin
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       same_day_prior_delay_percentage
      </td>
      <td>
       Numeric
      </td>
      <td>
       Percentage of flights delayed so far today
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dest_delay_rate_today
      </td>
      <td>
       Numeric
      </td>
      <td>
       Destination airport delay rate today
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.14-Cyclic-Encodings-(7)">
    A.14 Cyclic Encodings (7)
    <a class="anchor-link" href="#A.14-Cyclic-Encodings-(7)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       dep_time_sin
      </td>
      <td>
       Numeric
      </td>
      <td>
       Sine encoding of departure time (preserves 24h periodicity)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dep_time_cos
      </td>
      <td>
       Numeric
      </td>
      <td>
       Cosine encoding of departure time
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       arr_time_sin
      </td>
      <td>
       Numeric
      </td>
      <td>
       Sine encoding of arrival time
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       arr_time_cos
      </td>
      <td>
       Numeric
      </td>
      <td>
       Cosine encoding of arrival time (missing cos pair for arr)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       day_of_week_sin
      </td>
      <td>
       Numeric
      </td>
      <td>
       Sine encoding of day of week
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       day_of_week_cos
      </td>
      <td>
       Numeric
      </td>
      <td>
       Cosine encoding of day of week
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       month_sin
      </td>
      <td>
       Numeric
      </td>
      <td>
       Sine encoding of month
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.15-Network-Graph-Features-(5)">
    A.15 Network Graph Features (5)
    <a class="anchor-link" href="#A.15-Network-Graph-Features-(5)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       origin_degree_centrality
      </td>
      <td>
       Numeric
      </td>
      <td>
       Origin airport network connectivity (0-1)
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dest_betweenness
      </td>
      <td>
       Numeric
      </td>
      <td>
       Destination airport betweenness centrality
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       delay_propagation_score
      </td>
      <td>
       Numeric
      </td>
      <td>
       Network delay cascade risk score
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       network_delay_cascade
      </td>
      <td>
       Numeric
      </td>
      <td>
       Network-wide delay propagation metric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       days_since_epoch
      </td>
      <td>
       Numeric
      </td>
      <td>
       Days since reference date (temporal trend)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.16-Historical-Delay-Rates-(2)">
    A.16 Historical Delay Rates (2)
    <a class="anchor-link" href="#A.16-Historical-Delay-Rates-(2)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       origin_1yr_delay_rate
      </td>
      <td>
       Numeric
      </td>
      <td>
       1-year historical delay rate at origin
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       dest_1yr_delay_rate
      </td>
      <td>
       Numeric
      </td>
      <td>
       1-year historical delay rate at destination
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.17-RFM-(Recency-Frequency-Monetary)-Features-(5)">
    A.17 RFM (Recency-Frequency-Monetary) Features (5)
    <a class="anchor-link" href="#A.17-RFM-(Recency-Frequency-Monetary)-Features-(5)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       days_since_last_delay_route
      </td>
      <td>
       Numeric
      </td>
      <td>
       Days since route last had delay
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       days_since_carrier_last_delay_at_origin
      </td>
      <td>
       Numeric
      </td>
      <td>
       Days since carrier had delay at origin
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       route_delays_30d
      </td>
      <td>
       Numeric
      </td>
      <td>
       Number of delays on route in past 30 days
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       route_delay_rate_30d
      </td>
      <td>
       Numeric
      </td>
      <td>
       30-day delay rate for route
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       carrier_delays_at_origin_30d
      </td>
      <td>
       Numeric
      </td>
      <td>
       Number of carrier delays at origin in past 30 days
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.18-Interaction-Terms-(13)">
    A.18 Interaction Terms (13)
    <a class="anchor-link" href="#A.18-Interaction-Terms-(13)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       peak_hour_x_traffic
      </td>
      <td>
       Numeric
      </td>
      <td>
       Peak hour × traffic density interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       weekend_x_route_volume
      </td>
      <td>
       Numeric
      </td>
      <td>
       Weekend × route volume interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       weather_x_airport_delays
      </td>
      <td>
       Numeric
      </td>
      <td>
       Weather severity × airport delays interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       temp_x_holiday
      </td>
      <td>
       Numeric
      </td>
      <td>
       Temperature × holiday indicator interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       route_delay_rate_x_peak_hour
      </td>
      <td>
       Numeric
      </td>
      <td>
       Route delay rate × peak hour interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       carrier_encoded_x_hour
      </td>
      <td>
       Numeric
      </td>
      <td>
       Carrier × hour interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_encoded_x_weather
      </td>
      <td>
       Numeric
      </td>
      <td>
       Origin × weather condition interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_encoded_x_visibility
      </td>
      <td>
       Numeric
      </td>
      <td>
       Origin × visibility interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_encoded_x_precipitation
      </td>
      <td>
       Numeric
      </td>
      <td>
       Origin × precipitation interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_encoded_x_wind
      </td>
      <td>
       Numeric
      </td>
      <td>
       Origin × wind speed interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_x_dest_encoded
      </td>
      <td>
       Numeric
      </td>
      <td>
       Origin × destination route interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       carrier_x_origin_encoded
      </td>
      <td>
       Numeric
      </td>
      <td>
       Carrier × origin interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       carrier_x_dest_encoded
      </td>
      <td>
       Numeric
      </td>
      <td>
       Carrier × destination interaction
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.19-Breiman-Meta-Features-(2)">
    A.19 Breiman Meta-Features (2)
    <a class="anchor-link" href="#A.19-Breiman-Meta-Features-(2)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Type
      </th>
      <th>
       Description
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       rf_prob_delay
      </td>
      <td>
       Numeric
      </td>
      <td>
       Random Forest predicted probability of delay
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       rf_prob_delay_binned
      </td>
      <td>
       Numeric
      </td>
      <td>
       Binned RF delay probability (5 bins)
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <h2 id="A.20-Indexed-Categorical-Features-(12)">
    A.20 Indexed Categorical Features (12)
    <a class="anchor-link" href="#A.20-Indexed-Categorical-Features-(12)">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Feature
      </th>
      <th>
       Original String
      </th>
      <th>
       Cardinality
      </th>
      <th>
       Type
      </th>
      <th>
       Status
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       DEST_indexed
      </td>
      <td>
       DEST
      </td>
      <td>
       368
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       ORIGIN_indexed
      </td>
      <td>
       ORIGIN
      </td>
      <td>
       369
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       OP_UNIQUE_CARRIER_indexed
      </td>
      <td>
       OP_UNIQUE_CARRIER
      </td>
      <td>
       19
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       ORIGIN_STATE_ABR_indexed
      </td>
      <td>
       ORIGIN_STATE_ABR
      </td>
      <td>
       53
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       DEST_STATE_ABR_indexed
      </td>
      <td>
       DEST_STATE_ABR
      </td>
      <td>
       53
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       origin_type_indexed
      </td>
      <td>
       origin_type
      </td>
      <td>
       3
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       season_indexed
      </td>
      <td>
       season
      </td>
      <td>
       4
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       weather_condition_category_indexed
      </td>
      <td>
       weather_condition_category
      </td>
      <td>
       3
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       airline_reputation_category_indexed
      </td>
      <td>
       airline_reputation_category
      </td>
      <td>
       3
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       turnaround_category_indexed
      </td>
      <td>
       turnaround_category
      </td>
      <td>
       4
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       day_hour_interaction_indexed
      </td>
      <td>
       day_hour_interaction
      </td>
      <td>
       168
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
     <tr>
      <td>
       sky_condition_parsed_indexed
      </td>
      <td>
       sky_condition_parsed
      </td>
      <td>
       6
      </td>
      <td>
       Numeric
      </td>
      <td>
       FINAL
      </td>
     </tr>
    </tbody>
   </table>
   <hr/>
   <h2 id="A.21-Feature-Summary-Statistics">
    A.21 Feature Summary Statistics
    <a class="anchor-link" href="#A.21-Feature-Summary-Statistics">
     ¶
    </a>
   </h2>
   <p>
    <strong>
     Total Features:
    </strong>
    112
   </p>
   <p>
    <strong>
     Breakdown by Category:
    </strong>
   </p>
   <ul>
    <li>
     Target Variables: 2
    </li>
    <li>
     Core Identifiers: 11
    </li>
    <li>
     Geographic: 12
    </li>
    <li>
     Weather (raw + engineered): 11
    </li>
    <li>
     Distance: 2
    </li>
    <li>
     Rolling Aggregates: 8
    </li>
    <li>
     Event Indicators: 4
    </li>
    <li>
     Airline Reputation: 2
    </li>
    <li>
     Congestion: 6
    </li>
    <li>
     Aircraft Lag: 4
    </li>
    <li>
     Same-Day Temporal: 4
    </li>
    <li>
     Cyclic Encodings: 7
    </li>
    <li>
     Network Graph: 5
    </li>
    <li>
     Historical Rates: 2
    </li>
    <li>
     RFM Features: 5
    </li>
    <li>
     Interaction Terms: 13
    </li>
    <li>
     Breiman Meta-Features: 2
    </li>
    <li>
     Indexed Categoricals: 12
    </li>
   </ul>
   <p>
    <strong>
     Feature Engineering Summary:
    </strong>
   </p>
   <ul>
    <li>
     Original OTPW features retained: 29
    </li>
    <li>
     Weather features from join: 8
    </li>
    <li>
     Engineered features: 75
    </li>
    <li>
     Total: 112
    </li>
   </ul>
   <p>
    <strong>
     Data Types:
    </strong>
   </p>
   <ul>
    <li>
     Numeric (continuous): 82
    </li>
    <li>
     Numeric (indexed categorical): 12
    </li>
    <li>
     String (original): 10
    </li>
    <li>
     Binary: 5
    </li>
    <li>
     Date/Timestamp: 3
    </li>
   </ul>
   <hr/>
   <h2 id="A.22-Removed-Features-Summary">
    A.22 Removed Features Summary
    <a class="anchor-link" href="#A.22-Removed-Features-Summary">
     ¶
    </a>
   </h2>
   <table>
    <thead>
     <tr>
      <th>
       Stage
      </th>
      <th>
       Features Removed
      </th>
      <th>
       Count
      </th>
      <th>
       Reason
      </th>
     </tr>
    </thead>
    <tbody>
     <tr>
      <td>
       <strong>
        Stage 0 → CP1
       </strong>
      </td>
      <td>
       N/A (join operation)
      </td>
      <td>
       -139
      </td>
      <td>
       OTPW columns consolidated/removed during weather join
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP1 → CP2
       </strong>
      </td>
      <td>
       DEP_TIME, ARR_TIME, WHEELS_OFF, WHEELS_ON, TAXI_OUT, TAXI_IN, ACTUAL_ELAPSED_TIME, AIR_TIME, CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY, ARR_DEL15, ARR_DELAY
      </td>
      <td>
       15
      </td>
      <td>
       Data leakage (future information)
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP4 → CP5
       </strong>
      </td>
      <td>
       High correlation features, duplicate features, low-importance features
      </td>
      <td>
       33
      </td>
      <td>
       Pearson &gt;0.85, redundancy, zero contribution
      </td>
     </tr>
     <tr>
      <td>
       <strong>
        CP5 → CP5a
       </strong>
      </td>
      <td>
       Original string columns after indexing, additional low-importance features
      </td>
      <td>
       41
      </td>
      <td>
       String categoricals replaced by indexed versions, importance filtering
      </td>
     </tr>
    </tbody>
   </table>
   <p>
    <strong>
     Total Features Removed from Stage 0:
    </strong>
    214 → 112 = 102 features removed
   </p>
   <hr/>
  </div>
 </div>
</div>
<div class="cell border-box-sizing text_cell rendered">
 <div class="prompt input_prompt">
 </div>
 <div class="inner_cell">
  <div class="text_cell_render border-box-sizing rendered_html">
   <h2 id="References">
    References
    <a class="anchor-link" href="#References">
     ¶
    </a>
   </h2>
   <ul>
    <li>
     <p>
      Chaudhuri, T.,
      <em>
       et al.
      </em>
      (2024).
      <strong>
       Attention-based deep learning model for flight delay prediction.
      </strong>
      <em>
       SESAR Innovation Days.
      </em>
     </p>
    </li>
    <li>
     <p>
      Dai, M.,
      <em>
       et al.
      </em>
      (2024).
      <strong>
       A hybrid machine learning–based model for predicting flight delay.
      </strong>
      <em>
       Scientific Reports, 14
      </em>
      (1).
     </p>
    </li>
    <li>
     <p>
      Kan, H. Y.,
      <em>
       et al.
      </em>
      (2025).
      <strong>
       Scalable flight cancellation prediction with ensemble learning.
      </strong>
      <em>
       Scientific Reports, 15.
      </em>
     </p>
    </li>
    <li>
     <p>
      Tang, Y. (2021).
      <strong>
       Airline flight delay prediction using machine learning algorithms.
      </strong>
      <em>
       ACM International Conference Proceedings Series.
      </em>
     </p>
    </li>
    <li>
     <p>
      Zhang, K., Jiang, Y., Liu, D., &amp; Song, H. (2021).
      <strong>
       Spatio-temporal data mining for aviation delay prediction.
      </strong>
      <em>
       arXiv preprint
      </em>
      arXiv:2103.11221.
     </p>
    </li>
    <li>
     <p>
      Franco, J. L., Machado Neto, M. V., Verri, F. A. N., &amp; Amancio, D. R. (2025).
      <strong>
       Graph machine learning for flight delay prediction due to holding manoeuvre.
      </strong>
      <em>
       arXiv preprint
      </em>
      arXiv:2502.04233.
     </p>
    </li>
    <li>
     <p>
      Qu, J.,
      <em>
       et al.
      </em>
      (2023).
      <strong>
       Flight delay regression prediction model based on attention mechanism.
      </strong>
      <em>
       Entropy, 25
      </em>
      (5), 770.
     </p>
    </li>
    <li>
     <p>
      Soopal, D. (2020).
      <strong>
       Airline data analysis using Spark technologies.
      </strong>
      <em>
       Medium.
      </em>
     </p>
    </li>
   </ul>
  </div>
 </div>
</div>

    </div>
    <!-- Ensure MathJax processes the page after load -->
    <script>
      // Wait for MathJax to load and then process the page
      window.addEventListener('load', function() {
        if (window.MathJax && window.MathJax.typesetPromise) {
          MathJax.typesetPromise().then(function () {
            console.log('MathJax rendering complete');
          }).catch(function (err) {
            console.error('MathJax rendering error:', err);
          });
        } else {
          // If MathJax hasn't loaded yet, wait a bit and try again
          setTimeout(function() {
            if (window.MathJax && window.MathJax.typesetPromise) {
              MathJax.typesetPromise().then(function () {
                console.log('MathJax rendering complete (delayed)');
              }).catch(function (err) {
                console.error('MathJax rendering error:', err);
              });
            }
          }, 1000);
        }
      });
    </script>
      </div>
    </main>
  </div>
</body>
</html>

